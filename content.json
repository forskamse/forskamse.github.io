{"pages":[{"title":"About Me","text":"Hi there, this is Forskamse 👋 🏫 I’m currently a Ph.D. student in Electrical and Computer Engineering (ECE) with the University of Macau … 🔭 I’m working on Artifical Intelligence and Internet of Things … 📃 I constantly update blogs and tutorials on Forskamse’s Homepage and Forskamse’s Blog … 📫 You may contact me at forskamse@gmail.com …","link":"/about/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"},{"title":"Categories","text":"","link":"/categories/index.html"}],"posts":[{"title":"Linux远程桌面服务VNC&#x2F;XRDP&#x2F;Xdmcp&#x2F;SSH+X11转发及其在树莓派上的使用","text":"Linux下有三大知名的远程桌面服务，即VNC/XRDP/Xdmcp，此外还有一个认知度不那么高的SSH+X11转发服务也是很好用的。下面的介绍中我引入在树莓派上的应用（使用Raspbian Stretch），给大家一个直观的认识。 VNC 使用VNC服务时，先在树莓派上安装vncserver，然后在PC或其他设备上安装vncviewer。 树莓派上的vncserver有：realvnc、tightvnc、x11vnc等。其实知名的vnc服务提供方还有tigervnc和ultravnc等，只是没有推出arm或树莓派版本。 realvnc在此下载安装：https://www.realvnc.com/en/connect/download/vnc/raspberrypi/ tightvnc和x11vnc使用apt-get安装即可： 123sudo apt-get install tightvnc或sudo apt-get install x11vnc realvnc和tightvnc在安装完成后执行： 1vncserver 首次执行，会要求输入密码以及view-only模式密码，输入后生成一个桌面，提示如下： 12......New desktop is raspberrypi:1 (192.168.253.6:1) x11vnc在安装完成后执行: 1234#设置密码x11vnc -storepasswd#启动服务x11vnc -auth guess -once -loop -noxdamage -repeat -rfbauth /home/pi/.vnc/passwd -rfbport 5900 -shared vncviewer可以使用realvnc、tightvnc、ultravnc、tigervnc等提供的vncviewer。 realvnc viewer：https://www.realvnc.com/en/connect/download/viewer/ realvnc提供的vncviewer支持很多设备，同时复制粘贴等功能也相对完善，一般选用realvnc viewer就可以了。 tightvnc viewer：https://www.tightvnc.com/download.php ultravnc viewer：http://www.uvnc.com/downloads.html tigervnc viewer：https://bintray.com/tigervnc/beta/tigervnc XRDP Windows上有一个远程桌面服务（Remote Desktop Protocol，RDP），Linux上类似的RDP服务称为XRDP。 安装方法如下： 1sudo apt-get install xrdp XRDP安装完是默认启动的，开机也会自动启动。 Windows上自带的远程桌面连接可以直接使用： 不过复制粘贴这些功能做的不如vncviewer好。 Xdmcp Xdmcp（X Display Manager Control Protocol），即X显示管理器控制协议，由DP（Display Manager），即显示管理器。 树莓派上默认使用的是lightdm这个显示管理器，修改其配置以启用Xdmcp： 123sudo nano /etc/lightdm/lightdm.conf#找到XDMCP Server configuration，修改启用项配置，其他端口等配置不必改。enabled=true Xdmcp的客户端方面，我推荐xmanager，下载地址：http://www.xshellcn.com/xiazai.html 建立会话： 此外，也可以使用Mobaxterm： SSH+X11转发 这种远程桌面服务方式在服务端方面不需要进行更多的设置，只要SSH能正常访问即可。 客户端方面推荐使用Mobaxterm，只需要在对话中将Remote environment由Interactive shell修改为LXDE desktop，如下： 打开后的效果如下： 使用Putty也是可以的，在会话设置的Connection–SSH–X11下启用X11 forwarding： 打开终端后，执行以下命令： 1startlxde 就可以打开桌面了。 说一句题外话，Mobaxterm是个十分全面的终端软件，无论是明码文字接口Telnet、Rsh，密码文字接口SSH，图形接口Xdmcp（XServer）、RDP（XRDP）、VNC，X11 Forwarding，文件传输FTP、SFTP，甚至是串口Serial都支持。本人强烈推荐。","link":"/2018/07/21/2018-07-12-Linux_Remote_Desktop_Services_and_Their_Applications_on_RPi/"},{"title":"卷积神经网络重要论文资源合辑","text":"卷积神经网络的前身与早期发展： 1980年日本学者福岛邦彦（Kunihiko Fukushima）提出的神经认知机模型（Neocognitron） Fukushima K, Miyake S. Neocognitron: A self-organizing neural network model for a mechanism of visual pattern recognition[M].Competition and cooperation in neural nets. Springer, Berlin, Heidelberg, 1982: 267-285. 1989年Yann LeCun提出第一个真正意义上的CNN：LeNet 1989 LeCun Y, Boser B, Denker J S, et al. Backpropagation applied to handwritten zip code recognition[J]. Neural computation, 1989, 1(4): 541-551. 1998年Yann LeCun在其博士论文中详细介绍了LeNet（又称LeNet-5），影响力巨大 LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324. 2012年以来卷积神经网络迎来迅猛发展阶段： 2012年ILSVRC冠军：AlexNet，掀起深度学习计算机视觉狂潮 Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C].Advances in neural information processing systems. 2012: 1097-1105. 2013年ILSVRC冠军：ZFNet Zeiler M D, Fergus R. Visualizing and understanding convolutional networks[C].European conference on computer vision. Springer, Cham, 2014: 818-833. 2014年ILSVRC冠军：GoogLeNet，提出Inception结构 Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]. Cvpr, 2015. 2014年ILSVRC亚军：VGGNet，亮点是对网络深度的研究 Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014. 2015年ILSVRC冠军：ResNet，提出Residual结构 He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C].Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778. 卷积神经网络结合改进与瓶颈阶段： 合理结合Inception结构与Residual结构的卷积神经网络已经能够达到令人满意的特征提取效果，但是在解释性上却没有更深一步进展。 2016年Google团队结合了Inception结构与Residual 结构，提出Inception-Residual Net Szegedy C, Ioffe S, Vanhoucke V, et al. Inception-v4, inception-resnet and the impact of residual connections on learning[C].AAAI. 2017, 4: 12. 2016年何凯明提出新的ResNet的想法：Identity Mapping He K, Zhang X, Ren S, et al. Identity mappings in deep residual networks[C].European Conference on Computer Vision. Springer, Cham, 2016: 630-645. 2017年DenseNet Huang G, Liu Z, Weinberger K Q, et al. Densely connected convolutional networks[C].Proceedings of the IEEE conference on computer vision and pattern recognition. 2017, 1(2): 3. 轻量级卷积神经网络发展阶段： 2016年以来，卷积神经网络开始往轻量化发展，为视觉深度学习模型在移动设备上的应用提供条件。 2016年MobileNet Howard A G, Zhu M, Chen B, et al. Mobilenets: Efficient convolutional neural networks for mobile vision applications[J]. arXiv preprint arXiv:1704.04861, 2017. 2016年ShuffleNet Zhang X, Zhou X, Lin M, et al. Shufflenet: An extremely efficient convolutional neural network for mobile devices[J]. arXiv preprint arXiv:1707.01083, 2017. 2016年Xception【注：Xception目标并不是使卷积神经网络轻量化，而是在不增加网络复杂度的情况下提升性能，但其中使用的depthwise convolution思想是MobileNet等轻量级卷积神经网络的关键，故也列在这里】 Chollet F. Xception: Deep learning with depthwise separable convolutions[J]. arXiv preprint, 2017: 1610.02357. 2016年ResNeXt【注：ResNeXt也是为了在不增加网络复杂度的情况下提升性能，列在此处的原因与Xception相同】 Xie S, Girshick R, Dollár P, et al. Aggregated residual transformations for deep neural networks[C].Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. IEEE, 2017: 5987-5995. 论文合集GitHub地址：CNN-Papers","link":"/2018/06/20/2018-06-20-CNN_Papers_All_in_One/"},{"title":"Linux文件系统","text":"文件系统 计算机的文件系统是一种存储和组织计算机数据的方法，借助于文件系统，用户或程序对文件的访问和查找变得容易。 Linux支持的文件系统格式有：Ext2, Ext3, Ext4, ReiserFS, Xfs, Btrfs, FAT, FAT32, NTFS等。本文中，我并不打算展开对这些文件系统的详细解释，只是简单说出以下这些结论： Ext2, Ext3, Ext4是Linux系统上最常用的文件系统，发展到Ext4时已经十分稳定，没有特别要求时，一般都可以使用； ReiserFS是用B+树作为数据结构的文件系统，在处理小文件时有较好的性能，在实践中，ReiserFS在处理文件小于1k小文件时，甚至效率可以比ext3快约10倍; XFS使用64位管理空间，在多文件、大文件系统、空间利用率等方面相比Ext4更有优势。从CentOS 7开始，默认的文件系统就由此前的Ext4改为XFS了，由于文件规模的不断增大，日后Ext4可能会被XFS所取代。 Btrfs官方宣称其为“下一代文件系统”，虽然从理念上看Btrfs确实可能存在不错的效果，但截至目前，它的性能表现还是太差了，不建议使用。 【Ext4、XFS、Btrfs的详细对比，感兴趣的读者可以看看这篇Benchmark：EXT3 vs EXT4 vs XFS vs BTRFS linux filesystems benchmark】 Linux虽然支持FAT、FAT32、NTFS，但仅仅是为了兼容性，这三个文件系统很容易产生磁盘碎片（尽管NTFS上已有不小改善），Linux系统下一般是不会轻易使用的。 挂载点 挂载点是linux中的磁盘文件系统的入口目录。 挂载点与其功能描述如下： / 根目录，存放系统命令和用户数据等（如果下面挂载点没有单独的分区，它们都将在根目录的分区中） /boot boot loader 的静态链接文件，存放与Linux启动相关的程序 /home 用户目录，存放普通用户的数据 /tmp 临时文件 /usr 是Red Hat Linux系统存放软件的地方,如有可能应将最大空间分给它： /usr/local 自已安装程序安装在此 /usr/X1186 X-Windows目录，存放一些X-Windows的配置文件 /usr/include 系统头文件，存储一些C语言的头文件 /usr/src Linux内核源代码，Linux系统所安装的内核源代码都保存在此 /usr/bin 对/bin目录的一些补充 /usr/sbin 对/sbin目录的一些补充 /usr/share/doc 用户文档 /var 不断变化的数据，服务器的一些服务、日志放在下面： /var/www：一般WEB存放网页的目录 /var/mail：postfix邮件的存放邮件的目录 /var/log：系统日志记录 /var/spool：存放一些邮件、新闻、打印队列等。 /opt （Option可选的）附加的应用程序软件包 /bin 基本命令执行文件 /dev 设备文件 /etc 主机特定的系统配置 /lib 基本共享库以及内核模块 /media 用于移动介质的挂载点 /mnt 用于临时挂载文件系统或者别的硬件设备（如光驱、软驱） /proc 系统信息的虚拟目录(2.4 和 2.6 内核)，这些信息是在内存中，由系统自己产生的。 /root root 用户的目录 /sbin 基本系统命令执行文件 /sys 系统信息的虚拟目录(2.6 内核) /srv 系统提供的用于 service 的数据 /lost+found 这个目录在大多数情况下都是空的。但是如果你正在工作突然停电，或是没有用正常方式关机，在你重新启动机器的时候，有些文件就会找不到应该存放的地方，对于这些文件，系统将他们放在这个目录下。 当然上面这么多挂载点，实际上是没有比较每个目录都单独进行挂载，我们只需要根据自己的实际使用需要对个别目录进行挂载，这样系统结构看起来也会精简很多。最少的时候，我们只需要挂载/就可以了（当然这样并不好）。 分区 根据挂载点的不同，对磁盘进行分区，选择最合适的文件系统，可以使计算机的性能、管理达到最优。 分区有很多的优点，例如： 1）保护数据；假如误操作，有分区的情况下就可能保护一部分数据免受误操作的影响；重装操作系统时，如果原先的系统中/home与/两个挂载点是对应着两个不同分区时，/home目录就不会受到影响； 2）针对不同挂载点的特性选择文件系统，开启不同的挂载选项（如是否需要即时同步，是否开启日志，是否启用压缩）以更好地发挥性能，比如对/var使用Reiserfs（这里面的文件通常小而繁杂），对/home使用XFS（超大容量支持可能是用户文件比较需求的），对/使用Ext4（更加稳定）。 3）分区可以缩小硬盘搜索范围，提高效率。 我举一例比较典型的分区方案： 挂载点 分区 文件系统 分配详情 /boot 启动分区 Ext4 只需要几百m即可，可以容纳下两三个内核足矣。 /swap 交换分区 Swap 物理内存的1.5-2倍，物理内存够大也可不分配 / 根分区 Ext4 桌面系统给个100G~200G足矣。 /home 家分区 XFS 剩下的可以全部分配给家分区 参考文献 https://linux.cn/article-7083-1.html http://my.oschina.net/leejun2005/blog/290073 http://wuchong.me/blog/2014/07/19/linux-file-system/","link":"/2018/07/17/2018-07-17-Linux_File_System/"},{"title":"使用pip安装TensorFlow Object Detection API","text":"TensorFlow Object Detection API的安装相当麻烦，其 官方安装指导要求使用者先克隆下整个tensorflow/models仓库，然后安装Protobuf，编译出object_detection模块，再使用pip进行安装。虽然从开发者的角度看，此安装方法足以满足在各个系统平台下安装TensorFlow Object Detection API的需求，但对于使用者来说，安装这一个API可能就需要耗费大量的时间。 解决方法 【2021-07-05更新】TensorFlow在TensorFlow 2.2.0时推出了TensorFlow Models高级API的官方PyPI项目，然和遗憾的是，截止当前，TensorFlow官方仍然只在其中纳入Official分支，Community分支和Research分支（Object Detection就在其中）还是没有得到妥善安排。也就是说，我们仍然无法使用pip轻松地安装TensorFlow Object Detection API. 为跟上TensorFlow Object Detection API的官方更新，也为TensorFlow 2.x用户提供便捷安装途径，作出一些更新： 更新项目至PyPI 更新至支持TensorFlow 2.2.0以上版本 更新至支持TensorFlow 1.15.0 移除Python 2.x版本支持 移除此前提供的egg包 最新项目地址： GitHub: https://github.com/forskamse/TensorFlow-Object-Detection-API PyPI: tf1-tensorflow-object-detection-api，tf2-tensorflow-object-detection-api 鉴于上述问题，我将object detection api打包成whl包和egg包，直接使用pip或者easy_install安装即可。 我将打包好的whl包与egg包分享出来，打包环境为Raspbian 9 Stretch（Python环境是3.5.3和Python2.7.13）、Win10 64位（Python环境是3.6.6和Python2.7.15）、Manjaro Linux 64位（Python环境是3.6.6和Python2.7.15）。下载地址：Python_Packages_of_TensorFlow_Object_Detection_API 1. 安装依赖 Tensorflow Object Detection API 需要如下依赖： [使用包管理工具安装（Linux）/系统级安装（Windows）] protobuf python-tk (tk in Manjaro) [使用pip安装] tensorflow pillow lxml jupyter matplotlib cython contextlib2 2. 安装下载的whl包或者egg包 安装whl只需执行： 1pip install xxx.whl 安装egg只需执行： 1easy_install xxx.egg 3. 使用 使用方法如下： 123from object_detection.xxx import xxx# e.g.:from object_detection.utils import label_map_util, visualization_utils","link":"/2018/07/24/2018-07-24-Install_TensorFlow_Object_Detection_API_With_pip/"},{"title":"正向代理与反向代理","text":"客户端在访问目标服务器时，可能会遇到：1) 目标服务器允许客户端访问，但受到其他限制（如客户端防火墙等）导致客户端无法访问目标服务器的情况；2）目标服务器拒绝客户端访问资源（如服务器端防火墙、IP限制等）的情况。 正向代理与反向代理则是分别用于应对这两种情况的。 第一种情况下，为了能够访问到目标服务器，我们就在客户端与目标服务器中间设立一个代理服务器（当然要确保代理服务器可以访问目标服务器），客户端向代理服务器发送一个请求，告知代理要访问的目标服务器，代理接收到请求后向目标服务器转交访问请求并且将获得的内容返回给客户端。 第二种情况下，为了能够访问到目标服务器，我们也要在客户端与目标服务器中间设立一个代理服务器（当然也要确保代理服务器可以访问目标服务器），客户端向目标服务器发送请求（实际是发到了反向代理服务器上），反向代理访问目标服务器并且将获得的内容返回给客户端；这个行为是将目标服务器上的资源反代到了代理服务器上，使得客户端可以访问。 区别 个人认为正向代理与反向代理最本质的区别在于代理服务器代理的是客户端还是目标服务器端：如果代理服务器与客户端常态连接[1]，那么我们认为其代理的是客户端，称其为正向代理；如果代理服务器与目标服务器端常态连接，那么我们认为其代理的是目标服务器端，称其为反向代理。 看一下其他文章的看法[2]： 有一些文章强调反向代理对客户端是透明的（即反向代理隐藏了真实的服务器端），没有隐藏客户端，客户端不需要进行任何配置；正向代理对服务器端是透明的（即正向代理隐藏了真实的客户端），隐藏了客户端，客户端需要进行配置。 对于前者，我认为这是局限于反向代理服务器为目标服务器服务的场景（如负载均衡、静态缓冲等），并不恰当；在解除目标服务器对IP的限制等反向代理为客户端服务的场景下，反向代理变为对服务器端透明了，而且可能隐藏了客户端，此时客户端是需要配置指向反代服务器；而如果是内网穿透场景，客户端和目标服务器端都需要配置，反代服务器对任何一方都不是透明的。 对于后者，科学访问、加速访问等场景下，客户端是需要进行配置的，如果正向代理用来做授权访问的话，通常客户端就不需要配置，至于是将客户端的IP暴露给服务器端（正向代理对服务器端透明，客户端未被隐藏），还是将正向代理的IP暴露给服务器端（正向代理隐藏了客户端，对服务器端并不透明）也不确定。 也就是说，代理服务器的透明与否、是否隐藏客户端完全取决于代理服务器自身的配置，由此又有透明代理、匿名代理、混淆代理、高匿代理的区别[3]；是否需要配置客户端则完全由应用场景决定。 正向代理应用场景 科学访问 如图1所示，假设最初用户A要访问服务器B需要经过R1和R2路由器这样一个路由节点，如果路由器R1或者路由器R2发生故障，那么就无法访问服务器B了。但是如果用户A让代理服务器Z去代替自己访问服务器B，由于代理服务器Z没有在路由器R1或R2节点中，而是通过其它的路由节点访问服务器B，那么用户A就可以得到服务器B的数据了。 加速访问 仍如图一所示，假设路由器R1、R2已经恢复连接，但是用户A通过路由器R1、R2访问到服务器B的速度较慢，而通过代理服务器为访问服务器B的速度更快，人们就会使用代理服务器来加速访问。 缓存（Cache） 仍如图一所示，如果在用户A访问服务器B某数据J之前，已经有人通过代理服务器Z访问过服务器B上得数据J，那么代理服务器Z会把数据J保存一段时间，如果有人正好取该数据J，那么代理服务器Z不再访问服务器B，而把缓存的数据J直接发给用户A。这一技术被称为缓存命中。如果有更多的像用户A的用户来访问代理服务器Z，那么这些用户都可以直接从代理服务器Z中取得数据J，而不必再去服务器B下载数据了。 客户端授权访问 ) 如图2所示，在内网中，用户A和用户B都设置了代理服务器，如果A有访问互联网的权限，用户A被允许访问互联网，则可以通过代理服务器Z访问到服务器B；用户B不被允许访问互联网，其访问服务器B的数据包就会被丢弃。授权在代理服务器Z上做出。 反向代理应用场景 用于负载均衡 1）需要有一个负载均衡设备来分发用户请求，将用户请求分发到空闲的服务器上 2）服务器返回自己的服务到负载均衡设备 3）负载均衡将服务器的服务返回用户 缓存（Cache） 反向代理也可以用于缓存，客户端访问时可以从代理服务器直接读回数据。常有人将反向代理的缓存功能用于镜像网站的制作。 用于内网穿透 反向代理用于内网穿透的应用十分广泛。外网通常无法直接访问内网，但如果为内网设备配置了反向代理，客户端就可以透过反向代理服务器访问到内网设备。 更多细节可以移步我的博客 外网访问内网（内网穿透）方法总结 反向代理部分。 解除目标服务器对IP的限制 请看下面的反向代理实例。 正向代理实例 Nginx搭建HTTP正向代理服务器 该实例使用nginx搭建了一个HTTP正向代理服务器，使得公司内网中访问外网受限的电脑可以通过正向代理访问外网。 反向代理实例 自建反代服务器解决云音乐海外限制 该实例搭建了一个反向代理服务器，对网易云音乐网页文件及其 API 接口进行反带，使得网易云音乐客户端可以访问资源；实验的反代服务器位于国外，本身也是受限的，无法访问网易云音乐，但是这里使用了一个小Trick，反代服务器暴露给网易云音乐的是一个查得的国内IP，从而避免了网易云音乐的IP限制。当然，如果服务器本身位于国内，就不必使用这个Trick了。 [Reference] 反向代理为何叫反向代理？ nginx 反向代理 图解正向代理、反向代理、透明代理 Nginx搭建HTTP正向代理服务器 自建反代服务器解决云音乐海外限制 常态连接并不意味着双方有着绝对的持续连接状态，只要有着必要的映射关系即可。例如反向代理的负载均衡场景，代理服务器会将请求分发到哪些服务器上这是固定了的；再如正向代理的HTTP代理，代理服务器与客户端之间存在HTTP服务（端口）的映射关系，代理服务器具体访问哪个目标服务器则是由客户端指定的，不存在常态连接。 ↩︎ 正向代理和反向代理、透明代理的区别？, 正向代理与反向代理【总结】 ↩︎ 透明代理、匿名代理、混淆代理、高匿代理有什么区别？ ↩︎","link":"/2018/12/13/2018-12-13-Forward_and_Reverse_Proxy/"},{"title":"硬盘基础知识","text":"硬盘接口 IDE（Integrated Drive Electronics），即电子集成驱动器，是曾经主流的硬盘接口（同时也作为光驱的接口）。IDE又称ATA（Advanced Technology Attachment），即“高级技术附件”。稍晚时间后，又出现了EIDE（Enhanced IDE）及其他改进版本，从当下的视角再看，我们通常已经不再区分IDE与EIDE了。在SATA（Serial ATA）出现后，ATA改名为PATA（Parallel ATA）以作区分。PATA活跃于1986年至2013年。 SCSI（Small Computer System Interface），即小型计算机系统接口，可以连接硬盘、软驱、光驱、打印机等设备。SCSI出现的原因主要是因为IDE接口的硬盘转速太慢，传输速率太低。从原理层面看，SCSI与IDE一样使用的是并行技术，因此在SAS（Serial Attached SCSI）出现后SCSI就通常被称为并行SCSI了。 此后又出现了SATA（Serial Advanced Technology Attachment，串行高级技术附件）、SAS（Serial Attached SCSI，串行连接SCSI） 等接口，使用了串行技术，提高了数据传输速率。 我们可以将，SCSI和SAS划归为另一个系列，SCSI和SAS价格较高，在各自的年代都是用在高级的服务器上的，私人电脑上较少使用。而将IDE和SATA划归为一个系列，它们用于一般电脑或PC上，SATA在当下非常普遍。 命名 在Linux上，IDE硬盘会被标识为hd，例如，在一个IDE接口上接着的两块硬盘会被分别标识为hda与hdb；出现SCSI硬盘后，Linux将其标识为sd，如sda、sdb。此后所有除IDE接口外的硬盘全部沿用SCSI硬盘的标识标准，即sd，没有再做改动。 机械硬盘与固态硬盘 HDD（Hard Disk Drive），硬盘驱动器，常指机械硬盘（Mechanical Hard Disk），区别于固态硬盘（Solid State Disk/Drive）。 机械硬盘组成与容量 机械硬盘由盘片、磁头及其它辅助机构组成。盘片（Disk）是硬盘中承载数据存储的介质，其上附着着磁粉，磁粉的S/N极将分别代表着二进制中的0和1，从而表示二进制数据。利用磁头（Head）的磁力控制指定的一些磁粉的方向，就存储了特定的信息。 下图是一个盘片的示意图： 如上图所示，盘片被分为很多条磁道（Track），即表面上的一些同心圆，磁道是从盘片外圈往内圈编号0磁道，1磁道…。每一个磁道又按512个字节为单位划分为等分，叫做扇区（Sector）。 磁盘是由多个盘片叠加在一起，互相之间由垫圈隔开。盘片上下两面各有一个磁头，每张盘片同一位置的磁道，组成了柱面（Cylinder ）。显然，磁道数=柱面数。 知道CHS（Cylinders、Heads、Sectors）的数量后，就可以确定磁盘的容量： 磁盘容量 = 柱面数（磁道数）× 磁头数 × 扇区数 × 扇区大小（512 Bytes） 固态硬盘 固态硬盘没有采用磁性介质作为存储介质，而是使用半导体材料来存储数据。 固态硬盘的内部构造十分简单，固态硬盘内主体其实就是一块PCB板，而这块PCB板上最基本的配件就是控制芯片，缓存芯片（部分低端硬盘无缓存芯片）和用于存储数据的闪存芯片。如下图所示： 固态硬盘也有扇区（Sector）的概念，与机械硬盘一致。 运行模式 常见的硬盘运行模式有AHCI（Advanced Host Controller Interface，高级主控接口）模式与IDE模式，其中AHCI在Win7以后得到全面支持，IDE则兼容更多系统。IDE不支持一些新技术，也就难以发挥硬盘的速度性能，这一问题在机械硬盘时代显得没有那么严峻，然而伴随着SSD的兴起，这一问题已经变得极为严峻，也就是说SSD在AHCI模式下与在IDE模式下有很大的性能差异。因此，近年来，AHCI正在逐步淘汰IDE。两者的具体对比可查阅下表： 分区表（初始分区） 一块全新的硬盘，必须进行初始分区。初始分区可以分为MBR分区和GPT分区两种形式，对应MBR分区表和GPT分区表。 MBR分区形式 如上图所示，MBR分区形式下，硬盘的第一个扇区是主引导扇区，由三个部分组成：主引导记录（Master Boot Record，MBR）、硬盘分区表（Disk Partition Table，DPT）和硬盘有效标志。 MBR占446个字节，负责从活动分区（活动分区是即启动分区，安装有系统）中装载并运行系统引导程序。 DPT占64个字节，记录着硬盘中分区的数量以及每一分区的大小，每个分区的信息用16个字节表示，因此限制了分区的数量：不能超过4个主分区或者3主分区+1扩展分区，而扩展分区可以划分为任意数量的逻辑分区（扩展分区不可直接使用，需要转化为逻辑分区方可使用）【注1：逻辑分区数量受系统层级的限制，在Linux中，IDE硬盘最多有59个逻辑分区（5-63），SATA硬盘则有11个逻辑分区（5-15）】。 这16字节的具体内容是：启动标志、起止磁头号、起止扇区号、起止柱面号、隐含扇区数目(4个字节)、分区总扇区数目(4个字节)。这里又暴露了MBR分区的一个缺陷：用4个字节表示分区总扇区数， 最大能表示2的32次方的扇区个数，按每扇区512字节计算，每个分区最大不能超过2.2TB。 硬盘有效标志占2个字节，又被称为幻数（Magic Number），固定为55AA。如果该标志错误系统就不能启动。 GPT分区形式 GPT是GUID（Globally Unique Identifier Partition Table） Partition Table的缩写，意即全局唯一标识符分区表。 GPT分区的LBA0是保护性MBR【注2：LBA意为逻辑块地址（Logical Bolck Address），每个逻辑块的大小是512字节，这是与扇区不同的定位方式 】，为了实现有限的兼容性，GPT仍然为MBR保留了这一扇区，用来阻止基于MBR的磁盘工具识别错误，从而覆盖GPT磁盘。 LBA1是GPT头（Primary GPT Header），LBA-1是备份GPT头（Secondary GPT Header），这两部分内容是一样的。GPT头的具体内容在此不做详细说明了。 LBA2-LBA33是分区表项，LBA-33 - LBA-2是备份分区表项，两部分内容也是一样的。GPT就是为了避免MBR的两大缺点：在GPT中，分区表项的数量有MBR的4项增多到128项，因此允许划分128个主分区；同时每项由MBR的16字节扩大到128字节，描述每个分区的开始扇区和结束扇区都用8个字节，因而最多支持2的64次方的扇区数，即支持最大约9.4ZB大小的分区。分区表项的具体内容如下： MBR VS. GPT MBR的缺点之一是不支持大于2.2T的分区，而GPT可以支持18EB的硬盘； MBR还有一个缺点是限制磁盘不能超过4个主分区或者3主分区+1扩展分区（包含随意数目的逻辑分区），而GPT则没有此限制。 GPT也有缺点，GPT分区硬盘在修复磁盘坏轨、做资料恢复、系统还原等任务时都会遇到麻烦，MBR则较为方便。 GPT 定义是 Intel提出的用以替代BIOS以实现对更多硬件的支持的规范：EFI( Extensible Firmware Interface ) 的一部分。例如，使用EFI/UEFI就可以引导GPT分区下的系统，可以将系统安装到2T容量以上的硬盘中。 考虑到兼容性，在EFI/UEFI中可以设置Legacy（传统）模式，从而引导MBR分区下的系统了。 而BIOS只可以引导MBR分区下的系统，不可以引导GPT分区下的系统（但支持GPT分区的硬盘做数据盘）。 查看分区类型 Windows系统下 在“此电脑–管理–磁盘管理”中右键查看“磁盘0”或“磁盘1”属性，在“卷”选项卡下的“磁盘分区形式”即是该磁盘分区类型。 Linux系统下 使用命令查询： 1sudo parted -l Partition Table显示gpt则说明是GPT分区表，显示msdos则说明是MBR分区表。 MBR与GPT的选择 1. 作为系统盘 在Intel的大力推动下，现在很多PC、服务器出厂就是使用EFI/UEFI来启动系统的，磁盘的分区表也是GPT。 如果换上一块全新的磁盘，并希望使用MBR分区表，则需要在EFI/UEFI中切换Legacy模式，否则安装系统时会出错，例如：“Windows 无法安装到此磁盘。选定磁盘不是 GPT 分区类型的磁盘”。 2. 作为数据盘 GPT或是MBR都可以被在EFI/UEFI引导的系统下使用，没有差别。如果需要大于2.2T的分区或是更高的主分区数要求，则选择GPT。 总的来说，作为系统盘，如果需要在2.2T容量以上的分区安装系统，或者对主分区数有更高要求，就必须使用GPT+EFI/UEFI，否则选择GPT+EFI/UEFI、MBR+BIOS或者MBR+EFI/UEFI（Legacy）都是可以的；而作为数据盘，选择的随意性更大，不需要考虑EFI/UEFI的影响。 我的建议是分区方式最好不要转换，可能会造成文件的丢失，如果确有必要，可以通过傲梅分区助手、DiskGenius来辅助，切不可使用Windows系统磁盘管理中的转换或是Linux安装系统的转换功能。","link":"/2018/07/21/2018-07-21-Basics_of_Disks/"},{"title":"Linux域名解析服务","text":"Linux域名解析服务的配置由三个基本的配置文件决定： /etc/hosts, /etc/resolv.conf与/etc/nsswitch.conf。本文结合这三个文件各自的作用与联系介绍Linux的域名解析服务。 /etc/hosts /etc/hosts文件包含了IP地址和主机名之间的映射，可能还包括主机名的别名，合法条目格式如下： 1IP_address canonical_hostname [aliases...] 系统上的所有网络程序首先通过查询该文件来解析对应于某个主机名的IP地址，如果没有解析成功再使用DNS服务程序解析。 通常可以将常用的域名和IP地址映射加入到hosts文件中，实现快速方便的访问。通常情况下这个文件首先记录了本机的ip和主机名。 /etc/resolv.conf /etc/resolv.conf配置了DNS客户，它包含了主机的域名搜索顺序和DNS服务器的地址，合法条目格式如下： 1234nameserver Name server IP addressdomain Local domain namesearch Search list for host-name lookupsortlist 其中： nameserver 声明DNS服务器的IP地址。可以有很多行的nameserver，每一个带一个IP地址。在查询时就按nameserver在本文件中的顺序进行，且只有当第一个nameserver没有反应时才查询下面的nameserver。 domain 声明本地域名。在本地域名下的请求可以直接使用短名（Short Name），例如设置了domain example.com，要访问email.example.com主机[1]，可以直接用email这个短名来访问，就可以访问到email.example.com主机。 search 声明域名搜索列表。其默认值为domain设置的值，当search设置值以后，domain值就失效了。当要查询没有域名的主机（如email），解析器将轮流使用search声明的域名（如search google.com baidu.com）进行组合来查找主机（将查找到email.google.com，然后就停止解析了，不会再对baidu.com域进行检索）。 sortlist 允许将得到域名结果进行特定的排序。它的参数为网络/掩码对，允许任意的排列顺序。 /etc/nsswitch.conf 自glibc 2.x版本之后，Linux的域名解析服务就由Name Service Switch (NSS) 接管了，其配置文件为/etc/nsswitch.conf。 NSS并不是只管域名解析的，管域名解析的是它配置文件的hosts字段： 1hosts: files dns 其中，files指定了搜索/etc/hosts文件，且其优先级最高；dns字段则指定了前面用/etc/resolv.conf建立的主机数据库（hosts database）。 [Reference] Domain name resolution Arch manual pages - HOSTS(5) Arch manual pages - RESOLV.CONF(5) Arch manual pages - NSSWITCH.CONF(5) 域名和主机名都是IP的别名，为了避免记忆数字IP而设计出来的人类易读的形式。透过解析器（Resolver），可以将域名和主机名解析为对应的IP。域名的范围要比主机名大，一个域名下可以有多个主机名，例如，域名abc.com下，有主机server1和server2，其主机全名就是 server1.abc.com 和 server2.abc.com 。server1.abc.com 和 server2.abc.com 同时也是abc.com的子域名。 ↩︎","link":"/2018/12/13/2018-12-13-Linux_Domain_Name_Resolution/"},{"title":"基于树莓派的蓝牙出勤追踪系统","text":"本文介绍一个基于树莓派的蓝牙出勤追踪系统，用于记录和监督自己的工作时长情况。 代码与安装指引已更新在GitHub上：树莓派蓝牙出勤追踪系统。 该系统使用树莓派扫描附近的蓝牙或蓝牙低功耗设备，以无感方式收集出勤信息。信息将被存储在InfluxDB中，并通过Grafana的Dashboard使数据可视化。 我使用APScheduler设置定时事件，往数据库中插入一个异常值，来触发Grafana的报警，向邮箱发送每日报告。 系统目前支持多个蓝牙设备（蓝牙或BLE）的同时扫描与记录，便于多人使用。多人使用时，需要在代码中增加对应的scheduler。 此系统还可为树莓派在其他物联网场景的应用提供支持。 欢迎star与fork。 【附安装指引】 RPi Bluetooth Attendance Information Collection System This system helps collect attendance information in a non-inductive way by scanning the nearby Bluetooth or BLE device using Raspberry Pi. The system stores information in InfluxDB and makes the information observable via Grafana. The Daily report is also supported. Installation 1. Clone the repository 12cd ~git clone https://github.com/forskamse/RPi-Bluetooth-Attendance-Information-Collection-System.git 2. System dependencies 12345678910111213141516171819202122232425262728293031[Hardware: Raspberry Pi 4 - 4G RAM Version][OS: Raspbian GNU/Linux 10 (buster)][HCI Tool: V5.50][Influx DB: V1.6.4]wget -qO- https://repos.influxdata.com/influxdb.key | sudo apt-key add -echo &quot;deb https://repos.influxdata.com/debian buster stable&quot; | sudo tee /etc/apt/sources.list.d/influxdb.listsudo apt updatesudo apt install influxdb influxdb-client[Grafana V6.6.0]wget https://dl.grafana.com/oss/release/grafana_6.6.0_armhf.debsudo dpkg -i grafana_6.6.0_armhf.deb[Grafana Rendering Plugin]wget https://nodejs.org/dist/v12.16.0/node-v12.16.0-linux-armv7l.tar.xzsudo ln -s /home/pi/Projects/node-v12.16.0-linux-armv7l/bin/node /usr/bin/nodesudo ln -s /home/pi/Projects/node-v12.16.0-linux-armv7l/bin/npm /usr/bin/npmnpm -g install yarnnpm -g install typescriptsudo ln -s /home/pi/Projects/node-v12.16.0-linux-armv7l/bin/tsc /usr/bin/tscsudo ln -s /home/pi/Projects/node-v12.16.0-linux-armv7l/bin/yarn /usr/bin/yarn# You should change to root and run the following commands.su rootcd /var/lib/grafana/plugins/git clone https://github.com/grafana/grafana-image-renderer.gitcd grafana-image-renderermake depsmake buildsudo apt install chromium-browser chromium-chromedrivercd /var/lib/grafana/plugins/grafana-image-renderer/node_modules/puppeteer/.local-chromium/linux-706915/chrome-linux/ # here pls check whether your chrome version number is 706915 or notmv chrome chrome.bakcp /usr/bin/chromium-browser /var/lib/grafana/plugins/grafana-image-renderer/node_modules/puppeteer/.local-chromium/linux-706915/chrome-linux/chromecd ~ 3. Python dependencies Since BLE scanning requires system permission, using system python3 environment is highly recommended. Otherwise you might suffer from some issues on module searching when running the code with sudo permission. 1sudo pip3 install influxdb apscheduler -i https://pypi.tuna.tsinghua.edu.cn/simple/ Configuration 1. Code modification RPi-Bluetooth-Attendance-Information-Collection-System.py On considering the security, just write [your_db_pwd] into a txt file. Change [your_db_user]. Change target device names(targetDevName, data type: list) and target device addresses(targetDevAddrs, data type: list). You can put both ‘Bluetooth’ and ‘BLE’ device addresses in targetDevAddrs. Set triggers individually for each target device name if necessary. As a reminder, you should check whether your machine time and local time are consistant. start-when-power-on.sh Change /path/to/your/Project. 2. InfluxDB configuration 123sudo systemctl unmask influxdb.servicesudo systemctl enable influxdbsudo systemctl start influxdb Enter influxdb cli mode(by runing ‘influx’ on shell): 12CREATE USER [your_db_user] WITH PASSWORD [your_db_pwd] WITH ALL PRIVILEGESCREATE DATABASE attendanceInformation 3. Grafana configuration 123## Start grafana-image-renderer server in the backgroundcd /var/lib/grafana/plugins/grafana-image-renderer/nohup node build/app.js server --port=8081 &amp; 1234567891011121314151617## Edit grafana config filesudo nano /etc/grafana/grafana.ini#######################################[smtp]enabled = truehost = [your_email_smtp_host]user = [your_email_address]password = [your_email_passwd]from_address = [your_email_address]from_name = Grafana;For example: ;[your_email_smtp_host]: smtp.qq.com:465;[your_email_address]: xxx@qq.com[rendering]server_url = http://localhost:8081/rendercallback_url = http://localhost:3000/####################################### 1234## Enable and start grafana serversudo /bin/systemctl daemon-reloadsudo /bin/systemctl enable grafana-serversudo systemctl start grafana-server Run ‘hostname -I’ for [your_host_address]. Visit http://[your_host_address]:3000/. Change admin password when first login with username as ‘admin’ and password as ‘admin’. Create a dashbord and add data source InfluxDB with [your_db_user] and [your_db_pwd]. Set up query rules: Some additional query settins help with data observability and default image rendering time range: Set up alert rules: ‘Evaluate every’ determines the intervals when the rule is evaluated. ‘For’ determines the pending duration after the alert rule was triggered. Set up notification channels: Here ‘Include image’ determines whether to send a rendered image or not. ‘Disable Resolve Message’ prevents from sending another [OK] alerting email once the former alerting situation was resolved. 4. Boot from power on 12345## Add configuration before &quot;exit 0&quot;sudo nano /etc/rc.local########################################################/bin/bash /path/to/your/Project/start-when-power-on.sh######################################################## Running 12cd /path/to/your/Project/nohup sudo python3 RPi-Bluetooth-Attendance-Information-Collection-System.py &gt;&gt; RpiAttendance.log &amp; Reference https://pimylifeup.com/raspberry-pi-grafana/ https://github.com/grafana/grafana-image-renderer/blob/master/docs/building_from_source.md https://github.com/grafana/grafana-image-renderer/issues/7 https://grafana.com/docs/grafana/latest/administration/image_rendering/ https://community.openhab.org/t/tutorial-grafana-rendering-on-raspberry-pi/71777","link":"/2020/02/15/2020-02-15-Bluetooth_Attendance_Tracking_System_Based_on_RPi/"},{"title":"内网穿透方法总结","text":"自建服务器或者监控时，需要解决外网设备访问内网端口的任务。这个任务称为内网穿透，解决方法通常是端口映射与端口转发。 网上关于端口映射与端口转发之间区别的讨论很多，观点也不尽相同，在此我也无意争辩二者的区别，因为实际情况是，端口映射与端口转发这两个词在很多时候都混用了。 在阅读本文时，请各位暂且认同：端口映射发生于节点与路由/网关之间，其原理是NAT（Network Address Translation，网络地址翻译）；而端口转发则是利用反向隧道、反向代理，发生于两个网络节点的端口之间。 端口映射 （一） 路由器的虚拟服务器（端口映射）功能 （二） Windows上专用的端口映射工具PortTunnel （三） Linux端口映射工具：RINETD （四） nat123的端口映射 （五） 花生壳内网穿透NAT-DDNS 基于反向隧道的端口转发 （一） ssh端口转发 （二） Holer 基于反向代理的端口转发 （一） frp内网穿透 （二） ngrok内网穿透 （三） n2n内网穿透 端口映射 要实现端口映射，如果是家庭宽带是公网IP，可以直接使用带端口映射功能的路由器，或者将网线插入一台电脑做网关（需要解决的是各服务器之间网络连接的问题，如何使其他服务器连上这台电脑，是通过网线桥接还是无线连接需要自行衡量）；家庭宽带不是公网IP的，可以使用NAT服务、DDNS服务。 ######（一） 路由器的虚拟服务器（端口映射）功能 这种方法需要一个带有端口映射功能的路由器。我以中兴的天翼网关和树莓派motion网络服务为例。配置时，其中外部端口是外网访问的端口，例如可选9000，建议不要太小，因为服务提供商可能屏蔽较小的一些端口；内网端口是motion的端口，为8081或8080；协议选TCP；内部IP是树莓派的局域网ip。例如你的公网ip为59.60.84.xxx，这些设置完以后就可以在浏览器中输入59.60.84.xxx:9000，即可看到实时画面。 ######（二） Windows上专用的端口映射工具PortTunnel PortTunnel是一个实现端口映射的专用工具。它是一个直接运行的软件。如果操作系统为Windows NT/Windows 2000/Windows XP，第一次运行时选择Start，PortTunnel会自动以服务方式运行。点击[Add]按钮添加条目，点击[Edit]按钮编辑现有条目，点击[Delete]按钮删除条目。 在这个“新建/编辑端口映射”对话框中，我们要给该条目命名，然后设定输入端口（Port In）、绑定地址（Bind address）、输出端口（Port Out）和输出地址（Address Out）。其中，“绑定地址”是指监听该主机的哪一个IP（内部IP还是外部IP）。设为“Any(0.0.0.0)”则监听该主机的全部IP。 PortTunnel专门针对HTTP、FTP、SMTP服务的端口映射，提供了较多的参数设置，在相应的标签菜单下调整。此外，PortTunnel还提供了安全性设置和日志、统计等功能。 附一篇教程：《PortTunnel [端口映射软件] 使用配置说明》 ######（三） Linux端口映射工具：RINETD RINETD可以算得上Linux上最为简单好用的端口映射工具了，安装配置均很简单。在此我也就不展开说了，附一篇教程：《rinetd 一个linux下的端口转发工具》，若有需要，学着这个教程做一下就行。 ######（四） nat123的端口映射 nat123对Linux、Windows、Android都适用，在其官网上都有相应的教程： Linux版教程 / Windows版教程 / Android版教程 nat123提供了比较丰富的端口映射功能，有http映射（80端口）、https映射（443端口）、非80端口、非网站（其他端口）、全端口映射、全映射等。提醒大家注意，除全端口映射外，其他服务是不需要在访问侧（外网）加装p2p访问者软件的，可以方便使用【全映射是全端口映射的面p2p访问者软件版本】。nat123有免费线路，也有收费服务，具体的收费情况大家自己再行了解。 我简单说一下全端口映射，以树莓派的vnc服务为例，首先你需要在nat123官网注册一个账号，然后树莓派上安装好nat123软件，并在本地APP上登录账号。nat123的端口映射管理功能在官网上【而不是在本地进行，或者说它只是没有告诉我们如何在本地进行管理】，所以你需要在nat123官网上添加端口映射时选择全端口映射（仅p2p），然后在安卓手机或Windows上安装p2p访问者（nat123官网下载），运行端口映射服务与vnc服务，对vnc来说，端口号=5900+桌面号，例如桌面号为1，那么端口号就是5901，打开p2p访问者，添加访问端口5901，注意p2p访问者要在后台运行，不要关掉，然后打开vnc viewer，输入域名和端口号5901，即可访问树莓派了。 nat123配置较为简单，容易上手；有开放免费线路且使用体验较好；Linux/Windows/Android皆可使用，可能适合较多的人。 ######（五） 花生壳内网穿透NAT-DDNS 说到内网穿透，网上很多人都会提到花生壳的内网穿透。花生壳的解决方案是基于NAT和DDNS的。很多年前我使用花生壳的时候，这个服务确实还是可以的，免费，而且连接速度OK，现在用的人太多，速度自然降下来了，也开始提供付费服务了。具体内容我不多说了。 花生壳官网：http://www.oray.com 下面介绍端口转发，端口转发都需要一个公网IP服务器，如果自己没有的话，就只能寻求第三方提供的端口转发服务（如Holer）了。 基于反向隧道的端口转发 反向隧道端口转发的典型是SSH端口转发，下面我先介绍如何在自己有公网IP服务器的情况下用SSH反向隧道做端口转发，然后介绍一款开源的SSH端口转发工具（第三方服务）。 ######（一） ssh端口转发 ssh端口转发命令的基本格式为： ssh [其他Option] -L/-R sourceIP:sourcePort:targetIP:targetPort user@server_addr 首先明确，建立ssh隧道连接存在两个对象，在这里，我们称发起ssh连接的一侧为Client，而接受ssh连接的一侧为Server，server_addr即为Server的IP地址。 其中-L/-R含义如下： -L：本地端口转发，把发送到Client的端口的请求转发至Server的端口；此时Client是source，Server是target； -R：远程端口转发，把发送到Server的端口的请求转发至Client的端口；此时Server是source，Client是target；显然，内网穿透属于这种情况； 此外，ssh tunnel的典型应用一般是三种，除了上面的本地端口转发和远程端口转发，还有一种-D：动态端口转发，是把发送到Client端口（支持SOCKS协议）的请求转发至Server上，而不需指定转发到哪个Server端口，适用于端口映射关系较多的情况。这种情况相对复杂，与本文所讨论的内网穿透没有太大联系，暂且按下。关于动态端口转发，感兴趣的可以看一下：《SSH Dynamic Port Forwarding》与《SSH dynamic port forwarding with SOCKS》。 其他Options： -N：组织启动阻塞式远程 shell会话。当我们只用 ssh 来建立隧道时很有用。 -f：使该forwarding进程以守护进程形式启动（仅在使用-N选项时有效）。 -p：登录Server时的SSH的端口，不使用时为22。 下面以树莓派SSH服务端口为例来做一个ssh端口转发的简单测试。 Step1：按目前OpenSSH的默认配置，只有localhost才能使用本机的端口转发 , 其他设备发起的连接只会得到“ connection refused”。因此，在开启端口转发之前，首先应该修改sshd的配置，使其他设备发起的连接也可以得到转发。 编辑/etc/ssh/sshd_config文件，添加： 1GatewayPorts yes Step2：在树莓派上，通过远程端口映射，将服务器的2222端口映射到树莓派的22端口： 1ssh -fNR 2222:localhost:22 root@公网IP 这里其实有所省略，完整的写法是： 1ssh -fNR *:2222:localhost:22 root@公网IP *代表接受来自所有IP的连接请求，如果替换为localhost，那么即便做了Step1中的设置，其他设备也无法连接。 Step3：通过服务器的公网IP地址以及2222端口上访问树莓派： 1ssh -p 2222 pi@server_addr 当然，规避OpenSSH的默认限制亦可以选择在其他设备上单独做一个与服务器之间的隧道连接，只是这样较为麻烦： 在第三方设备上，通过本地端口映射，将第三方设备的2222端口映射到服务器的2222端口： 1ssh -fNL 2222:localhost:2222 root@公网IP 在第三方设备上访问树莓派： 1ssh -p 2222 pi@localhost ######（二） Holer Holer的GitHub地址：https://github.com/Wisdom-Projects/holer Holer是基于SSH的内网穿透服务。在Holer仓库的readme文档下有使用指南，没什么技术难度，我就简单说说：例如你想远程SSH登陆你的树莓派，将conf/holer.conf文件中原有的Holer Access Key修改为针对SSH服务的Holer Access Key，再启动Holer即可，服务端就配置完成了。Holer提供的SSH服务的映射端口是holer.org:65534，则在客户端的连接方式是： 1ssh pi@holer.org -p 65534 可以看到，Holer的配置确实简单，但是其问题也十分明显，只有一个Holer Access Key作为唯一标识，大家都是用这个Key，连接数多了以后就出问题了。 Holer也提供了独立的Access Key，这是需要付费开通的。 基于反向代理的端口转发 有公网IP服务器的人可以使用frp、ngrok、n2n等反向代理工具来实现内网穿透。 ######（一） frp内网穿透 GitHub仓库：https://github.com/fatedier/frp GitHubReleases：https://github.com/fatedier/frp/releases/ 根据服务器/客户端所属架构与系统，在releases中分别下载合适的版本，并解压出来。 frps.ini是服务器端的配置文件，配置如下： 12\\[common\\]bind_port = 6666 记住bind_port是frp服务的监听端口。 启动服务端frps： 1./frps -c ./frps.ini 而在客户端，我们要修改的配置文件是frpc.ini（以ssh服务为例）： 123456789\\[common\\]server_addr = x.x.x.xserver_port = 6666 \\[ssh\\]type = tcplocal_ip = 127.0.0.1local_port = 22remote_port = 2222 server_addr是服务器的公网ip，server_port是服务器上设置的frp服务的监听端口。 [ssh]部分的local_port是ssh服务的本地端口，默认是22，而remote端口并不是6666，而是由自己另外指定的服务器上ssh转发的目标端口，这里我选择2222。 启动客户端frpc： 1./frpc -c ./frpc.ini 正确连接后，访问本地服务器则可以使用以下命令： 1ssh pi@公网ip -p 2222 为提高frp服务的可靠性，可以添加crontab来保证frp在意外中断后能够及时恢复服务。 服务端添加crontab定时任务： 1* * * * * /bin/bash /path/to/frp/frps_control.sh 其中frps_control.sh为： 12345678910111213141516171819202122232425#!/bin/bash ps -ef | grep 'frps.ini' | grep -v 'grep' if \\[ $? -ne 0 \\] then cd /path/to/frp/ nohup ./frps -c frps.ini &gt;&gt; log &amp; echo 'frps is now restarting!' exit else echo 'frps is running!' exit fi 客户端添加crontab定时任务： 1* * * * * /bin/bash /path/to/frp/frpc_control.sh 其中frpc_control为： 12345678910111213141516171819202122232425#!/bin/bash client_state=\\`ps -ef | grep 'frpc.ini' | grep -v 'grep'\\` if \\[ ! -n &quot;$client_state&quot; \\] then cd /path/to/frp/ nohup ./frpc -c frpc.ini &gt;&gt; log &amp; echo 'frpc is now restarting!' exit else echo 'frpc is running!' exit fi ######（二） ngrok内网穿透 关于ngrok内网穿透，这里有一篇较完整的教程，供大家参考《自搭Ngrok实现树莓派内网穿透》。 ######（三） n2n内网穿透 请看《n2n内网穿透神器(一条命令实现穿透)(linux,安卓,win,openwrt全介绍)》。 总结 内网穿透服务提供商提供的免费服务的质量逐渐下降是商业的必然趋势。而在选择他们提供的付费服务和自行搭建内网穿透服务之间，我个人还是更倾向于自己搭建，更加灵活而且长期成本会更低。以上内网穿透方法中，目前我一直在用的是路由器端口映射、frp和ngrok内网穿透，这三个方法也是我最终的推荐，足以满足绝大多数场景的内网穿透配置需求**。**","link":"/2020/04/23/2020-04-23-Methods_to_Conduct_Intranet_Penetration/"},{"title":"算法时间复杂度及P、NP、NP-Complete、NP-Hard问题","text":"算法的时间复杂度 如果某个算法的复杂度可以表示为O(nk)O(n^k)O(nk)，即问题规模n出现在底数的位置，这种复杂度称为多项式时间复杂度； 如果某个算法的复杂度表示为O(kn)O(k^n)O(kn)或O(n!)O(n!)O(n!)，这种复杂度称为指数型时间复杂度。 相同问题规模下（同时这个问题规模不是太小），指数型时间复杂度远远大于多项式时间复杂度。 当我们在解决一个问题时，我们选择的算法通常都需要是多项式时间复杂度的，指数型时间复杂度的算法是计算机所不能承受的（除非问题规模很小）。 P、NP、NP-Complete、NP-Hard问题 如果一个问题可以找到一个只有多项式复杂度的算法（这个算法可以在多项式时间内求得解），那这个问题就属于P（Polynomial）问题（即多项式问题）； 无法找到任何多项式复杂度算法的可解问题，则称为指数型（Exponential）问题； 没有任何可解算法的问题，则称为不可解问题； 此外，我们关注多项式时间内是否可以验证一个解，如果可以，这个问题就被称为NP（Non-Deterministic Polynomial ）问题（即非决定性多项式问题）。 由此可知，所有的P问题都是NP问题。 之所以要定义NP问题，是因为通常只有NP问题才可能找到多项式的算法。我们不会指望一个连多项式地验证一个解都不行的问题存在一个解决它的多项式级的算法。 在NP问题中，有这么一类问题，所有的NP问题在多项式时间内都可以归约成这类问题【注：“问题A可归约为问题B”有一个重要的直观意义：B的时间复杂度高于或者等于A的时间复杂度。】，这类问题被称为NPC(NP-Complete)问题【所以说，NPC问题的时间复杂度大于等于NP问题的时间复杂度，NP问题不比NPC问题难。 】。 如果能够证明任何一个NPC问题可以在多项式时间内求得解，就可以证明**P=NP?**这个困扰信息学的重要问题了。 而无论是不是NP问题，又有这么一类问题，所有的NP问题在多项式时间内都可以归约成这类问题，这类问题就被称为NPH（NP-Hard）问题； NPC和NPH两者的区别是: 验证一个问题A是否为NP-Hard无须判断A是否属于NP，但是NPC问题必须首先是NP问题. 根据定义可知NPC ∈ NPH。 由于P=NP？并没有得到证明，因此，目前可以对问题作出这样的分类： 典型的NP-Hard问题 旅行商问题，即TSP问题（Traveling Salesman Problem），又译为旅行推销员问题、货郎担问题，是数学领域中著名问题之一。假设有一个旅行商人要拜访n个城市，他必须选择所要走的路径，路径的限制是每个城市只能拜访一次，而且最后要回到原来出发的城市。路径的选择目标是要求得的路径路程为所有路径之中的最小值。 若有 20 个城，则排法就有19!19!19!种。在排列组合里n!n!n! 写起来轻松，但19!=1.21∗101719! = 1.21*10^{17}19!=1.21∗1017是一个大得不得了的数字。若每秒钟排一次，要排 3.84∗1093.84∗10^{9}3.84∗109 年。旅行商问题可以归约到NPC问题。 参考文献 算法的时间复杂度和空间复杂度-总结 什么是P问题、NP问题和NPC问题 P/NP/NPC/NP-hard NP-Hard问题浅谈","link":"/2020/07/04/2020-07-04-Time_Complexity_of_Algorithms/"},{"title":"使用VS Code的代码片(snippets)以及使用Settings Sync插件同步VS Code的配置","text":"创建Snippets文件 在VS Code可以为每种语言创建Snippets文件：打开File–&gt;Preferences–&gt;User Snippets，Existing Snippets区域显示了已经创建的Snippets文件，点击New Snippets区域的语言可以创建新的Snippets文件。 值得一提的是，对于markdown，VS Code编辑器默认没有开启quickSuggestion，因此即使已准备好markdown.json，仍需在设置中开启quickSuggestion，以便获得快速插入代码片的提示： 打开左下角Manage–&gt;Settings，搜索markdown，找到以下设置项： 选择在settings.json中编辑，将&quot;editor.quickSuggestions&quot;: false改为&quot;editor.quickSuggestions&quot;: true并保存。 语法结构 可直接参考VS Code官方指南里的Snippets语法。 同步管理 【2021-07-03更新】日前VS Code已推出官方同步方案，可以同步设置、User Snippets和所安装插件。可在设置中开启“Settings Sync”。以下同步方案可以忽略。 有两种方案，第一种：由于VS Code的User Snippets功能只需依赖Snippets文件就可以，Snippets文件位于&quot;C:\\Users\\user_name\\AppData\\Roaming\\Code\\User\\snippets&quot;，所以可以简单地使用OneDrive来同步，以管理员身份打开CMD，执行： 1mklink /d &quot;C:\\Users\\your_user_name\\OneDrive\\snippets&quot; &quot;C:\\Users\\your_user_name\\AppData\\Roaming\\Code\\User\\snippets&quot; 第二种，可以使用Settings Sync插件，Settings Sync插件支持同步用户配置、Snippets、扩展及其配置等，很实用。 首先安装Settings Sync插件，重新加载后会进入Settings Sync的配置的界面，点击LOGIN WITH GITHUB，授权GitHub Token和Github Gist Id，并选择新建Gist来存储配置文件。 以后只要使用Shift + Alt + U就可以上传配置；使用Shift + Alt + D就可以下载配置。 在Gist中，有名为cloudSettings Secret的Gist，里面就有所有的配置文件以及Revision信息。 值得注意的是，虽然该插件插件的是Secret Gist，但是只要有Gist ID，所有人还是都可以访问这个Gist的。建议大家千万不要把登录信息放在Snippets中！平时也要注意，代码中不要直接使用明文密码，最起码也用文件读取的方式，安全一些，否则可能不小心就同步到GitHub上去了！","link":"/2020/05/18/2020-05-18-Tips_of_Using_VSCode_Snippets_and_SettingsSync_Plugin/"},{"title":"基于TensorFlow 2.x的一些CNN模块&#x2F;网络的实现","text":"开源一些基于TensorFlow 2.x的CNN模块/网络的实现，可能不定时更新。仓库链接：TensorFlow-2-Implementations-of-CNN-Based-Networks 目前的实现包括： Feature Extraction/Fusion Blocks Atrous Convolutional Block for 1D (data points / sequences) or 2D inputs (images / feature maps), suggested by An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling Receptive Field Block, from Receptive Field Block Net for Accurate and Fast Object Detection Attention Blocks Squeeze-and-Excitation Block (Kind of Channel Attention), from Squeeze-and-Excitation Networks Convolutional Block Attention Module (CBAM), including Channel Attention Module and Spatial Attention Module, from CBAM: Convolutional Block Attention Module Non-Local Block, including ‘Gaussian’, ‘Embedded Gaussian’, ‘Dot Product’ and ‘Concatenation’ modes, from Non-local Neural Networks Dual Attention Module, including Channel Attention Module and Position Attention Module, from Dual Attention Network for Scene Segmentation Backbone Networks DenseNet, from Densely Connected Convolutional Networks 参考了以下文章/仓库中的一些代码实现，在此感谢： [1] https://github.com/philipperemy/keras-tcn [2] https://github.com/Baichenjia/Tensorflow-TCN/blob/master/tcn.py [3] https://arxiv.org/pdf/1803.01271.pdf [4] https://arxiv.org/pdf/1711.07767.pdf [5] https://arxiv.org/abs/1709.01507 [6] https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/nets/attention_module.py [7] https://arxiv.org/abs/1807.06521 [8] https://arxiv.org/pdf/1711.07971.pdf [9] https://github.com/titu1994/keras-non-local-nets/blob/master/non_local.py [10] https://github.com/Tramac/Non-local-tensorflow/tree/master/non_local [11] https://arxiv.org/pdf/1809.02983.pdf [12] https://github.com/niecongchong/DANet-keras/blob/master/layers/attention.py [13] https://github.com/okason97/DenseNet-Tensorflow2/blob/master/densenet/densenet.py [14] https://arxiv.org/pdf/1608.06993.pdf","link":"/2021/03/08/2021-03-08-Implementations_of_Some_CNN_Modules_Based_on_TensorFlow2/"},{"title":"在远程服务器上部署JupyterLab 3.0","text":"近期，JupyterLab刚刚升级到3.0版本，在安装与使用方面都有不小改进，加之之前部署在树莓派上时遇到偶尔需要跟服务器之间做些文件交换的情况，处理起来还是稍微麻烦了点，所以趁着这次JupyterLab的大更新，也在远程服务器上来部署下JupyterLab 3.0了。 通过Anaconda安装Jupyter Lab 先创建一个虚拟环境： 1conda create -n JupyterLab python=3.7 创建完毕并激活环境后，安装JupyterLab： 1conda install -c conda-forge jupyterlab 配置JupyterLab以实现远程安全访问 先用python shell生成一个加密后的密码串：命令行执行python后再python shell中执行以下命令，并输入和确认密码，将会生成一个经过加密的sha1开头的密码串，先将其复制下来。 1from jupyter_server.auth import passwd; passwd() 生成JupyterLab的配置文件： 1jupyter lab --generate-config 会反馈提示默认配置文件的位置，如/home/xxxx/.jupyter/jupyter_lab_config.py。打开该文件并找到以下版块，取消这两个项目的注释，使其生效。密码部分用刚刚生成的加密密码串替换。 123456#------------------------------------------------------------------------------# ServerApp(JupyterApp) configuration#------------------------------------------------------------------------------c.ServerApp.password = 'sha1: xxxxx' #由jupyter_server.auth生成的密码串c.ServerApp.allow_remote_access = True 启动Jupyter Lab 后台启动Jupyter Lab： 1nohup jupyter lab --no-browser &amp; –no-browser 参数代表不要在启动JupyterLab时打开服务器上的浏览器。 在客户端浏览器访问Jupyter Lab JupyterLab网页服务默认端口为8888，因此浏览器中访问server_ip:8888/lab即可跳转到输入密码的界面： 此时要输入的是未加密的原始密码，验证成功后就可以在这个网页上使用JupyterLab了。","link":"/2021/01/07/2021-01-07-Deployment_of_JupyterLab3_on_Remote_Server/"},{"title":"预训练语言模型综述（一）—— 预训练语言模型及其历史","text":"本系列文章是笔者以邱锡鹏老师《Pre-trained Models for Natural Language Processing: A Survey》为主要参考材料所做的关于“预训练语言模型综述”的记录，所涉及之素材也包括其他相关综述与未被纳入此综述的工作，分享出来与大家交流讨论。此篇记录预训练语言模型及其历史。 补充知识 一个好的语言模型应该可以从语料中： （1）捕获语言的特征（linguistic features），包括但不限于 语义特征（semantic features）：词与句子的语义 句法[1]特征（syntactic features）：即句子的结构组织以及句子中词语次之间的依赖关系。 （2）反映语言现象： 一词多义（polysemy）, 指代（anaphora）, 语用学（pragmatics，现多指言外之意）等。 词的表示方法(Word Representations/Word Embeddings) 把文本向量化通常是自然语言处理的第一步。词的向量表示有最简单的One-hot Representation，以及用低维度稠密向量表示的Distributed Representation[2]。 NLP方法/模型发展简史 1. 非神经网络方法 非神经网络方法通常依赖于离散的人工特征，应用起来也比较困难。 2. 早期神经网络模型 早期神经网络模型多使用RNN、CNN等神经网络，同时网络也较浅。主要原因是缺少针对各种NLP任务的大规模数据集，模型如果过深极易引起过拟合，在实际使用中难以确保泛化能力。 3. 第一代预训练语言模型 第一代预训练语言模型学习Non-contextual(static) word embeddings，即与上下文无关的、静态的词向量。第一代预训练语言模型的做法是把词汇表中的每一个词汇映射到一个lookup table中，训练过程就是得到这个lookup table的过程。得到这个lookup table后，把每个词的One-hot乘以lookup table就得到这个词的词向量了。 第一代预训练语言模型有两个明显的缺陷，一是无法处理一词多义等语言现象，因为它没有把词与词的上下文联系起来；二是OOV(Out of Vocabulary)问题，如果有些词没有在训练数据中出现过，那么通过lookup table中也无法得到它的词向量，为了解决OOV问题，我们可以把词进一步分割，变成字符等形式[3]，这样就可以一定程度上解决OOV问题了。 第一代预训练语言模型相对于第二代预训练语言模型还是比较浅的。两个经典结构是Continuous Bag-of-Words(CBOW)和Skip-Gram(SG)，最典型的实现就是word2vec。还有一个经典结构是GloVe，也被广泛用于获取词向量。 推广开来，同时期还有不少工作研究句向量、段向量乃至篇章向量（如Skip-thought vectors，Paragraph vector，Context2Vec等）。将这些工作也归类为第一代预训练语言模型的原因是他们也是把输入映射为固定维度的向量表示。 4. 第二代预训练语言模型 第二代预训练语言模型学习contextual(dynamical) word embeddings，即与上下文相关的、动态的词向量。 第二代预训练语言模型的重要代表是ElMo(Embeddings from Language Models)、OpenAI GPT (Generative Pre-training) 和BERT(Bidirectional Encoder Representation from Transformer) 。 得益于更强的算力、深度模型的发展、NLP预训练任务的设计、大规模训练语料的利用、各种训练技巧的出现，第二代预训练语言模型蓬勃发展、越来越强大。 5. 扩展的预训练语言模型 随着预训练语言模型的发展，研究人员已经不再满足于使用简单范式和简单语料训练预训练语言模型，由此催生了一系列扩展的预训练语言模型。其中包括：知识增强（Knowledge-Enriched）的预训练模型、多语言/跨语言（Multilingual）的预训练模型、针对特定语言（Language-Specific）的预训练模型、多模态（Multi-Modal，包括视频-文本、图像-文本、声音-文本等）的预训练模型、针对特定领域（Domain-Specific）的预训练模型、针对特定任务（Task-Specific）的预训练模型等。此外，还有一些预训练模型是在大型预训练模型上做出一些修改/压缩等操作所得的，包括修剪、量化、参数共享、蒸馏、模块替换等，这其中也涉及到如何应用预训练语言模型的问题，在讲到预训练模型的应用是还会进一步介绍。下图是邱老师综述中关于扩展的预训练模型及相关工作的归纳： NLP深度神经网络的发展 当前，NLP任务通用的神经网络架构如图1所示（其实就是第二代预训练语言模型的架构）。 邱老师的文章把Neural Contextual Encoders分为了两类。 一类是Sequence Models，此类模型是按序列顺序来获取词的上下文（包括CNN模型和RNN模型（LSTM和GRU）），无法很好地处理长期依赖（Long-term dependency）。 另一类是Graph-based Models，此类模型按预定义的树形或图结构（如句法结构、语义联系）建立词与上下文的联系，但是如何建立好的此类结构是比较困难的。因此，全连接与自注意力在强大算力的加持下就提供了一个更为直接的方法：可以建立全连接图然后让模型学习两个词之间的联系。 .tg {border-collapse:collapse;border-spacing:0;} .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; overflow:hidden;padding:10px 5px;word-break:normal;} .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;} .tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top} .tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top} Contextual Encoders NN Types References Sequence Models CNN [1]Y. Kim, “Convolutional Neural Networks for Sentence Classification,” in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Doha, Qatar, Oct. 2014, pp. 1746–1751, doi: 10.3115/v1/D14-1181. LSTM [1]A. M. Dai and Q. V. Le, “Semi-supervised Sequence Learning,” arXiv:1511.01432 [cs], Nov. 2015, Accessed: May 17, 2020. [Online]. Available: http://arxiv.org/abs/1511.01432.[2]P. Liu, X. Qiu, and X. Huang, “Recurrent Neural Network for Text Classification with Multi-Task Learning,” p. 7. GRU [1]R. Kadlec, M. Schmid, O. Bajgar, and J. Kleindienst, “Text Understanding with the Attention Sum Reader Network,” arXiv:1603.01547 [cs], Jun. 2016, Accessed: May 17, 2020. [Online]. Available: http://arxiv.org/abs/1603.01547.[2]L. Li, M. Huang, Y. Liu, S. Qian, and X. He, “Contextual label sensitive gated network for biomedical event trigger extraction,” Journal of Biomedical Informatics, vol. 95, p. 103221, Jul. 2019, doi: 10.1016/j.jbi.2019.103221. Graph-based Models Recursive NN [1]R. Socher et al., “Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank,” in Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Seattle, Washington, USA, Oct. 2013, pp. 1631–1642, Accessed: May 17, 2020. [Online]. Available: https://www.aclweb.org/anthology/D13-1170. TreeLSTM [1]K. S. Tai, R. Socher, and C. D. Manning, “Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks,” in Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Beijing, China, Jul. 2015, pp. 1556–1566, doi: 10.3115/v1/P15-1150.[2]X. Zhu, P. Sobhani, and H. Guo, “Long short-term memory over recursive structures,” in Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, Lille, France, Jul. 2015, pp. 1604–1612, Accessed: May 16, 2020. [Online]. GCN [1]T. N. Kipf and M. Welling, “Semi-Supervised Classification with Graph Convolutional Networks,” arXiv:1609.02907 [cs, stat], Feb. 2017, Accessed: May 17, 2020. [Online]. Available: http://arxiv.org/abs/1609.02907. [1] https://www.zhihu.com/question/31370551?sort=created [2] Z. S. Harris, “Distributional Structure,” WORD, vol. 10, no. 2–3, pp. 146–162, Aug. 1954, doi: 10.1080/00437956.1954.11659520. 容易混淆的概念有语法与词法，词法是分析词与词的变形，即形态学(morphology)；而语法是一个更完整的概念，包括音韵学（phonology）、形态学(morphology)与造句法（syntax）[1]。 ↩︎ Distributed Representation与Distributional Representation容易混淆。通常认为，Distributed Representation是与Local Representation（One-hot Representation就属于Local Representation）相对的，用到低维稠密向量来表示词的语义，单独的维度是不表达什么含义的，只有整个向量表达出含义；而One-hot Representation则是高维稀疏向量来表示词的语义，只有一个维度表示含义。而Distributional Representation的理论基础则是Harris在1954年提出的分布假说（Distributional Hypothesis）[2]，即上下文相似的词，其语义也相近。所以说凡是用到上下文的Representation都可以称为Distributional Representation，如传统的基于计数的词向量、Word2Vec以及contextualized word vector都属于Distributional Representation。 ↩︎ 代表工作有CharCNN、FastText和Byte-Pair Encoding (BPE)等。 ↩︎","link":"/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/"},{"title":"预训练语言模型综述（二）—— 预训练任务及训练策略","text":"本系列文章是笔者以邱锡鹏老师《Pre-trained Models for Natural Language Processing: A Survey》为主要参考材料所做的关于“预训练语言模型综述”的记录，所涉及之素材也包括其他相关综述与未被纳入此综述的工作，分享出来与大家交流讨论。此篇记录预训练任务及训练策略。 预训练任务 预训练任务按学习范式可归类成监督学习、无监督学习和自监督学习三类任务。自监督学习略微特殊，它也有输入和输出标签，所以训练方法其实和监督学习一致，但是它的标签是自动生成而非人工标注的，最典型的就是Masked Language Model(MLM)任务了（监督学习这里特指标签由人工标注的情况）。受限于训练语料的丰富程度，目前基于监督学习的预训练任务仅有机器翻译（Machine Translation），其他主流预训练任务都是无监督或自监督的。随着时间的推移，也有可能发展出其他更为细化的、基于监督学习的预训练任务。总的来说，目前预训练任务的具体分类可参考下表： 1. Language Modeling Language Modeling/Probabilistic Language Modeling(LM) 是经典概率密度估计问题，属无监督学习问题，可以通过MLE来估计。 通常特指自回归语言模型或单向语言模型，因此存在只编码了从左到右的上下文信息的缺点；改进版本是BiLM，即同时编码从左到右的上下文信息和从右到左的上下文信息。 2. Masked Language Modeling 掩码语言建模（Masked Language Modeling）归类为自监督学习问题，并通常作为分类问题来处理。 BERT的MLM是遮挡一个词，然后用含遮挡词标记的整个输入序列来预测被遮挡的词；同时由于fine-tuning时并没有mask token，BERT采取的办法是在数据预处理时选择句子15%的词作为目标掩码词（这些词将不再改变，称之为静态masking），并让数据生成器80%的时间内用[Mask]替代目标遮挡词、10%时间用随机词替代目标遮挡词、10%时间用目标遮挡词替代目标遮挡词。 从Mask Token(s)的角度来看，不同于BERT只mask一个词，Seq2Seq MLM用到Seq2Seq模型，被遮挡了多个连续的词的输入序列由Encoder进行编码，再由Decoder解码被遮挡词序列；SpanBERT也是遮挡多个连续词，同时还引入了用边界预测Mask Tokens的损失。 从执行Masking的角度，不同于BERT的静态masking，RoBERTa采用动态masking，它没有在预处理的时候执行 masking，而是在把序列输入模型时动态生成 mask，并且遮挡词不是固定的，有利于模型学习各种掩码策略下语料表现出来的特征。 还有一类更为综合的MLM，是将知识融入到掩码策略中，典型代表就是百度的ERNIE了。百度的ERNIE在掩码时额外使用了短语级别和实体级别的掩码，藉此向语言模型中引入了知识。 3. Permuted Language Modeling 置换语言建模（Permuted Language Modeling）的开山之作XLNet指出，掩码语言建模中使用的一些特殊符号，尤其是[MASK]，在下游任务中时不存在的，因此在预训练过程和微调过程中就存在一定的gap。所以，XLNet的作者就提出使用置换来替代掩码，即使用置换词而不使用掩码[MASK]。 4. Denoising Autoencoder (DAE) 上述MLM、PLM都属于基于Denoising Autoencoder来进行预训练的方式，即对一个输入进行一定干扰，然后让模型来恢复未受干扰的原始输入。此外还有文本填充（多个Token被同时替换，任务的目标是预测被替换Token的数量）、句子置换（置换文本中句子的顺序）等可用于干扰输入的方法。 5. Contrastive Learning (CTL) 不同于上述几种预训练任务（都是自编码形式），对比学习提供了一种全新的无监督预训练方式，将来也很有希望成为NLP中另一种大行其道的训练方式。对比学习的核心是通过对比进行训练。例如，对比合法的句子与不合法的句子之间的相似度，从而调整训练。邱老师的综述中列举了替换词检测（RTD）、下一句预测（NSP）等使用了对比学习的工作。 训练策略 语料的使用 预训练语言模型离不开对大规模语料的使用。我们可以将语料大致可以分为三类：通用语料、特定领域语料、下游任务直接相关的语料。一般预训练中所用是大规模通用语料与特定领域语料。ULMFiT提出了三阶段训练，其中预训练包含两个阶段，第一阶段使用大规模通用语料进行语言模型预训练，使其学习语言的通用规律；第二阶段使用大规模特定领域语料，得到适合于特定领域的预训练模型，最后再在具体任务上进行微调。此外，从语言种类的角度，多语言预训练语言模型的训练中也存在语料使用的问题。multilingual BERT使用共享词汇表来解决多语言语料的使用问题， XLM则是在此基础上进一步引入了翻译语言建模（translation language modeling），以提升多语言预训练语言模型的效果。 预训练任务的选择 我们在上一部分介绍了各种预训练任务，这些预训练任务都有这各自的特点和优势，在选择应当遵循一些基本的原则。从效率角度考虑，与其他任务相比，对比学习具有更小的计算复杂度，在资源受限时可做优先考虑。从效果角度考虑，需要考虑预训练任务对下游任务的影响，毕竟这才是最终目的。例如：NSP可以使预训练语言模型理解两句话之间的关系，因此针对问答、自然语言推理等下游任务，可以考虑NSP作为预训练任务训练预训练语言模型。","link":"/2021/08/28/2021-08-28-Review_on_Pretrained_Language_Models_Part_II/"},{"title":"预训练语言模型综述（三）—— 预训练语言模型的实际使用","text":"本系列文章是笔者以邱锡鹏老师《Pre-trained Models for Natural Language Processing: A Survey》为主要参考材料所做的关于“预训练语言模型综述”的记录，所涉及之素材也包括其他相关综述与未被纳入此综述的工作，分享出来与大家交流讨论。此篇记录预训练语言模型的实际使用。 预训练语言模型的实际使用 预训练语言模型的实际使用也是一个复杂的问题，我将其归纳为两个方面。一方面，如何将预训练语言模型应用到NLP的下游任务中，提升模型在下游任务的性能才是预训练语言模型这项技术最终的目标；另一方面，尽管预训练语言模型能给各种NLP任务带来性能上的提升，其带来的大量能源消耗以及对计算资源的依赖也始终受到诸多诟病。 迁移学习 大量的文献已经表明，预训练语言模型在通用基准测试、问答、情感分析、命名实体识别、机器翻译、摘要等众多下有任务中可以带来喜人的性能提升。目前，将预训练语言模型应用到下游任务中主要还是依赖于迁移学习进行，迁移学习可以把从预训练语言模型从大规模语料（Source Dataset）中学习到的通用语言知识迁移到特定的下游任务（Target Dataset）上，如下图所示。 （1）预训练任务、模型结构、语料的选择 如在预训练语言模型综述（二）—— 预训练任务及训练策略中所述，我们需要考虑预训练任务对下游任务的影响。例如：NSP可以使预训练语言模型理解两句话之间的关系，因此针对问答、自然语言推理等下游任务，可以考虑NSP作为预训练任务训练预训练语言模型。 模型结构、语料方面，也需要根据下游任务进行选择。如BERT模型，由于其不具备Encoder-Decoder结构，因此其难以用于生成类任务，相比之下，GPT系列预训练模型则可能在生成类任务上带来更好的性能。语料方面亦是如此，如果具备条件，即有大量domain-specific或是language-specific的语料可用于预训练或有现成预训练模型，使用这些模型或可在相关的下游任务上带来更多提升。 （2）层的选择 一个预训练语言模型的不同层可能提取到的特征是不尽相同的。利用这些特征的方式有多种，如仅使用静态的Embedding、顶层表示、全部层的综合表示（按一定方式进行融合）。至于哪一种表示更好或是更适合哪类任务，目前并无定论，还是得通过具体任务的实验来选择。 （3）微调阶段预训练模型参数是否固化 我们知道，通常迁移学习包含两个阶段，一是预训练，二是微调。对于一些任务，在微调阶段，预训练模型作为特征抽取器，其参数被固化（如Word Embedding、ELMo（更为典型））。而对于大多数任务，微调阶段预训练模型的参数不固化，仍在微调阶段进行调整，以适应下游任务。前者做法对比后者做法的优点我暂时还无法明确，个人还是倾向于后者。 模型压缩与加速 为解决大规模预训练语言模型大量消耗能源以及对计算资源依赖的问题，使其可以为更多人员、行业、计算平台所应用，模型压缩与加速是必不可少的。 其实模型压缩这个话题并不限于预训练语言模型，而是与深度学习模型的发展相伴相生。常见的方法，如剪枝、量化、参数共享、低秩分解、知识蒸馏等，在预训练模型上都已有应用案例，具体文献大家可以看邱老师的综述。 笔者在此想指出的是硬件加速方面的工作似乎没有得到邱老师这篇Survey的关注，硬件加速将更有利于预训练模型向更多计算平台（尤其是算力有限的平台）。笔者推荐以下一些工作供大家参考： [1]S. Pati, S. Aga, N. Jayasena, and M. D. Sinclair, “Demystifying BERT: implications for accelerator design,” p. 17. [2]Y. J. Kim and H. H. Awadalla, “FastFormers: highly efficient transformer models for natural language understanding,” arXiv:2010.13382 [cs], Oct. 2020, Accessed: Sep. 26, 2021. [Online]. Available: http://arxiv.org/abs/2010.13382 [3]Z. Liu, G. Li, and J. Cheng, “Hardware acceleration of fully quantized BERT for efficient natural language processing,” arXiv:2103.02800 [cs], Mar. 2021, Accessed: Sep. 26, 2021. [Online]. Available: http://arxiv.org/abs/2103.02800 [4]Y. You et al., “Large batch optimization for deep learning: training BERT in 76 minutes,” arXiv:1904.00962 [cs, stat], Jan. 2020, Accessed: Sep. 26, 2021. [Online]. Available: http://arxiv.org/abs/1904.00962","link":"/2021/09/26/2021-09-27-Review_on_Pretrained_Language_Models_Part_III/"},{"title":"卷积神经网络详解(一)——基础知识","text":"1. 卷积神经网络的组成 1981年诺贝尔医学奖得主，神经生物学家David Hubel 和Torsten Wiesel对人脑视觉系统的研究表明：人脑视觉系统首先通过眼睛来成像，图像通过瞳孔、晶状体最终在视网膜上成像。视网膜上布满了大量的光感受细胞，可以把光刺激转换为神经冲动，神经冲动通过视觉通路传递到大脑的初级视觉皮层（Primary Visual Cortex，V1），V1初步处理得到边缘、方向等特征信息，而后经由V2的进一步抽象得到轮廓、形状等特征信息，如此迭代地经由多层（V1层至V5层）的抽象后得到高层特征。高层特征是低层特征的组合[1]，从低层特征到高层特征的抽象过程中，语义的表现越来越清晰，存在的歧义越来越少，对目标的识别也就越来越精确。这就是人脑视觉系统的分层处理机制。 视觉皮层上的细胞有简单细胞（Simple Cell）与复杂细胞（Complex Cell）之分，这两种细胞的共同点是他们都只对特定方向的条形图样刺激有反应，而他们的主要区别是简单细胞对应的视网膜上的光感受细胞所在的区域比复杂细胞所对应的区域来得小，这个区域被称为感受野（Receptive Field）。这就是人脑视觉系统的感受野机制。 1980年，日本学者Kunihiko Fukushima提出感知机模型（Neocognitron），提出使用卷积层来模拟视觉细胞对特定图案的反应、使用池化层模拟感受野的方法。卷积神经网络的设计深受这个方法的影响，其基本结构为： 具体说来，卷积层用于提取不同的图像特征，有减少参数数量、保留空间信息的作用；池化层用于模拟感受野，有选取特征、减少参数数量的作用，同时引入微小平移不变性[2]；而激活层的设置则是为了引入非线性因子，提升模型的表达能力，这是神经网络中普遍采用的。 2. 卷积层 2.1 图像的局部相关性 图像是具有局部相关性的一类数据[3]，其局部相关性是指组成图像的每个像素点与其周围的像素点是有关联的，而图像上距离较远的像素相关性较弱，因此处理图像时实际上没必要每个神经元都对全局图像进行感知。 2.2 全连接网络用于图像处理 以MNIST手写数字识别为例，该数据集中的图像为（28，28，1）的灰度图像，这个图像由28 * 28个像素点（Pixel）构成，每个像素点有一个通道（Channel）。如果使用全连接网络（即网络中的神经元与相邻层上的每个神经元均连接），那么输入层有28 * 28 =784个神经元，假设hidden层采用了15个神经元[4]，输出层是10个神经元，那么参数个数(w和b)就有：784 * 15 * 10+15+10=117625个。即使在这种情况下，参数量都十分庞大了，如果输入图像的像素点更多、全连接网络的隐藏层层数更多、隐藏层神经元数量更多，参数量就会更加庞大。 大量的参数很容易导致网络过拟合，而且每进行一次反向传播计算量都是巨大的，无论从调参还是计算资源的角度都不建议用全连接网络做图像处理。此外，全连接网络认为“每个输入值都是平等的”，它将输入视为一维向量，并不关心这个像素是第几行、第几列的像素，忽视了空间信息，用于图像这种具有空间局部相关性的数据也是不合适的。 2.3 减少参数数量 在图像局部相关性的支撑下，卷积连接应用而生。 为简化说明，来看一个简单的例子： 在下面的这张图中，输入为3 * 3 = 9个像素，如果将其与16个隐藏层神经元全连接，就会有9 * 16 = 144个连接，也就有144个权值。 为减少连接数，并且基于图像局部相关性的假设，可以仅取四个位置相近（注意图像的Width和Height两个维度）的像素作为输入，四个像素与同一个神经元进行连接，连接的权值记为w0w_0w0​、w1w_1w1​、w2w_2w2​、w3w_3w3​， 如下图所示。 这种连接方式又可看作是数学上的卷积操作[5]，其中这一组权值就被称为卷积核， 如下图右图所示，因此得名卷积连接。 我们将这个卷积操作在输入图像上滑动起来，自然地，连接的神经元也向下滑动，连接的权值仍记为w0w_0w0​、w1w_1w1​、w2w_2w2​、w3w_3w3​，如下图所示。此时注意，这个卷积操作要覆盖图像上的所有9个像素，需要滑动四次，因此对应着四个神经元。图像的四部分局部像素与这四个神经元连接时共享同一套权值（简洁地说，这四个神经元共享一套权值），这就是所谓的“权值共享”的概念。这组权值又叫做卷积核。 卷积连接方式使得每个神经元所感知的图像的范围由整张图缩减到了4个像素点，从而减少了权值的数量，又采取了“权值共享”的方法，进一步减少了参数的数量。 允许我们对图像进行卷积操作的理论依据就是图像的局部相关性：卷积神经网络的设计认为每个神经元没必要对全局图像进行感知，只需对局部像素按空间位置进行局部连接即可。 2.4 提取图像特征 卷积层每次用一个卷积核在图像上滑动，来提取图像的某一显著特征。 卷积核可以找到图中和卷积核自身最相似的部分，而且相似度越高，得到的响应值越大。 图7中上面一排的照片是5架战斗机，把其中一架战斗机的图像截出来作为卷积核，与原图像进行卷积，得到结果如下排图像所示。可以看到，每架战斗机所在的位置都得到了一个极大的响应。 因此，通过设置合理的损失函数，在卷积神经网络中使用反向传播算法，最终可以学习到相应于目标结果的卷积核，在Inference的时候就可以提取出有效特征。 2.5 保留空间信息 与全连接网络相比，卷积网络没有将图像展开为一维向量，而是使用卷积核在原图像上滑动来提取特征，因此保留了原图像的局部空间信息。 图7中上面一排右边的照片是由左边照片对5架战斗机平移得到的。经过同样的卷积操作后，得到的特征响应图相当于左边的特征响应图做相应的平移。这是卷积神经网络的局部连接和权值共享带来的“同变性（Equivariance）”[6]，亦是卷积神经网络可以保留图像空间信息的体现。 2.6 卷积操作的补充 卷积核（Filter） 在数学定义上，矩阵的卷积（Convolution）操作为：首先将卷积核进行翻转，构成一个卷积核的镜像，然后使用该镜像和前面矩阵相应位置进行点乘。如下面所示： 步长（Step） 卷积操作每次移动的单位数称为步长。 填充（Padding） 为了控制输出的尺寸，可以采用填充的方法。例如在步长为2的情况下，输出尺寸原为5 * 5，如果想使输出尺寸为3 * 3， 可以在输入外围添加一圈0，在这种情况下，输出的尺寸就是3 * 3。 3. 激活层 激活层算不上卷积神经网络的特色，这里就不详细介绍了，简而言之，激活层的作用就是引入非线性因子，提升模型的表达能力。 4. 池化层 卷积神经网络在卷积层和激活层之后又增加了池化层，用来模拟感受野，以达到选取特征、减少参数数量的作用，同时引入微小平移不变性。 4.1 特征选取 池化的一个功能是对特征的选取，卷积神经网络中常用的有Average Pooling和Maximum Pooling。Average Pooling，即对池化区域内特征点求平均，Maximum Pooling则对池化区域内特征点取最大。Average Pooling更能保留图片的背景信息，如果背景中也含有有效信息，Average Pooling就更合适；Maximum Pooling会忽略背景信息，在有噪声的情况下则更有效。 通过池化，CNN进一步减少了参数数量（降维）。 4.2 微小平移不变性 在局部连接和权值共享的作用下，平移后图像的特征映射图与特征映射图直接做对应的平移得到的结果差别不大，即前面所述的同变性。 此时再进行池化，以Maximum Pooling为例，如下图所示，在左图中得到的池化结果是11，在右图中得到的池化结果也是11，体现了平移不变性。 需要指出的是，池化的平移不变性是有限的，即所说的微小平移不变性。如果平移超出了感受野的位置，平移不变性就难以体现。 5. 分层表达 前已述及，人脑视觉系统存在分层处理的机制，卷积神经网络用多层的网络来模拟人脑视觉系统的分层处理。 通过多层的卷积神经网络，计算机逐步“理解”一幅图像大致遵循这样的过程：像素–&gt;边缘–&gt;基本形状–&gt;复杂图案–&gt;更复杂图案。 例如，在学习一张车的图片时，浅层的卷积层能从最基本的像素中学习到边缘特征，较深层点的可以学习到圆形等基本形状，再经过几层可以学习到轮胎、车身等图案特征，最后可以学习到车的整体特征。 6. 卷积的可视化与解释性 深度学习的解释性学界仍在研究当中。目前对于卷积神经网络，仅能通过可视化提供简单的解释。 6.1 边缘检测 先解释卷积层如何做边缘检测。 图片最常做的边缘检测有两类：垂直边缘（Vertical Edges）检测和水平边缘（Horizontal Edges）检测。 以垂直边缘检测为例，原始灰度图像尺寸为 6x6，卷积核尺寸为 3x3，不做Padding，Stride = 1，卷积后得到的特征映射图尺寸为 4x4，得到结果如下： 在灰度图像中，０代表灰，正值表示白，值越大越白，负值代表黑，值越小越黑。本例的原始图像和卷积后的特征映射图，有图例所示的黑白灰分布，提取出了垂直边缘。 6.2 响应相似图形 这部分可以参考2.4节。 6.3 特征响应图可视化 相关研究[7]中，曾实现了对特征映射图的可视化。直接看一下结果： 目前的研究虽然还是不能完全解释CNN，但是通过可视化，我们发现CNN学习到的特征确实如我们所预期的呈现分层特性，底层是一些边缘角点以及颜色的抽象特征，越到高层则越呈现出具体的特征，与人类视觉系统类似。 7. 卷积神经网络为什么有效 从神经科学角度：卷积神经网络模仿了人脑视觉系统的分层处理机制以及感受野机制； 从统计角度：卷积神经网络抓住了图像的局部相关性（Spatially-local Correlation）； 从正则化的角度：由于局部连接、权值共享和池化，降低了模型参数数量，控制了模型复杂度，可有效避免模型过拟合。 关键词 ： 局部感受野、权值共享、时间/空间亚采样 参考文献 深度学习与计算机视觉——算法原理、框架应用与代码实现 Derivation of Convolutional Neural Network from Fully Connected Network Step-By-Step 卷积神经网络CNN原理详解(一)——基本原理 CNN为什么有效 卷积神经网络为什么具有平移不变性？ 吴恩达 DeepLearning.ai 课程提炼笔记（4-1）卷积神经网络 — 卷积神经网络基础 CNN十大问 CNN中减少网络的参数的三个思想 需要注意的是这些层之间的连接并不一定是简单的逐层连接，例如V2层就与其它层均有连接，对这些层之间连接的进一步研究有可能进一步提升卷积神经网络的效果。 ↩︎ 亦有人称池化同时引入了尺度变换和旋转的不变性，由于其可解释性与效果都不佳，因此认可度不高，在此省略不讲。 ↩︎ 语音和自然语言也是具有局部特征性的数据，CNN也可以用于语音处理与自然语言处理。 ↩︎ 可看作选择15个特征。 ↩︎ 实际上应该是数学上的互相关（Cross-correlation）。在深度学习中，我们使用的卷积运算实则没有卷积核翻转为镜像的这一步操作，因为在权重学习的角度，翻转是没有必要的，互相关与卷积相差的就是核没有翻转，所以深度学习中的卷积操作在数学上准确度来说称为互相关。 ↩︎ 关于 CNN对图像特征的 位移、尺度、形变不变性的理解 ↩︎ Deep Visualization:可视化并理解CNN ↩︎","link":"/2019/01/22/2019-01-22-CNN_in_Detail_Part_I/"},{"title":"Paho MQTT Python客户端常用API、安装与使用","text":"MQTT(Message Queuing Telemetry Transport)是一种轻量级的即时通信协议，相关介绍可见：MQTT简介。 Paho 是Eclipse的开源 MQTT 客户端项目，提供多种语言的 MQTT 客户端实现，包括 C、C++、C#、Java、Python、JavaScript 等。在Python环境下，Paho MQTT Python客户端由paho-mqtt模块支撑。 安装Paho MQTT Python 客户端 Paho MQTT Python 客户端依赖于Python 2.7.9以上版本和Python 3.5以上版本。本文测试环境为Python 3.7.1。 用pip安装paho-mqtt如下： 1pip install paho-mqtt 常用API paho-mqtt主要由三个模块组成：Client模块、Publish模块和Subscribe模块。Publish模块和Subscribe模块使用相对较少，参数含义也与Client模块的publish和subscribe方法的参数类似，本文限于篇幅原因就不介绍了。 Client的基本使用流程 Client的基本使用流程如下： 创建客户端实例 使用 connect*() 函数之一连接到代理 调用 loop*() 函数之一来维护与代理的网络流量 使用 subscribe() 订阅主题并接收消息 使用 publish() 将消息发布到代理 使用 disconnect() 断开与代理的连接 值得注意的是，Client使用过程中存在许多回调，这些回调可以帮助Client处理各种事件，后面我们将详细介绍。 Client类与方法 （1）Client的构建与重置 Client的构建与重置由以下两个方法承担： 12Client(client_id=&quot;&quot;, clean_session=True, userdata=None, protocol=MQTTv311, transport=&quot;tcp&quot;)reinitialise(client_id=&quot;&quot;, clean_session=True, userdata=None) 具体参数说明如下： client_id: 连接到代理时使用的唯一客户端 ID 字符串。如果 client_id 为零长度或 None ，则将随机生成一个。在这种情况下，clean_session 参数必须为 True。 clean_session: 确定客户端类型的布尔值。如果为 True，代理将在断开连接时删除有关此客户端的所有信息。如果为 False，则客户端是持久客户端，并且在客户端断开连接时将保留订阅信息和排队消息。 注意，客户端永远不会在断开连接时丢弃自己的传出消息。调用 connect() 或 reconnect() 将导致消息被重新发送。使用 reinitialise() 将客户端重置为其原始状态。 userdata: 作为 userdata 参数传递给回调的任何类型的用户定义数据。稍后可能会使用 user_data_set() 函数对其进行更新。 protocol: 用于此客户端的 MQTT 协议版本。可以是 MQTTv31 或 MQTTv311 transport: 设置为“websockets”以通过 WebSockets 发送 MQTT。保留默认值“tcp”以使用原始 TCP。 使用示例如下： 12345import paho.mqtt.client as mqtt# 构建一个Clientmqttc = mqtt.Client()# 重置一个Clientmqttc.reinitialise() （2）连接至代理/重新连接/与代理断开连接 相应方法是： 123connect(host, port=1883, keepalive=60, bind_address=&quot;&quot;)reconnect()disconnect() 注意，MQTT的本质是一个用以维护客户端与代理之间的长连接的、并且是低消耗的协议。所以，无论对于代理还是对于客户端，他们都需要清楚地知道二者之间的连接是否断开、而且是正常断开还是非正常断开（正常断开（客户端使用disconnect方法）则不需特别操作；非正常断开情况下，客户端需要尝试重新连接，而代理则需要发送遗嘱）。这一点贯穿与MQTT的协议设计与“连接”这一部分的内容。 具体参数说明如下： host: 远程代理的主机名或 IP 地址 port: 要连接的服务器主机的网络端口。 默认为 1883。请注意，基于 SSL/TLS 的 MQTT 的默认端口为 8883，因此如果您使用 tls_set() 或 tls_set_context()，则可能需要手动提供端口 keepalive: 与代理通信之间允许的最长间隔（以秒为单位）。 如果没有其他消息正在交换，这将控制客户端向代理发送 ping 消息的速率。 需要指出，MQTT协议规定，在 1.5倍的keepalive时间内，如果代理没有收到来自客户端的任何数据包，那么代理将认为它和这个客户端之间的连接已经断开；而如果客户端没有收到来自 代理的任何数据包，那么这个客户端会认为它和代理之间的连接已经断开。为维持正常的连接，如果代理与客户端之间没有其他数据传输，客户端会每隔keepalive时间向代理发送一次ping消息（由loop()来维护）。keepalive的缺省时间是60s。 bind_address: 假设存在多个接口，要将此客户端绑定到的本地网络接口的 IP 地址 使用示例如下： 12345# 已构建一个Client：mqttcmqttc.connect(&quot;mqtt.eclipseprojects.io&quot;) # 使用reconnect与disconnect之前必须已经调用过connectmqttc.reconnect()mqttc.disconnect() 注意这三个方法是阻塞进程的。 （3）网络回路控制 网络回路控制是客户端对传入与发出数据进行控制的背后驱动力，同时也根据客户端的keepalive设置发送ping消息（心跳报文），以刷新连接。如果不调用网络回路方法，则客户端不会处理传入的网络数据，并且可能无法及时发送传出的网络数据。其作用可由下图表示： 相关方法包括： 1234loop(timeout=1.0, max_packets=1)loop_start()loop_stop(force=False)loop_forever(timeout=1.0, max_packets=1, retry_first_connection=False) 包含三套逻辑，一是循环调用loop()阻塞进程：timeout参数定义了loop()阻塞进程的超时时间，而max_packets 参数已过时，应保持未设置。timeout 不得超过客户端的 keepalive 值，否则客户端将被代理定期断开连接。 用例如下： 1234mqttc.connect(&quot;mqtt.eclipseprojects.io&quot;)while True: mqttc.loop(timeout=1.0) # do something else 二是使用loop_start()和loop_stop()创建和停止后台线程，以自动调用loop()。这种方式释放了主线程。 loop_start()可以在connect*() 之前或之后调用。 此调用还处理与代理的重新连接。 调用 loop_stop() 停止后台线程。 force 参数当前被忽略。 定期调用以处理网络事件。 此调用在 select() 中等待，直到网络套接字可用于读取或写入（如果合适），然后处理传入/传出数据。 此函数最多阻塞超时秒。 用例如下： 12345678mqttc.connect(&quot;mqtt.eclipseprojects.io&quot;)mqttc.loop_start()# do something elsewhile True: temperature = sensor.blocking_read() mqttc.publish(&quot;paho/temperature&quot;, temperature)mqttc.loop_stop() 三是使用loop_forever()持续阻塞进程（不需外部循环），连接将维持到客户端调用disconnect()。timeout 和 max_packets 参数已过时，应保持未设置。retry_first_connection=True 使其重试第一次连接。警告：这可能会导致客户端不断连接到不存在的主机而不提示失败的情况。由于主线程被阻塞，其他操作无法在主线程执行，包括disconnect()在内的其他操作都需要通过回调函数来执行。 用例如下： 12mqttc.connect(&quot;mqtt.eclipseprojects.io&quot;)mqttc.loop_forever(retry_first_connection=False) （4）订阅/取消订阅 使客户端订阅到一个或多个主题，或从相应主题退订。 12subscribe(topic, qos=0)unsubscribe(topic) 具体参数说明： topic: 一个字符串，指定要订阅的订阅主题。 qos: 订阅所需的服务质量(quality of service)级别。 默认为 0，可选0，1，2。 用例： 1234mqttc.subscribe((&quot;my/topic&quot;, 1))mqttc.subscribe([(&quot;my/topic&quot;, 0), (&quot;another/topic&quot;, 2)])mqttc.unsubscribe(&quot;my/topic&quot;)mqttc.unsubscribe([&quot;my/topic&quot;, &quot;another/topic&quot;]) （5）发布 发布会使得消息被发送到代理，然后再由代理发送到订阅匹配主题的任何客户端。 相关方法： 1publish(topic, payload=None, qos=0, retain=False) 具体参数说明如下： topic: 消息应该发布到的主题 payload: 要发送的实际消息。 如果没有给出，或者设置为 None 将使用零长度消息。 传递 int 或 float 将导致有效负载转换为表示该数字的字符串。 如果您希望发送真正的 int/float，请使用 struct.pack() 创建您需要的有效负载。 qos: 要使用的服务质量（quality of service）水平，默认为 0，可选0，1，2。 retain: 如果设置为 True，则该消息将被设置为该主题的保留消息。保留消息的作用是使新订阅某个主题的客户端能够收到该主题中上一次发布的消息。 用例如下： 1mqttc.publish(topic=&quot;my/topic&quot;, payload=None, qos=0, retain=True) 回调 回调是在指由某个事件触发相应的处理。七大类回调函数，分别为连接、断开连接、收到消息、发布消息、订阅主题、取消订阅主题、收到日志七类事件提供了处理方法。 （1）连接 on_connect()：当代理响应客户端的连接请求时调用。 1on_connect(client, userdata, flags, rc) 具体参数说明如下： client: 此回调的客户端实例 userdata: 在 Client() 或 user_data_set() 中设置的私有用户数据 flags: 代理发送的响应标志 rc: 连接结果 用例： 12345def on_connect(client, userdata, flags, rc): print(&quot;Connection returned result: &quot;+connack_string(rc))mqttc.on_connect = on_connect... （2）断开连接 on_disconnect()：当客户端与代理断开连接时调用。 1on_disconnect(client, userdata, rc) 具体参数说明如下： client: 此回调的客户端实例 userdata: 在 Client() 或 user_data_set() 中设置的私有用户数据 flags: 代理发送的响应标志 rc: 断开结果 用例： 123456def on_disconnect(client, userdata, rc): if rc != 0: print(&quot;Unexpected disconnection.&quot;)mqttc.on_disconnect = on_disconnect... （3）收到消息 on_message()：当收到客户端订阅的主题的消息并且该消息与现有主题过滤器回调（由message_callback_add()定义）不匹配时调用。 message_callback_add()：当收到客户端订阅的主题的消息并且该消息与现有主题过滤器回调匹配时调用。 message_callback_remove()：删除之前使用message_callback_add()定义的主题过滤器回调 123on_message(client, userdata, message)message_callback_add(sub, callback)message_callback_remove(sub) 具体参数说明如下： client: 此回调的客户端实例 userdata: 在 Client() 或 user_data_set() 中设置的私有用户数据 message: MQTTMessage信息实例，这是一个包含成员 topic、payload、qos、retain 的类。 sub: 特定主题 callback: 定义的callback函数 on_message()用例： 123456def on_message(client, userdata, message): print(&quot;Received message '&quot; + str(message.payload) + &quot;' on topic '&quot; + message.topic + &quot;' with QoS &quot; + str(message.qos))mqttc.on_message = on_message... 另外在举个例子说明下何时使用message_callback_add()，如果客户端订阅了sensors/#系列主题（#为通配符），可能收到消息的主题有sensors/temperature和sensors/humidity，则可以使用message_callback_add()定义两个主题过滤器回调，分别处理这两个主题下收到的消息。 12345678910def temperature_callback(client, userdata, message): ...def humidity_callback(client, userdata, message): ...mqttclient.message_callback_add(&quot;sensors/temperature&quot;, temperature_callback)mqttc.message_callback_add(&quot;sensors/humidity&quot;, humidity_callback)mqttc.subscribe(&quot;sensors/#&quot;) （4）发布消息 on_publish()： 1on_publish(client, userdata, mid) （5）订阅主题 on_subscribe()：当代理响应订阅请求时调用。 1on_subscribe(client, userdata, mid, granted_qos) （6）取消订阅 on_unsubscribe()：当代理响应取消订阅请求时调用。 1on_unsubscribe(client, userdata, mid) （7）收到日志 on_log()：当客户端有日志信息时调用。 定义该回调可用于调试。 级别变量给出消息的严重性，将是 MQTT_LOG_INFO、MQTT_LOG_NOTICE、MQTT_LOG_WARNING、MQTT_LOG_ERR 和 MQTT_LOG_DEBUG 之一。 1on_log(client, userdata, level, buf) 参考资料 Paho Python Client Documentation Paho MQTT Python GitHub Repository Steve’s Internet Guide","link":"/2021/10/10/2021-10-10-Paho_MQTT_Python_Client_API_and_Usage/"}],"tags":[{"name":"Computer","slug":"Computer","link":"/tags/Computer/"},{"name":"Operation&amp;Maintenance","slug":"Operation-Maintenance","link":"/tags/Operation-Maintenance/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","link":"/tags/Raspberry-Pi/"},{"name":"CNN","slug":"CNN","link":"/tags/CNN/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"Forward Proxy","slug":"Forward-Proxy","link":"/tags/Forward-Proxy/"},{"name":"Reverse Proxy","slug":"Reverse-Proxy","link":"/tags/Reverse-Proxy/"},{"name":"Proxy","slug":"Proxy","link":"/tags/Proxy/"},{"name":"DNS","slug":"DNS","link":"/tags/DNS/"},{"name":"IoT","slug":"IoT","link":"/tags/IoT/"},{"name":"Wireless Sensor Networks","slug":"Wireless-Sensor-Networks","link":"/tags/Wireless-Sensor-Networks/"},{"name":"InfluxDB","slug":"InfluxDB","link":"/tags/InfluxDB/"},{"name":"Grafana","slug":"Grafana","link":"/tags/Grafana/"},{"name":"Penetration","slug":"Penetration","link":"/tags/Penetration/"},{"name":"Port Forwarding","slug":"Port-Forwarding","link":"/tags/Port-Forwarding/"},{"name":"NAT","slug":"NAT","link":"/tags/NAT/"},{"name":"Tunnel","slug":"Tunnel","link":"/tags/Tunnel/"},{"name":"Complexity","slug":"Complexity","link":"/tags/Complexity/"},{"name":"NPC","slug":"NPC","link":"/tags/NPC/"},{"name":"NP-Hard","slug":"NP-Hard","link":"/tags/NP-Hard/"},{"name":"P&#x3D;NP?","slug":"P-NP","link":"/tags/P-NP/"},{"name":"VS Code","slug":"VS-Code","link":"/tags/VS-Code/"},{"name":"User Snippets","slug":"User-Snippets","link":"/tags/User-Snippets/"},{"name":"Settings Sync","slug":"Settings-Sync","link":"/tags/Settings-Sync/"},{"name":"Neural Networks","slug":"Neural-Networks","link":"/tags/Neural-Networks/"},{"name":"Implementations","slug":"Implementations","link":"/tags/Implementations/"},{"name":"TensorFlow2","slug":"TensorFlow2","link":"/tags/TensorFlow2/"},{"name":"JupyterLab","slug":"JupyterLab","link":"/tags/JupyterLab/"},{"name":"Jupyter","slug":"Jupyter","link":"/tags/Jupyter/"},{"name":"Debug","slug":"Debug","link":"/tags/Debug/"},{"name":"Pre-trained Language Model","slug":"Pre-trained-Language-Model","link":"/tags/Pre-trained-Language-Model/"},{"name":"Language Modeling","slug":"Language-Modeling","link":"/tags/Language-Modeling/"},{"name":"MQTT","slug":"MQTT","link":"/tags/MQTT/"},{"name":"Python","slug":"Python","link":"/tags/Python/"}],"categories":[{"name":"Computer","slug":"Computer","link":"/categories/Computer/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/categories/Deep-Learning/"},{"name":"Linux","slug":"Computer/Linux","link":"/categories/Computer/Linux/"},{"name":"Basics of Computers","slug":"Computer/Basics-of-Computers","link":"/categories/Computer/Basics-of-Computers/"},{"name":"Neural Networks","slug":"Deep-Learning/Neural-Networks","link":"/categories/Deep-Learning/Neural-Networks/"},{"name":"Raspberry Pi","slug":"Raspberry-Pi","link":"/categories/Raspberry-Pi/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"Deployment","slug":"Deep-Learning/Deployment","link":"/categories/Deep-Learning/Deployment/"},{"name":"Tools","slug":"Tools","link":"/categories/Tools/"},{"name":"CNN Special Column","slug":"Deep-Learning/Neural-Networks/CNN-Special-Column","link":"/categories/Deep-Learning/Neural-Networks/CNN-Special-Column/"},{"name":"IoT","slug":"IoT","link":"/categories/IoT/"},{"name":"Mathematics","slug":"Algorithm/Mathematics","link":"/categories/Algorithm/Mathematics/"},{"name":"Wireless Sensor Networks","slug":"IoT/Wireless-Sensor-Networks","link":"/categories/IoT/Wireless-Sensor-Networks/"},{"name":"Demo","slug":"Demo","link":"/categories/Demo/"},{"name":"Implementations","slug":"Deep-Learning/Neural-Networks/Implementations","link":"/categories/Deep-Learning/Neural-Networks/Implementations/"},{"name":"NLP","slug":"NLP","link":"/categories/NLP/"},{"name":"MQTT","slug":"IoT/MQTT","link":"/categories/IoT/MQTT/"},{"name":"PTM Special Column","slug":"NLP/PTM-Special-Column","link":"/categories/NLP/PTM-Special-Column/"},{"name":"Python","slug":"Python","link":"/categories/Python/"}]}