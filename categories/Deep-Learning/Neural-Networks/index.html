<!doctype html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta><title>Category: Neural Networks - Forskamse&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Forskamse&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Forskamse&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Forskamse&#039;s Blog"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="Forskamse&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="Forskamse"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Forskamse's Blog","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Forskamse"},"publisher":{"@type":"Organization","name":"Forskamse's Blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.png"}},"description":""}</script><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Forskamse's Blog" type="application/atom+xml"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Forskamse&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li><a href="/categories/Deep-Learning/">Deep Learning</a></li><li class="is-active"><a href="#" aria-current="page">Neural Networks</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time datetime="2019-01-22T06:00:00.000Z" title="2019/1/22下午2:00:00">2019-01-22</time></span><span class="level-item">Updated&nbsp;<time datetime="2021-06-12T10:52:37.918Z" title="2021/6/12下午6:52:37">2021-06-12</time></span><span class="level-item"> Forskamse </span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/Neural-Networks/">Neural Networks</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/Neural-Networks/CNN-Special-Column/">CNN Special Column</a></span><span class="level-item">27 minutes read (About 3978 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/01/22/2019-01-22-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3(%E4%B8%80)%E2%80%94%E2%80%94%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">卷积神经网络详解(一)——基础知识</a></h1><div class="content"><h2 id="1-卷积神经网络的组成"><a href="#1-卷积神经网络的组成" class="headerlink" title="1. 卷积神经网络的组成"></a>1. 卷积神经网络的组成</h2><p>1981年诺贝尔医学奖得主，神经生物学家David Hubel 和Torsten Wiesel对人脑视觉系统的研究表明：人脑视觉系统首先通过眼睛来成像，图像通过瞳孔、晶状体最终在视网膜上成像。视网膜上布满了大量的光感受细胞，可以把光刺激转换为神经冲动，神经冲动通过视觉通路传递到大脑的初级视觉皮层（Primary Visual Cortex，V1），V1初步处理得到边缘、方向等特征信息，而后经由V2的进一步抽象得到轮廓、形状等特征信息，如此迭代地经由多层（V1层至V5层）的抽象后得到高层特征。高层特征是低层特征的组合<a href="%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E6%98%AF%E8%BF%99%E4%BA%9B%E5%B1%82%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BF%9E%E6%8E%A5%E5%B9%B6%E4%B8%8D%E4%B8%80%E5%AE%9A%E6%98%AF%E7%AE%80%E5%8D%95%E7%9A%84%E9%80%90%E5%B1%82%E8%BF%9E%E6%8E%A5%EF%BC%8C%E4%BE%8B%E5%A6%82V2%E5%B1%82%E5%B0%B1%E4%B8%8E%E5%85%B6%E5%AE%83%E5%B1%82%E5%9D%87%E6%9C%89%E8%BF%9E%E6%8E%A5%EF%BC%8C%E5%AF%B9%E8%BF%99%E4%BA%9B%E5%B1%82%E4%B9%8B%E9%97%B4%E8%BF%9E%E6%8E%A5%E7%9A%84%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%A0%94%E7%A9%B6%E6%9C%89%E5%8F%AF%E8%83%BD%E8%BF%9B%E4%B8%80%E6%AD%A5%E6%8F%90%E5%8D%87%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%95%88%E6%9E%9C%E3%80%82">^5</a>，从低层特征到高层特征的抽象过程中，语义的表现越来越清晰，存在的歧义越来越少，对目标的识别也就越来越精确。这就是人脑视觉系统的分层处理机制。</p><p>视觉皮层上的细胞有简单细胞（Simple Cell）与复杂细胞（Complex Cell）之分，这两种细胞的共同点是他们都只对特定方向的条形图样刺激有反应，而他们的主要区别是简单细胞对应的视网膜上的光感受细胞所在的区域比复杂细胞所对应的区域来得小，这个区域被称为感受野（Receptive Field）。这就是人脑视觉系统的感受野机制。</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190121231252850_1844689380.png"></div><p>1980年，日本学者Kunihiko Fukushima提出感知机模型（Neocognitron），提出使用卷积层来模拟视觉细胞对特定图案的反应、使用池化层模拟感受野的方法。卷积神经网络的设计深受这个方法的影响，其基本结构为：</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190107202305429_94794149.png"></div><p>具体说来，卷积层用于提取不同的图像特征，有减少参数数量、保留空间信息的作用；池化层用于模拟感受野，有选取特征、减少参数数量的作用，同时引入微小平移不变性<a href="%E4%BA%A6%E6%9C%89%E4%BA%BA%E7%A7%B0%E6%B1%A0%E5%8C%96%E5%90%8C%E6%97%B6%E5%BC%95%E5%85%A5%E4%BA%86%E5%B0%BA%E5%BA%A6%E5%8F%98%E6%8D%A2%E5%92%8C%E6%97%8B%E8%BD%AC%E7%9A%84%E4%B8%8D%E5%8F%98%E6%80%A7%EF%BC%8C%E7%94%B1%E4%BA%8E%E5%85%B6%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%E4%B8%8E%E6%95%88%E6%9E%9C%E9%83%BD%E4%B8%8D%E4%BD%B3%EF%BC%8C%E5%9B%A0%E6%AD%A4%E8%AE%A4%E5%8F%AF%E5%BA%A6%E4%B8%8D%E9%AB%98%EF%BC%8C%E5%9C%A8%E6%AD%A4%E7%9C%81%E7%95%A5%E4%B8%8D%E8%AE%B2%E3%80%82">^1</a>；而激活层的设置则是为了引入非线性因子，提升模型的表达能力，这是神经网络中普遍采用的。</p><h2 id="2-卷积层"><a href="#2-卷积层" class="headerlink" title="2. 卷积层"></a>2. 卷积层</h2><h3 id="2-1-图像的局部相关性"><a href="#2-1-图像的局部相关性" class="headerlink" title="2.1 图像的局部相关性"></a>2.1 图像的局部相关性</h3><p>图像是具有局部相关性的一类数据<a href="%E8%AF%AD%E9%9F%B3%E5%92%8C%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E4%B9%9F%E6%98%AF%E5%85%B7%E6%9C%89%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81%E6%80%A7%E7%9A%84%E6%95%B0%E6%8D%AE%EF%BC%8CCNN%E4%B9%9F%E5%8F%AF%E4%BB%A5%E7%94%A8%E4%BA%8E%E8%AF%AD%E9%9F%B3%E5%A4%84%E7%90%86%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E3%80%82">^3</a>，其局部相关性是指组成图像的每个像素点与其周围的像素点是有关联的，而图像上距离较远的像素相关性较弱，因此处理图像时实际上没必要每个神经元都对全局图像进行感知。</p><h3 id="2-2-全连接网络用于图像处理"><a href="#2-2-全连接网络用于图像处理" class="headerlink" title="2.2 全连接网络用于图像处理"></a>2.2 全连接网络用于图像处理</h3><p>以MNIST手写数字识别为例，该数据集中的图像为（28，28，1）的灰度图像，这个图像由28 * 28个像素点（Pixel）构成，每个像素点有一个通道（Channel）。如果使用全连接网络（即网络中的神经元与相邻层上的每个神经元均连接），那么输入层有28 * 28 =784个神经元，假设hidden层采用了15个神经元<a href="%E5%8F%AF%E7%9C%8B%E4%BD%9C%E9%80%89%E6%8B%A915%E4%B8%AA%E7%89%B9%E5%BE%81%E3%80%82">^2</a>，输出层是10个神经元，那么参数个数(w和b)就有：784 * 15 * 10+15+10=117625个。即使在这种情况下，参数量都十分庞大了，如果输入图像的像素点更多、全连接网络的隐藏层层数更多、隐藏层神经元数量更多，参数量就会更加庞大。<br>大量的参数很容易导致网络过拟合，而且每进行一次反向传播计算量都是巨大的，无论从调参还是计算资源的角度都不建议用全连接网络做图像处理。此外，全连接网络认为“每个输入值都是平等的”，它将输入视为一维向量，并不关心这个像素是第几行、第几列的像素，忽视了空间信息，用于图像这种具有空间局部相关性的数据也是不合适的。</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/1546681571_28983.png"></div><h3 id="2-3-减少参数数量"><a href="#2-3-减少参数数量" class="headerlink" title="2.3 减少参数数量"></a>2.3 减少参数数量</h3><p>在图像局部相关性的支撑下，卷积连接应用而生。<br>为简化说明，来看一个简单的例子：<br>在下面的这张图中，输入为3 * 3 = 9个像素，如果将其与16个隐藏层神经元全连接，就会有9 * 16 = 144个连接，也就有144个权值。</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190112180923731_700883300.png"></div><p>为减少连接数，并且基于图像局部相关性的假设，可以仅取四个位置相近（注意图像的Width和Height两个维度）的像素作为输入，四个像素与同一个神经元进行连接，连接的权值记为$w_0$、$w_1$、$w_2$、$w_3$， 如下图所示。</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190112181611409_233506424.png"></div><p>这种连接方式又可看作是数学上的卷积操作<a href="%E5%AE%9E%E9%99%85%E4%B8%8A%E5%BA%94%E8%AF%A5%E6%98%AF%E6%95%B0%E5%AD%A6%E4%B8%8A%E7%9A%84%E4%BA%92%E7%9B%B8%E5%85%B3%EF%BC%88Cross-correlation%EF%BC%89%E3%80%82%E5%9C%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%EF%BC%8C%E6%88%91%E4%BB%AC%E4%BD%BF%E7%94%A8%E7%9A%84%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97%E5%AE%9E%E5%88%99%E6%B2%A1%E6%9C%89%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%BF%BB%E8%BD%AC%E4%B8%BA%E9%95%9C%E5%83%8F%E7%9A%84%E8%BF%99%E4%B8%80%E6%AD%A5%E6%93%8D%E4%BD%9C%EF%BC%8C%E5%9B%A0%E4%B8%BA%E5%9C%A8%E6%9D%83%E9%87%8D%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%A7%92%E5%BA%A6%EF%BC%8C%E7%BF%BB%E8%BD%AC%E6%98%AF%E6%B2%A1%E6%9C%89%E5%BF%85%E8%A6%81%E7%9A%84%EF%BC%8C%E4%BA%92%E7%9B%B8%E5%85%B3%E4%B8%8E%E5%8D%B7%E7%A7%AF%E7%9B%B8%E5%B7%AE%E7%9A%84%E5%B0%B1%E6%98%AF%E6%A0%B8%E6%B2%A1%E6%9C%89%E7%BF%BB%E8%BD%AC%EF%BC%8C%E6%89%80%E4%BB%A5%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C%E5%9C%A8%E6%95%B0%E5%AD%A6%E4%B8%8A%E5%87%86%E7%A1%AE%E5%BA%A6%E6%9D%A5%E8%AF%B4%E7%A7%B0%E4%B8%BA%E4%BA%92%E7%9B%B8%E5%85%B3%E3%80%82">^4</a>，其中这一组权值就被称为卷积核， 如下图右图所示，因此得名卷积连接。</p><p>我们将这个卷积操作在输入图像上滑动起来，自然地，连接的神经元也向下滑动，连接的权值仍记为$w_0$、$w_1$、$w_2$、$w_3$，如下图所示。此时注意，这个卷积操作要覆盖图像上的所有9个像素，需要滑动四次，因此对应着四个神经元。图像的四部分局部像素与这四个神经元连接时共享同一套权值（简洁地说，这四个神经元共享一套权值），这就是所谓的“权值共享”的概念。这组权值又叫做卷积核。</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190112183300720_471577742.png"></div><p>卷积连接方式使得每个神经元所感知的图像的范围由整张图缩减到了4个像素点，从而减少了权值的数量，又采取了“权值共享”的方法，进一步减少了参数的数量。</p><p>允许我们对图像进行卷积操作的理论依据就是图像的局部相关性：卷积神经网络的设计认为每个神经元没必要对全局图像进行感知，只需对局部像素按空间位置进行局部连接即可。</p><h3 id="2-4-提取图像特征"><a href="#2-4-提取图像特征" class="headerlink" title="2.4 提取图像特征"></a>2.4 提取图像特征</h3><p>卷积层每次用一个卷积核在图像上滑动，来提取图像的某一显著特征。<br>卷积核可以找到图中和卷积核自身最相似的部分，而且相似度越高，得到的响应值越大。</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190122174325180_288459116.png"></div><p>图7中上面一排的照片是5架战斗机，把其中一架战斗机的图像截出来作为卷积核，与原图像进行卷积，得到结果如下排图像所示。可以看到，每架战斗机所在的位置都得到了一个极大的响应。<br>因此，通过设置合理的损失函数，在卷积神经网络中使用反向传播算法，最终可以学习到相应于目标结果的卷积核，在Inference的时候就可以提取出有效特征。</p><h3 id="2-5-保留空间信息"><a href="#2-5-保留空间信息" class="headerlink" title="2.5 保留空间信息"></a>2.5 保留空间信息</h3><p>与全连接网络相比，卷积网络没有将图像展开为一维向量，而是使用卷积核在原图像上滑动来提取特征，因此保留了原图像的局部空间信息。<br>图7中上面一排右边的照片是由左边照片对5架战斗机平移得到的。经过同样的卷积操作后，得到的特征响应图相当于左边的特征响应图做相应的平移。这是卷积神经网络的局部连接和权值共享带来的“同变性（Equivariance）”[^7]，亦是卷积神经网络可以保留图像空间信息的体现。</p><p>[^7]: <a target="_blank" rel="noopener" href="https://blog.csdn.net/voxel_grid/article/details/79275637#annotations:l5eZ9BJ8EemTjb9M9uq6Mw">关于 CNN对图像特征的 位移、尺度、形变不变性的理解</a></p><h3 id="2-6-卷积操作的补充"><a href="#2-6-卷积操作的补充" class="headerlink" title="2.6 卷积操作的补充"></a>2.6 卷积操作的补充</h3><ol><li>卷积核（Filter）</li></ol><p>在数学定义上，矩阵的卷积（Convolution）操作为：首先将卷积核进行翻转，构成一个卷积核的镜像，然后使用该镜像和前面矩阵相应位置进行点乘。如下面所示：</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/1546851390_24790.png"></div><ol start="2"><li>步长（Step）</li></ol><p>卷积操作每次移动的单位数称为步长。</p><ol start="3"><li>填充（Padding）<br>为了控制输出的尺寸，可以采用填充的方法。例如在步长为2的情况下，输出尺寸原为5 * 5，如果想使输出尺寸为3 * 3， 可以在输入外围添加一圈0，在这种情况下，输出的尺寸就是3 * 3。</li></ol><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190107180531456_2081156539.png"></div><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190112180202610_1822722602.png"></div><h2 id="3-激活层"><a href="#3-激活层" class="headerlink" title="3. 激活层"></a>3. 激活层</h2><p>激活层算不上卷积神经网络的特色，这里就不详细介绍了，简而言之，激活层的作用就是引入非线性因子，提升模型的表达能力。</p><h2 id="4-池化层"><a href="#4-池化层" class="headerlink" title="4. 池化层"></a>4. 池化层</h2><p>卷积神经网络在卷积层和激活层之后又增加了池化层，用来模拟感受野，以达到选取特征、减少参数数量的作用，同时引入微小平移不变性。</p><h3 id="4-1-特征选取"><a href="#4-1-特征选取" class="headerlink" title="4.1 特征选取"></a>4.1 特征选取</h3><p>池化的一个功能是对特征的选取，卷积神经网络中常用的有Average Pooling和Maximum Pooling。Average Pooling，即对池化区域内特征点求平均，Maximum Pooling则对池化区域内特征点取最大。Average Pooling更能保留图片的背景信息，如果背景中也含有有效信息，Average Pooling就更合适；Maximum Pooling会忽略背景信息，在有噪声的情况下则更有效。<br>通过池化，CNN进一步减少了参数数量（降维）。</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/1540565865_21442.png"></div><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/1540565888_8954.png"></div><h3 id="4-2-微小平移不变性"><a href="#4-2-微小平移不变性" class="headerlink" title="4.2 微小平移不变性"></a>4.2 微小平移不变性</h3><p>在局部连接和权值共享的作用下，平移后图像的特征映射图与特征映射图直接做对应的平移得到的结果差别不大，即前面所述的同变性。</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190107204820550_1059782468.png"></div>此时再进行池化，以Maximum Pooling为例，如下图所示，在左图中得到的池化结果是11，在右图中得到的池化结果也是11，体现了平移不变性。<div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190108100749906_1800606002.png"></div>需要指出的是，池化的平移不变性是有限的，即所说的微小平移不变性。如果平移超出了感受野的位置，平移不变性就难以体现。<h2 id="5-分层表达"><a href="#5-分层表达" class="headerlink" title="5. 分层表达"></a>5. 分层表达</h2><p>前已述及，人脑视觉系统存在分层处理的机制，卷积神经网络用多层的网络来模拟人脑视觉系统的分层处理。<br>通过多层的卷积神经网络，计算机逐步“理解”一幅图像大致遵循这样的过程：像素–&gt;边缘–&gt;基本形状–&gt;复杂图案–&gt;更复杂图案。<br>例如，在学习一张车的图片时，浅层的卷积层能从最基本的像素中学习到边缘特征，较深层点的可以学习到圆形等基本形状，再经过几层可以学习到轮胎、车身等图案特征，最后可以学习到车的整体特征。</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190108113541696_1346990095.png"></div><h2 id="6-卷积的可视化与解释性"><a href="#6-卷积的可视化与解释性" class="headerlink" title="6. 卷积的可视化与解释性"></a>6. 卷积的可视化与解释性</h2><p>深度学习的解释性学界仍在研究当中。目前对于卷积神经网络，仅能通过可视化提供简单的解释。</p><h3 id="6-1-边缘检测"><a href="#6-1-边缘检测" class="headerlink" title="6.1 边缘检测"></a>6.1 边缘检测</h3><p>先解释卷积层如何做边缘检测。<br>图片最常做的边缘检测有两类：垂直边缘（Vertical Edges）检测和水平边缘（Horizontal Edges）检测。</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190108120127391_1249309616.png"></div><p>以垂直边缘检测为例，原始灰度图像尺寸为 6x6，卷积核尺寸为 3x3，不做Padding，Stride = 1，卷积后得到的特征映射图尺寸为 4x4，得到结果如下：</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190108142020333_337721441.png"></div>在灰度图像中，０代表灰，正值表示白，值越大越白，负值代表黑，值越小越黑。本例的原始图像和卷积后的特征映射图，有图例所示的黑白灰分布，提取出了垂直边缘。<h3 id="6-2-响应相似图形"><a href="#6-2-响应相似图形" class="headerlink" title="6.2 响应相似图形"></a>6.2 响应相似图形</h3><p>这部分可以参考2.4节。</p><h3 id="6-3-特征响应图可视化"><a href="#6-3-特征响应图可视化" class="headerlink" title="6.3 特征响应图可视化"></a>6.3 特征响应图可视化</h3><p>相关研究[^6]中，曾实现了对特征映射图的可视化。直接看一下结果：</p><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190108144217752_522028051.png"></div><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190108144230894_1788507434.png"></div><div align="center"><img src="https://raw.githubusercontent.com/forskamse/forskamse-open-images/main/blog/Jan_2019/CNN_Basics_P1/20190108144335133_1669012016.png"></div>目前的研究虽然还是不能完全解释CNN，但是通过可视化，我们发现CNN学习到的特征确实如我们所预期的呈现分层特性，底层是一些边缘角点以及颜色的抽象特征，越到高层则越呈现出具体的特征，与人类视觉系统类似。<p>[^6]: <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/24833574">Deep Visualization:可视化并理解CNN</a></p><h2 id="7-卷积神经网络为什么有效"><a href="#7-卷积神经网络为什么有效" class="headerlink" title="7. 卷积神经网络为什么有效"></a>7. 卷积神经网络为什么有效</h2><ol><li>从神经科学角度：卷积神经网络模仿了人脑视觉系统的分层处理机制以及感受野机制；</li><li>从统计角度：卷积神经网络抓住了图像的局部相关性（Spatially-local Correlation）；</li><li>从正则化的角度：由于局部连接、权值共享和池化，降低了模型参数数量，控制了模型复杂度，可有效避免模型过拟合。</li></ol><p><strong>关键词 ： 局部感受野、权值共享、时间/空间亚采样</strong></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://book.douban.com/subject/27125397/">深度学习与计算机视觉——算法原理、框架应用与代码实现</a><br><a target="_blank" rel="noopener" href="https://www.linkedin.com/pulse/derivation-convolutional-neural-network-from-fully-connected-gad">Derivation of Convolutional Neural Network from Fully Connected Network Step-By-Step</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/charlotte77/p/7759802.html">卷积神经网络CNN原理详解(一)——基本原理</a><br><a target="_blank" rel="noopener" href="https://lguduy.github.io//2017/07/02/CNN%E4%B8%BA%E4%BB%80%E4%B9%88work/#annotations:EasaThA1EemS5wtu41br7w">CNN为什么有效</a><br><a target="_blank" rel="noopener" href="https://zhangting2020.github.io/2018/05/30/Transform-Invariance/">卷积神经网络为什么具有平移不变性？</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/30800318">吴恩达 DeepLearning.ai 课程提炼笔记（4-1）卷积神经网络 — 卷积神经网络基础</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhang2012liang/article/details/52687498">CNN十大问</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hejunlin1992/p/7583444.html">CNN中减少网络的参数的三个思想</a></p></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time datetime="2018-06-20T06:00:00.000Z" title="2018/6/20下午2:00:00">2018-06-20</time></span><span class="level-item">Updated&nbsp;<time datetime="2021-06-12T10:31:49.997Z" title="2021/6/12下午6:31:49">2021-06-12</time></span><span class="level-item"> Forskamse </span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/Neural-Networks/">Neural Networks</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/Neural-Networks/CNN-Special-Column/">CNN Special Column</a></span><span class="level-item">5 minutes read (About 782 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2018/06/20/2018-06-20-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%87%8D%E8%A6%81%E8%AE%BA%E6%96%87%E8%B5%84%E6%BA%90%E5%90%88%E8%BE%91/">卷积神经网络重要论文资源合辑</a></h1><div class="content"><h2 id="卷积神经网络的前身与早期发展："><a href="#卷积神经网络的前身与早期发展：" class="headerlink" title="卷积神经网络的前身与早期发展："></a><strong>卷积神经网络的前身与早期发展：</strong></h2><ul><li><strong>1980年日本学者福岛邦彦（Kunihiko Fukushima）提出的神经认知机模型（Neocognitron）</strong><br>Fukushima K, Miyake S. Neocognitron: A self-organizing neural network model for a mechanism of visual pattern recognition[M].Competition and cooperation in neural nets. Springer, Berlin, Heidelberg, 1982: 267-285.</li><li><strong>1989年Yann LeCun提出第一个真正意义上的CNN：LeNet 1989</strong><br>LeCun Y, Boser B, Denker J S, et al. Backpropagation applied to handwritten zip code recognition[J]. Neural computation, 1989, 1(4): 541-551.</li><li><strong>1998年Yann LeCun在其博士论文中详细介绍了LeNet（又称LeNet-5），影响力巨大</strong><br>LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324.</li></ul><h2 id="2012年以来卷积神经网络迎来迅猛发展阶段："><a href="#2012年以来卷积神经网络迎来迅猛发展阶段：" class="headerlink" title="2012年以来卷积神经网络迎来迅猛发展阶段："></a><strong>2012年以来卷积神经网络迎来迅猛发展阶段：</strong></h2><ul><li><strong>2012年ILSVRC冠军：AlexNet，掀起深度学习计算机视觉狂潮</strong><br>Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C].Advances in neural information processing systems. 2012: 1097-1105.</li><li><strong>2013年ILSVRC冠军：ZFNet</strong><br>Zeiler M D, Fergus R. Visualizing and understanding convolutional networks[C].European conference on computer vision. Springer, Cham, 2014: 818-833.</li><li><strong>2014年ILSVRC冠军：GoogLeNet，提出Inception结构</strong><br>Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]. Cvpr, 2015.</li><li><strong>2014年ILSVRC亚军：VGGNet，亮点是对网络深度的研究</strong><br>Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.</li><li><strong>2015年ILSVRC冠军：ResNet，提出Residual结构</strong><br>He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C].Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.</li></ul><h2 id="卷积神经网络结合改进与瓶颈阶段："><a href="#卷积神经网络结合改进与瓶颈阶段：" class="headerlink" title="卷积神经网络结合改进与瓶颈阶段："></a><strong>卷积神经网络结合改进与瓶颈阶段：</strong></h2><p><em><strong>合理结合Inception结构与Residual结构的卷积神经网络已经能够达到令人满意的特征提取效果，但是在解释性上却没有更深一步进展。</strong></em></p><ul><li><strong>2016年Google团队结合了Inception结构与Residual 结构，提出Inception-Residual Net</strong><br>Szegedy C, Ioffe S, Vanhoucke V, et al. Inception-v4, inception-resnet and the impact of residual connections on learning[C].AAAI. 2017, 4: 12.</li><li><strong>2016年何凯明提出新的ResNet的想法：Identity Mapping</strong><br>He K, Zhang X, Ren S, et al. Identity mappings in deep residual networks[C].European Conference on Computer Vision. Springer, Cham, 2016: 630-645.</li><li><strong>2017年DenseNet</strong><br>Huang G, Liu Z, Weinberger K Q, et al. Densely connected convolutional networks[C].Proceedings of the IEEE conference on computer vision and pattern recognition. 2017, 1(2): 3.</li></ul><h2 id="轻量级卷积神经网络发展阶段："><a href="#轻量级卷积神经网络发展阶段：" class="headerlink" title="轻量级卷积神经网络发展阶段："></a><strong>轻量级卷积神经网络发展阶段：</strong></h2><p><em><strong>2016年以来，卷积神经网络开始往轻量化发展，为视觉深度学习模型在移动设备上的应用提供条件。</strong></em></p><ul><li><strong>2016年MobileNet</strong><br>Howard A G, Zhu M, Chen B, et al. Mobilenets: Efficient convolutional neural networks for mobile vision applications[J]. arXiv preprint arXiv:1704.04861, 2017.</li><li><strong>2016年ShuffleNet</strong><br>Zhang X, Zhou X, Lin M, et al. Shufflenet: An extremely efficient convolutional neural network for mobile devices[J]. arXiv preprint arXiv:1707.01083, 2017.</li><li><strong>2016年Xception</strong>【注：Xception目标并不是使卷积神经网络轻量化，而是在不增加网络复杂度的情况下提升性能，但其中使用的depthwise convolution思想是MobileNet等轻量级卷积神经网络的关键，故也列在这里】<br>Chollet F. Xception: Deep learning with depthwise separable convolutions[J]. arXiv preprint, 2017: 1610.02357.</li><li><strong>2016年ResNeXt</strong>【注：ResNeXt也是为了在不增加网络复杂度的情况下提升性能，列在此处的原因与Xception相同】<br>Xie S, Girshick R, Dollár P, et al. Aggregated residual transformations for deep neural networks[C].Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. IEEE, 2017: 5987-5995.</li></ul><p><strong>论文合集GitHub地址：<a target="_blank" rel="noopener" href="https://github.com/forskamse/CNN">CNN-Papers</a></strong></p></div></article></div></div><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Forskamse"></figure><p class="title is-size-4 is-block" style="line-height:inherit">Forskamse</p><p class="is-size-6 is-block">MSc in ECE</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Macau, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">5</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/forskamse" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/forskamse"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="CSDN" href="/forskamse.blog.csdn.net"><i class="fab fa-cuttlefish"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:forskamse@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://skliotsc.um.edu.mo/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">SKL-IOTSC(UM)</span></span><span class="level-right"><span class="level-item tag">skliotsc.um.edu.mo</span></span></a></li><li><a class="level is-mobile" href="https://um.edu.mo/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">University of Macau</span></span><span class="level-right"><span class="level-item tag">um.edu.mo</span></span></a></li><li><a class="level is-mobile" href="https://sisse.jnu.edu.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">SISSE(JNU)</span></span><span class="level-right"><span class="level-item tag">sisse.jnu.edu.cn</span></span></a></li><li><a class="level is-mobile" href="https://jnu.edu.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Jinan University</span></span><span class="level-right"><span class="level-item tag">jnu.edu.cn</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Computer/"><span class="level-start"><span class="level-item">Computer</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Computer/Basics-of-Computers/"><span class="level-start"><span class="level-item">Basics of Computers</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Computer/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Deployment/"><span class="level-start"><span class="level-item">Deployment</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Neural-Networks/"><span class="level-start"><span class="level-item">Neural Networks</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Neural-Networks/CNN-Special-Column/"><span class="level-start"><span class="level-item">CNN Special Column</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/Raspberry-Pi/"><span class="level-start"><span class="level-item">Raspberry Pi</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time datetime="2019-01-22T06:00:00.000Z">2019-01-22</time></p><p class="title"><a href="/2019/01/22/2019-01-22-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3(%E4%B8%80)%E2%80%94%E2%80%94%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">卷积神经网络详解(一)——基础知识</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a> / <a href="/categories/Deep-Learning/Neural-Networks/">Neural Networks</a> / <a href="/categories/Deep-Learning/Neural-Networks/CNN-Special-Column/">CNN Special Column</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2018-07-24T08:27:57.000Z">2018-07-24</time></p><p class="title"><a href="/2018/07/24/2018-07-24-%E6%89%93%E5%8C%85TensorFlow%20Object%20Detection%20API/">打包TensorFlow Object Detection API</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a> / <a href="/categories/Deep-Learning/Deployment/">Deployment</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2018-07-21T08:37:57.000Z">2018-07-21</time></p><p class="title"><a href="/2018/07/21/2018-07-12-Linux%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2%E6%9C%8D%E5%8A%A1%E5%8F%8A%E5%85%B6%E5%9C%A8%E6%A0%91%E8%8E%93%E6%B4%BE%E4%B8%8A%E7%9A%84%E4%BD%BF%E7%94%A8/">Linux远程桌面服务VNC/XRDP/Xdmcp/SSH+X11转发及其在树莓派上的使用</a></p><p class="categories"><a href="/categories/Computer/">Computer</a> / <a href="/categories/Computer/Linux/">Linux</a> / <a href="/categories/Raspberry-Pi/">Raspberry Pi</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2018-07-21T08:37:57.000Z">2018-07-21</time></p><p class="title"><a href="/2018/07/21/2018-07-21-%E7%A3%81%E7%9B%98%E7%9F%A5%E8%AF%86/">磁盘知识</a></p><p class="categories"><a href="/categories/Computer/">Computer</a> / <a href="/categories/Computer/Basics-of-Computers/">Basics of Computers</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2018-07-17T08:37:57.000Z">2018-07-17</time></p><p class="title"><a href="/2018/07/17/2018-07-17-Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/">Linux文件系统</a></p><p class="categories"><a href="/categories/Computer/">Computer</a> / <a href="/categories/Computer/Basics-of-Computers/">Basics of Computers</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">January 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">June 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer/"><span class="tag">Computer</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Operation-Maintenance/"><span class="tag">Operation&amp;Maintenance</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Raspberry-Pi/"><span class="tag">Raspberry Pi</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Forskamse&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2021 Forskamse</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en")</script><script>var IcarusThemeSettings={article:{highlight:{clipboard:!0,fold:"unfolded"}}}</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener("DOMContentLoaded",function(){loadInsight({contentUrl:"/content.json"},{hint:"Type something...",untitled:"(Untitled)",posts:"Posts",pages:"Pages",categories:"Categories",tags:"Tags"})})</script></body></html>