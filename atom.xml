<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Forskamse&#39;s Homepage</title>
  
  
  <link href="https://forskamse.github.io/atom.xml" rel="self"/>
  
  <link href="https://forskamse.github.io/"/>
  <updated>2021-08-06T06:51:27.932Z</updated>
  <id>https://forskamse.github.io/</id>
  
  <author>
    <name>Forskamse</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>预训练语言模型综述（一）—— 预训练语言模型及其历史</title>
    <link href="https://forskamse.github.io/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/"/>
    <id>https://forskamse.github.io/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/</id>
    <published>2021-07-14T17:52:31.000Z</published>
    <updated>2021-08-06T06:51:27.932Z</updated>
    
    <content type="html"><![CDATA[<p>本系列文章是笔者以邱锡鹏老师《Pre-trained Models for Natural Language Processing: A Survey》为主要参考材料所做的关于“预训练语言模型综述”的记录，所涉及之素材也包括其他相关综述与未被纳入此综述的工作，分享出来与大家交流讨论。此篇记录预训练语言模型及其历史。</p><span id="more"></span><h2 id="补充知识"><a class="markdownIt-Anchor" href="#补充知识"></a> 补充知识</h2><ol><li><p>一个好的语言模型应该可以从语料中：</p><p>（1）捕获语言的特征（linguistic features），包括但不限于<br />语义特征（semantic features）：词与句子的语义<br />句法<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>特征（syntactic features）：即句子的结构组织以及句子中词语次之间的依赖关系。<br />（2）反映语言现象：<br />一词多义（polysemy）, 指代（anaphora）, 语用学（pragmatics，现多指言外之意）等。</p></li></ol><ol start="2"><li>词的表示方法(Word Representations/Word Embeddings)<br />把文本向量化通常是自然语言处理的第一步。词的向量表示有最简单的One-hot Representation，以及用低维度稠密向量表示的Distributed Representation<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>。</li></ol><h2 id="nlp方法模型发展简史"><a class="markdownIt-Anchor" href="#nlp方法模型发展简史"></a> NLP方法/模型发展简史</h2><h6 id="1-非神经网络方法"><a class="markdownIt-Anchor" href="#1-非神经网络方法"></a> 1. 非神经网络方法</h6><p>非神经网络方法通常依赖于离散的人工特征，应用起来也比较困难。</p><h6 id="2-早期神经网络模型"><a class="markdownIt-Anchor" href="#2-早期神经网络模型"></a> 2. 早期神经网络模型</h6><p>早期神经网络模型多使用RNN、CNN等神经网络，同时网络也较浅。主要原因是缺少针对各种NLP任务的大规模数据集，模型如果过深极易引起过拟合，在实际使用中难以确保泛化能力。</p><h6 id="3-第一代预训练语言模型"><a class="markdownIt-Anchor" href="#3-第一代预训练语言模型"></a> 3. 第一代预训练语言模型</h6><p>第一代预训练语言模型学习Non-contextual(static) word embeddings，即与上下文无关的、静态的词向量。第一代预训练语言模型的做法是把词汇表中的每一个词汇映射到一个lookup table中，训练过程就是得到这个lookup table的过程。得到这个lookup table后，把每个词的One-hot乘以lookup table就得到这个词的词向量了。</p><p>第一代预训练语言模型有两个明显的缺陷，一是无法处理一词多义等语言现象，因为它没有把词与词的上下文联系起来；二是OOV(Out of Vocabulary)问题，如果有些词没有在训练数据中出现过，那么通过lookup table中也无法得到它的词向量，为了解决OOV问题，我们可以把词进一步分割，变成字符等形式<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>，这样就可以一定程度上解决OOV问题了。</p><p>第一代预训练语言模型相对于第二代预训练语言模型还是比较浅的。两个经典结构是Continuous Bag-of-Words(CBOW)和Skip-Gram(SG)，最典型的实现就是word2vec。还有一个经典结构是GloVe，也被广泛用于获取词向量。<br />推广开来，同时期还有不少工作研究句向量、段向量乃至篇章向量（如Skip-thought vectors，Paragraph vector，Context2Vec等）。将这些工作也归类为第一代预训练语言模型的原因是他们也是把输入映射为固定维度的向量表示。</p><h6 id="4-第二代预训练语言模型"><a class="markdownIt-Anchor" href="#4-第二代预训练语言模型"></a> 4. 第二代预训练语言模型</h6><p>第二代预训练语言模型学习contextual(dynamical) word embeddings，即与上下文相关的、动态的词向量。</p><p>第二代预训练语言模型的重要代表是ElMo(Embeddings from Language Models)、OpenAI GPT (Generative Pre-training) 和BERT(Bidirectional Encoder Representation from Transformer) 。</p><p>得益于<strong>更强的算力、深度模型的发展、NLP预训练任务的设计、大规模训练语料的利用、各种训练技巧</strong>的出现，第二代预训练语言模型蓬勃发展、越来越强大。</p><p><img src="https://img-blog.csdnimg.cn/20200517112313993.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="第一代与第二代预训练语言模型" /></p><h6 id="5-扩展的预训练语言模型"><a class="markdownIt-Anchor" href="#5-扩展的预训练语言模型"></a> 5. 扩展的预训练语言模型</h6><p>随着预训练语言模型的发展，研究人员已经不再满足于使用简单范式和简单语料训练预训练语言模型，由此催生了一系列扩展的预训练语言模型。其中包括：知识增强（Knowledge-Enriched）的预训练模型、多语言/跨语言（Multilingual）的预训练模型、针对特定语言（Language-Specific）的预训练模型、多模态（Multi-Modal，包括视频-文本、图像-文本、声音-文本等）的预训练模型、针对特定领域（Domain-Specific）的预训练模型、针对特定任务（Task-Specific）的预训练模型等。此外，还有一些预训练模型是在大型预训练模型上做出一些修改/压缩等操作所得的，包括修剪、量化、参数共享、蒸馏、模块替换等，这其中也涉及到如何应用预训练语言模型的问题，在讲到预训练模型的应用是还会进一步介绍。下图是邱老师综述中关于扩展的预训练模型及相关工作的归纳：</p><p><img src="https://img-blog.csdnimg.cn/20210715235045868.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="扩展的预训练语言模型" /></p><h2 id="nlp深度神经网络的发展"><a class="markdownIt-Anchor" href="#nlp深度神经网络的发展"></a> NLP深度神经网络的发展</h2><p><img src="https://img-blog.csdnimg.cn/20200517113139104.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /><br />当前，NLP任务通用的神经网络架构如图1所示（其实就是第二代预训练语言模型的架构）。<br />邱老师的文章把Neural Contextual Encoders分为了两类。<br />一类是Sequence Models，此类模型是按序列顺序来获取词的上下文（包括CNN模型和RNN模型（LSTM和GRU）），无法很好地处理长期依赖（Long-term dependency）。<br />另一类是Graph-based Models，此类模型按预定义的树形或图结构（如句法结构、语义联系）建立词与上下文的联系，但是如何建立好的此类结构是比较困难的。因此，全连接与自注意力在强大算力的加持下就提供了一个更为直接的方法：可以建立全连接图然后让模型学习两个词之间的联系。</p><style type="text/css">.tg  {border-collapse:collapse;border-spacing:0;}.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;  overflow:hidden;padding:10px 5px;word-break:normal;}.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}</style><table class="tg"><thead>  <tr>    <th class="tg-0pky">Contextual Encoders</th>    <th class="tg-0pky">NN Types</th>    <th class="tg-0pky">References</th>  </tr></thead><tbody>  <tr>    <td class="tg-c3ow" rowspan="3">Sequence Models</td>    <td class="tg-0pky">CNN</td>    <td class="tg-0pky">[1]Y. Kim, “Convolutional Neural Networks for Sentence Classification,” in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Doha, Qatar, Oct. 2014, pp. 1746–1751, doi: 10.3115/v1/D14-1181.</td>  </tr>  <tr>    <td class="tg-0pky">LSTM</td>    <td class="tg-0pky">[1]A. M. Dai and Q. V. Le, “Semi-supervised Sequence Learning,” arXiv:1511.01432 [cs], Nov. 2015, Accessed: May 17, 2020. [Online]. Available: <a href="http://arxiv.org/abs/1511.01432"><span style="color:#905">http://arxiv.org/abs/1511.01432</span></a>.<br>[2]P. Liu, X. Qiu, and X. Huang, “Recurrent Neural Network for Text Classification with Multi-Task Learning,” p. 7.</td>  </tr>  <tr>    <td class="tg-0pky">GRU</td>    <td class="tg-0pky">[1]R. Kadlec, M. Schmid, O. Bajgar, and J. Kleindienst, “Text Understanding with the Attention Sum Reader Network,” arXiv:1603.01547 [cs], Jun. 2016, Accessed: May 17, 2020. [Online]. Available: <a href="http://arxiv.org/abs/1603.01547"><span style="color:#905">http://arxiv.org/abs/1603.01547</span></a>.<br>[2]L. Li, M. Huang, Y. Liu, S. Qian, and X. He, “Contextual label sensitive gated network for biomedical event trigger extraction,” Journal of Biomedical Informatics, vol. 95, p. 103221, Jul. 2019, doi: 10.1016/j.jbi.2019.103221.</td>  </tr>  <tr>    <td class="tg-c3ow" rowspan="3">Graph-based Models</td>    <td class="tg-0pky">Recursive NN</td>    <td class="tg-0pky">[1]R. Socher et al., “Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank,” in Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Seattle, Washington, USA, Oct. 2013, pp. 1631–1642, Accessed: May 17, 2020. [Online]. Available: <a href="https://www.aclweb.org/anthology/D13-1170"><span style="color:#905">https://www.aclweb.org/anthology/D13-1170</span></a>.</td>  </tr>  <tr>    <td class="tg-0pky">TreeLSTM</td>    <td class="tg-0pky">[1]K. S. Tai, R. Socher, and C. D. Manning, “Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks,” in Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Beijing, China, Jul. 2015, pp. 1556–1566, doi: 10.3115/v1/P15-1150.<br>[2]X. Zhu, P. Sobhani, and H. Guo, “Long short-term memory over recursive structures,” in Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, Lille, France, Jul. 2015, pp. 1604–1612, Accessed: May 16, 2020. [Online].</td>  </tr>  <tr>    <td class="tg-0pky">GCN</td>    <td class="tg-0pky">[1]T. N. Kipf and M. Welling, “Semi-Supervised Classification with Graph Convolutional Networks,” arXiv:1609.02907 [cs, stat], Feb. 2017, Accessed: May 17, 2020. [Online]. Available: <a href="http://arxiv.org/abs/1609.02907"><span style="color:#905">http://arxiv.org/abs/1609.02907</span></a>.</td>  </tr></tbody></table><p><img src="https://img-blog.csdnimg.cn/20200515153802900.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /></p><p>[1] <a href="https://www.zhihu.com/question/31370551?sort=created">https://www.zhihu.com/question/31370551?sort=created</a><br />[2] Z. S. Harris, “Distributional Structure,” WORD, vol. 10, no. 2–3, pp. 146–162, Aug. 1954, doi: 10.1080/00437956.1954.11659520.</p><hr class="footnotes-sep" /><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>容易混淆的概念有语法与词法，词法是分析词与词的变形，即形态学(morphology)；而语法是一个更完整的概念，包括音韵学（phonology）、形态学(morphology)与造句法（syntax）[1]。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Distributed Representation与Distributional Representation容易混淆。通常认为，Distributed Representation是与Local Representation（One-hot Representation就属于Local Representation）相对的，用到低维稠密向量来表示词的语义，单独的维度是不表达什么含义的，只有整个向量表达出含义；而One-hot Representation则是高维稀疏向量来表示词的语义，只有一个维度表示含义。而Distributional Representation的理论基础则是Harris在1954年提出的分布假说（Distributional Hypothesis）[2]，即上下文相似的词，其语义也相近。所以说凡是用到上下文的Representation都可以称为Distributional Representation，如传统的基于计数的词向量、Word2Vec以及contextualized word vector都属于Distributional Representation。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>代表工作有CharCNN、FastText和Byte-Pair Encoding (BPE)等。 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">&lt;p&gt;本系列文章是笔者以邱锡鹏老师《Pre-trained Models for Natural Language Processing: A Survey》为主要参考材料所做的关于“预训练语言模型综述”的记录，所涉及之素材也包括其他相关综述与未被纳入此综述的工作，分享出来与大家交流讨论。此篇记录预训练语言模型及其历史。&lt;/p&gt;</summary>
    
    
    
    <category term="Deep Learning" scheme="https://forskamse.github.io/categories/Deep-Learning/"/>
    
    <category term="NLP" scheme="https://forskamse.github.io/categories/NLP/"/>
    
    <category term="PTM Special Column" scheme="https://forskamse.github.io/categories/NLP/PTM-Special-Column/"/>
    
    
    <category term="Pre-trained Language Model" scheme="https://forskamse.github.io/tags/Pre-trained-Language-Model/"/>
    
    <category term="Language Modeling" scheme="https://forskamse.github.io/tags/Language-Modeling/"/>
    
  </entry>
  
  <entry>
    <title>基于TensorFlow 2.x的一些CNN模块/网络的实现</title>
    <link href="https://forskamse.github.io/2021/03/08/2021-03-08-Implementations_of_Some_CNN_Modules_Based_on_TensorFlow2/"/>
    <id>https://forskamse.github.io/2021/03/08/2021-03-08-Implementations_of_Some_CNN_Modules_Based_on_TensorFlow2/</id>
    <published>2021-03-08T07:22:01.000Z</published>
    <updated>2021-08-06T06:30:59.875Z</updated>
    
    <content type="html"><![CDATA[<p>开源一些基于TensorFlow 2.x的CNN模块/网络的实现，可能不定时更新。仓库链接：<a href="https://github.com/forskamse/TensorFlow-2-Implementations-of-CNN-Based-Networks">TensorFlow-2-Implementations-of-CNN-Based-Networks</a></p><p>目前的实现包括：<br /><img src="https://img-blog.csdnimg.cn/20210705005936584.png" alt="" /></p><span id="more"></span><h3 id="feature-extractionfusion-blocks"><a class="markdownIt-Anchor" href="#feature-extractionfusion-blocks"></a> Feature Extraction/Fusion Blocks</h3><ul><li><p><a href="https://github.com/forskamse/TensorFlow-2-Implementations-of-CNN-Based-Networks/blob/main/Feature_Extraction_and_Fusion_Blocks/Atrous_Convolutional_Block.py">Atrous Convolutional Block</a> for 1D (data points / sequences) or 2D inputs (images / feature maps), suggested by <em><a href="https://arxiv.org/abs/1803.01271">An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling</a></em></p></li><li><p><a href="https://github.com/forskamse/TensorFlow-2-Implementations-of-CNN-Based-Networks/blob/main/Feature_Extraction_and_Fusion_Blocks/Receptive_Field_Block.py">Receptive Field Block</a>, from <em><a href="https://arxiv.org/pdf/1711.07767.pdf">Receptive Field Block Net for Accurate and Fast Object Detection</a></em></p></li></ul><h3 id="attention-blocks"><a class="markdownIt-Anchor" href="#attention-blocks"></a> Attention Blocks</h3><ul><li><p><a href="https://github.com/forskamse/TensorFlow-2-Implementations-of-CNN-Based-Networks/blob/main/Attention_Blocks/Squeeze_and_Excitation_Block.py">Squeeze-and-Excitation Block (Kind of Channel Attention)</a>, from <em><a href="https://arxiv.org/pdf/1709.01507.pdf">Squeeze-and-Excitation Networks</a></em></p></li><li><p><a href="https://github.com/forskamse/TensorFlow-2-Implementations-of-CNN-Based-Networks/blob/main/Attention_Blocks/Convolutional_Block_Attention_Module.py">Convolutional Block Attention Module (CBAM)</a>, including Channel Attention Module and Spatial Attention Module, from <em><a href="https://arxiv.org/abs/1807.06521">CBAM: Convolutional Block Attention Module</a></em></p></li><li><p><a href="https://github.com/forskamse/TensorFlow-2-Implementations-of-CNN-Based-Networks/blob/main/Attention_Blocks/Non_Local_Block.py">Non-Local Block</a>, including ‘Gaussian’, ‘Embedded Gaussian’, ‘Dot Product’ and ‘Concatenation’ modes, from <em><a href="https://arxiv.org/pdf/1711.07971.pdf">Non-local Neural Networks</a></em></p></li><li><p><a href="https://github.com/forskamse/TensorFlow-2-Implementations-of-CNN-Based-Networks/blob/main/Attention_Blocks/Dual_Attention_Module.py">Dual Attention Module</a>, including Channel Attention Module and Position Attention Module, from <em><a href="https://arxiv.org/pdf/1809.02983.pdf">Dual Attention Network for Scene Segmentation</a></em></p></li></ul><h3 id="backbone-networks"><a class="markdownIt-Anchor" href="#backbone-networks"></a> Backbone Networks</h3><ul><li><a href="https://github.com/forskamse/TensorFlow-2-Implementations-of-CNN-Based-Networks/blob/main/Backbone_Networks/DenseNet.py">DenseNet</a>, from <em><a href="https://arxiv.org/pdf/1608.06993.pdf">Densely Connected Convolutional Networks</a></em></li></ul><p>参考了以下文章/仓库中的一些代码实现，在此感谢：</p><p>[1] <a href="https://github.com/philipperemy/keras-tcn">https://github.com/philipperemy/keras-tcn</a><br />[2] <a href="https://github.com/Baichenjia/Tensorflow-TCN/blob/master/tcn.py">https://github.com/Baichenjia/Tensorflow-TCN/blob/master/tcn.py</a><br />[3] <a href="https://arxiv.org/pdf/1803.01271.pdf">https://arxiv.org/pdf/1803.01271.pdf</a><br />[4] <a href="https://arxiv.org/pdf/1711.07767.pdf">https://arxiv.org/pdf/1711.07767.pdf</a><br />[5] <a href="https://arxiv.org/abs/1709.01507">https://arxiv.org/abs/1709.01507</a><br />[6] <a href="https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/nets/attention_module.py">https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/nets/attention_module.py</a><br />[7] <a href="https://arxiv.org/abs/1807.06521">https://arxiv.org/abs/1807.06521</a><br />[8] <a href="https://arxiv.org/pdf/1711.07971.pdf">https://arxiv.org/pdf/1711.07971.pdf</a><br />[9] <a href="https://github.com/titu1994/keras-non-local-nets/blob/master/non_local.py">https://github.com/titu1994/keras-non-local-nets/blob/master/non_local.py</a><br />[10] <a href="https://github.com/Tramac/Non-local-tensorflow/tree/master/non_local">https://github.com/Tramac/Non-local-tensorflow/tree/master/non_local</a><br />[11] <a href="https://arxiv.org/pdf/1809.02983.pdf">https://arxiv.org/pdf/1809.02983.pdf</a><br />[12] <a href="https://github.com/niecongchong/DANet-keras/blob/master/layers/attention.py">https://github.com/niecongchong/DANet-keras/blob/master/layers/attention.py</a><br />[13] <a href="https://github.com/okason97/DenseNet-Tensorflow2/blob/master/densenet/densenet.py">https://github.com/okason97/DenseNet-Tensorflow2/blob/master/densenet/densenet.py</a><br />[14] <a href="https://arxiv.org/pdf/1608.06993.pdf">https://arxiv.org/pdf/1608.06993.pdf</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;开源一些基于TensorFlow 2.x的CNN模块/网络的实现，可能不定时更新。仓库链接：&lt;a href=&quot;https://github.com/forskamse/TensorFlow-2-Implementations-of-CNN-Based-Networks&quot;&gt;TensorFlow-2-Implementations-of-CNN-Based-Networks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;目前的实现包括：&lt;br /&gt;
&lt;img src=&quot;https://img-blog.csdnimg.cn/20210705005936584.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Deep Learning" scheme="https://forskamse.github.io/categories/Deep-Learning/"/>
    
    <category term="Neural Networks" scheme="https://forskamse.github.io/categories/Deep-Learning/Neural-Networks/"/>
    
    <category term="Implementations" scheme="https://forskamse.github.io/categories/Deep-Learning/Neural-Networks/Implementations/"/>
    
    
    <category term="CNN" scheme="https://forskamse.github.io/tags/CNN/"/>
    
    <category term="Deep Learning" scheme="https://forskamse.github.io/tags/Deep-Learning/"/>
    
    <category term="Neural Networks" scheme="https://forskamse.github.io/tags/Neural-Networks/"/>
    
    <category term="Implementations" scheme="https://forskamse.github.io/tags/Implementations/"/>
    
    <category term="TensorFlow2" scheme="https://forskamse.github.io/tags/TensorFlow2/"/>
    
  </entry>
  
  <entry>
    <title>在远程服务器上部署JupyterLab 3.0</title>
    <link href="https://forskamse.github.io/2021/01/07/2021-01-07-Deployment_of_JupyterLab3_on_Remote_Server/"/>
    <id>https://forskamse.github.io/2021/01/07/2021-01-07-Deployment_of_JupyterLab3_on_Remote_Server/</id>
    <published>2021-01-07T08:52:43.000Z</published>
    <updated>2021-08-06T06:30:59.874Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20210714003645449.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /><br />近期，JupyterLab刚刚升级到3.0版本，在安装与使用方面都有不小改进，加之之前部署在树莓派上时遇到偶尔需要跟服务器之间做些文件交换的情况，处理起来还是稍微麻烦了点，所以趁着这次JupyterLab的大更新，也在远程服务器上来部署下JupyterLab 3.0了。</p><span id="more"></span><h2 id="通过anaconda安装jupyter-lab"><a class="markdownIt-Anchor" href="#通过anaconda安装jupyter-lab"></a> 通过Anaconda安装Jupyter Lab</h2><p>先创建一个虚拟环境：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n JupyterLab python=3.7</span><br></pre></td></tr></table></figure><p>创建完毕并激活环境后，安装JupyterLab：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge jupyterlab</span><br></pre></td></tr></table></figure><h2 id="配置jupyterlab以实现远程安全访问"><a class="markdownIt-Anchor" href="#配置jupyterlab以实现远程安全访问"></a> 配置JupyterLab以实现远程安全访问</h2><p>先用python shell生成一个加密后的密码串：命令行执行python后再python shell中执行以下命令，并输入和确认密码，将会生成一个经过加密的sha1开头的密码串，先将其复制下来。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from jupyter_server.auth import passwd; passwd()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210107200837732.png" alt="" /></p><p>生成JupyterLab的配置文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter lab --generate-config</span><br></pre></td></tr></table></figure><p>会反馈提示默认配置文件的位置，如/home/xxxx/.jupyter/jupyter_lab_config.py。打开该文件并找到以下版块，取消这两个项目的注释，使其生效。密码部分用刚刚生成的加密密码串替换。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"># ServerApp(JupyterApp) configuration</span><br><span class="line">#------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">c.ServerApp.password = &#x27;sha1: xxxxx&#x27; #由jupyter_server.auth生成的密码串</span><br><span class="line">c.ServerApp.allow_remote_access = True</span><br></pre></td></tr></table></figure><h2 id="启动jupyter-lab"><a class="markdownIt-Anchor" href="#启动jupyter-lab"></a> 启动Jupyter Lab</h2><p>后台启动Jupyter Lab：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup jupyter lab --no-browser &amp;</span><br></pre></td></tr></table></figure><p>–no-browser 参数代表不要在启动JupyterLab时打开服务器上的浏览器。</p><h2 id="在客户端浏览器访问jupyter-lab"><a class="markdownIt-Anchor" href="#在客户端浏览器访问jupyter-lab"></a> 在客户端浏览器访问Jupyter Lab</h2><p>JupyterLab网页服务默认端口为8888，因此浏览器中访问server_ip:8888/lab即可跳转到输入密码的界面：<br /><img src="https://img-blog.csdnimg.cn/2021010716470961.png" alt="" /><br />此时要输入的是未加密的原始密码，验证成功后就可以在这个网页上使用JupyterLab了。<br /><img src="https://img-blog.csdnimg.cn/20210107165014657.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210714003645449.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70&quot; alt=&quot;&quot; /&gt;&lt;br /&gt;
近期，JupyterLab刚刚升级到3.0版本，在安装与使用方面都有不小改进，加之之前部署在树莓派上时遇到偶尔需要跟服务器之间做些文件交换的情况，处理起来还是稍微麻烦了点，所以趁着这次JupyterLab的大更新，也在远程服务器上来部署下JupyterLab 3.0了。&lt;/p&gt;</summary>
    
    
    
    <category term="Tools" scheme="https://forskamse.github.io/categories/Tools/"/>
    
    
    <category term="JupyterLab" scheme="https://forskamse.github.io/tags/JupyterLab/"/>
    
    <category term="Jupyter" scheme="https://forskamse.github.io/tags/Jupyter/"/>
    
    <category term="Debug" scheme="https://forskamse.github.io/tags/Debug/"/>
    
  </entry>
  
  <entry>
    <title>算法时间复杂度及P、NP、NP-Complete、NP-Hard问题</title>
    <link href="https://forskamse.github.io/2020/07/04/2020-07-04-Time_Complexity_of_Algorithms/"/>
    <id>https://forskamse.github.io/2020/07/04/2020-07-04-Time_Complexity_of_Algorithms/</id>
    <published>2020-07-04T14:24:25.000Z</published>
    <updated>2021-08-06T06:30:59.873Z</updated>
    
    <content type="html"><![CDATA[<h3 id="算法的时间复杂度"><a class="markdownIt-Anchor" href="#算法的时间复杂度"></a> 算法的时间复杂度</h3><p>如果某个算法的复杂度可以表示为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.099108em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，即问题规模n出现在底数的位置，这种复杂度称为<strong>多项式时间复杂度</strong>；</p><p>如果某个算法的复杂度表示为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>k</mi><mi>n</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(k^n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>或<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">!</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n!)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">!</span><span class="mclose">)</span></span></span></span>，这种复杂度称为<strong>指数型时间复杂度</strong>。</p><p>相同问题规模下（同时这个问题规模不是太小），指数型时间复杂度远远大于多项式时间复杂度。</p><span id="more"></span><p>当我们在解决一个问题时，我们选择的算法通常都需要是多项式时间复杂度的，指数型时间复杂度的算法是计算机所不能承受的（除非问题规模很小）。</p><h3 id="p-np-np-complete-np-hard问题"><a class="markdownIt-Anchor" href="#p-np-np-complete-np-hard问题"></a> P、NP、NP-Complete、NP-Hard问题</h3><p>如果一个问题可以找到一个只有多项式复杂度的算法（这个算法可以在多项式时间内<strong>求得解</strong>），那这个问题就属于<strong>P（Polynomial）问题（即多项式问题）</strong>；</p><p>无法找到任何多项式复杂度算法的可解问题，则称为<strong>指数型（Exponential）问题</strong>；</p><p>没有任何可解算法的问题，则称为<strong>不可解问题</strong>；</p><p>此外，我们关注多项式时间内是否可以<strong>验证</strong>一个解，如果可以，这个问题就被称为<strong>NP（Non-Deterministic Polynomial ）问题（即非决定性多项式问题）</strong>。</p><p>由此可知，<strong>所有的P问题都是NP问题</strong>。</p><p><strong>之所以要定义NP问题，是因为通常只有NP问题才可能找到多项式的算法。我们不会指望一个连多项式地验证一个解都不行的问题存在一个解决它的多项式级的算法。</strong></p><p>在NP问题中，有这么一类问题，所有的NP问题在多项式时间内都可以归约成这类问题【注：“问题A可归约为问题B”有一个重要的直观意义：B的时间复杂度高于或者等于A的时间复杂度。】，这类问题被称为<strong>NPC(NP-Complete)问题</strong>【所以说，NPC问题的时间复杂度大于等于NP问题的时间复杂度，NP问题不比NPC问题难。 】。</p><p>如果能够证明任何一个NPC问题可以在多项式时间内求得解，就可以证明**P=NP?**这个困扰信息学的重要问题了。</p><p>而无论是不是NP问题，又有这么一类问题，所有的NP问题在多项式时间内都可以归约成这类问题，这类问题就被称为<strong>NPH（NP-Hard）问题</strong>；</p><p>NPC和NPH两者的区别是: 验证一个问题A是否为NP-Hard无须判断A是否属于NP，但是NPC问题必须首先是NP问题. 根据定义可知NPC ∈ NPH。</p><p>由于P=NP？并没有得到证明，因此，目前可以对问题作出这样的分类：<br /><img src="https://img-blog.csdn.net/20180622221308453?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" /></p><h3 id="典型的np-hard问题"><a class="markdownIt-Anchor" href="#典型的np-hard问题"></a> 典型的NP-Hard问题</h3><p>旅行商问题，即TSP问题（Traveling Salesman Problem），又译为旅行推销员问题、货郎担问题，是数学领域中著名问题之一。假设有一个旅行商人要拜访n个城市，他必须选择所要走的路径，路径的限制是每个城市只能拜访一次，而且最后要回到原来出发的城市。路径的选择目标是要求得的路径路程为所有路径之中的最小值。 若有 20 个城，则排法就有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>19</mn><mo stretchy="false">!</mo></mrow><annotation encoding="application/x-tex">19!</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">9</span><span class="mclose">!</span></span></span></span>种。在排列组合里<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mo stretchy="false">!</mo></mrow><annotation encoding="application/x-tex">n!</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">n</span><span class="mclose">!</span></span></span></span> 写起来轻松，但<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>19</mn><mo stretchy="false">!</mo><mo>=</mo><mn>1.21</mn><mo>∗</mo><mn>1</mn><msup><mn>0</mn><mn>17</mn></msup></mrow><annotation encoding="application/x-tex">19! = 1.21*10^{17}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">9</span><span class="mclose">!</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">2</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span></span>是一个大得不得了的数字。若每秒钟排一次，要排 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>3.84</mn><mi mathvariant="normal">∗</mi><mn>1</mn><msup><mn>0</mn><mn>9</mn></msup></mrow><annotation encoding="application/x-tex">3.84∗10^{9}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">.</span><span class="mord">8</span><span class="mord">4</span><span class="mord">∗</span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">9</span></span></span></span></span></span></span></span></span></span></span></span> 年。旅行商问题可以归约到NPC问题。</p><h4 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h4><p><a href="https://blog.csdn.net/zolalad/article/details/11848739">算法的时间复杂度和空间复杂度-总结</a><br /><a href="http://www.matrix67.com/blog/archives/105">什么是P问题、NP问题和NPC问题</a><br /><a href="http://blog.51cto.com/yang19890314/1160588">P/NP/NPC/NP-hard</a><br /><a href="https://blog.csdn.net/bitcarmanlee/article/details/51935400">NP-Hard问题浅谈</a></p>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;算法的时间复杂度&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#算法的时间复杂度&quot;&gt;&lt;/a&gt; 算法的时间复杂度&lt;/h3&gt;
&lt;p&gt;如果某个算法的复杂度可以表示为&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;O(n^k)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1.099108em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;O&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.849108em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，即问题规模n出现在底数的位置，这种复杂度称为&lt;strong&gt;多项式时间复杂度&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;如果某个算法的复杂度表示为&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;O(k^n)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;O&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;msupsub&quot;&gt;&lt;span class=&quot;vlist-t&quot;&gt;&lt;span class=&quot;vlist-r&quot;&gt;&lt;span class=&quot;vlist&quot; style=&quot;height:0.664392em;&quot;&gt;&lt;span style=&quot;top:-3.063em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;pstrut&quot; style=&quot;height:2.7em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;sizing reset-size6 size3 mtight&quot;&gt;&lt;span class=&quot;mord mathdefault mtight&quot;&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;或&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;!&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;O(n!)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.02778em;&quot;&gt;O&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;，这种复杂度称为&lt;strong&gt;指数型时间复杂度&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;相同问题规模下（同时这个问题规模不是太小），指数型时间复杂度远远大于多项式时间复杂度。&lt;/p&gt;</summary>
    
    
    
    <category term="Algorithm" scheme="https://forskamse.github.io/categories/Algorithm/"/>
    
    <category term="Mathematics" scheme="https://forskamse.github.io/categories/Algorithm/Mathematics/"/>
    
    
    <category term="Complexity" scheme="https://forskamse.github.io/tags/Complexity/"/>
    
    <category term="NPC" scheme="https://forskamse.github.io/tags/NPC/"/>
    
    <category term="NP-Hard" scheme="https://forskamse.github.io/tags/NP-Hard/"/>
    
    <category term="P=NP?" scheme="https://forskamse.github.io/tags/P-NP/"/>
    
  </entry>
  
  <entry>
    <title>使用VS Code的代码片(snippets)以及使用Settings Sync插件同步VS Code的配置</title>
    <link href="https://forskamse.github.io/2020/05/18/2020-05-18-Tips_of_Using_VSCode_Snippets_and_SettingsSync_Plugin/"/>
    <id>https://forskamse.github.io/2020/05/18/2020-05-18-Tips_of_Using_VSCode_Snippets_and_SettingsSync_Plugin/</id>
    <published>2020-05-18T04:16:41.000Z</published>
    <updated>2021-08-06T06:30:59.872Z</updated>
    
    <content type="html"><![CDATA[<h2 id="创建snippets文件"><a class="markdownIt-Anchor" href="#创建snippets文件"></a> 创建Snippets文件</h2><p>在VS Code可以为每种语言创建Snippets文件：打开File–&gt;Preferences–&gt;User Snippets，Existing Snippets区域显示了已经创建的Snippets文件，点击New Snippets区域的语言可以创建新的Snippets文件。</p><span id="more"></span><p><img src="https://img-blog.csdnimg.cn/20200518111928452.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /><br />值得一提的是，对于markdown，VS Code编辑器默认没有开启quickSuggestion，因此即使已准备好markdown.json，仍需在设置中开启quickSuggestion，以便获得快速插入代码片的提示：<br />打开左下角Manage–&gt;Settings，搜索markdown，找到以下设置项：<br /><img src="https://img-blog.csdnimg.cn/20210703174135391.png" alt="" /><br />选择在settings.json中编辑，将&quot;editor.quickSuggestions&quot;: false改为&quot;editor.quickSuggestions&quot;: true并保存。</p><h2 id="语法结构"><a class="markdownIt-Anchor" href="#语法结构"></a> 语法结构</h2><p>可直接参考VS Code官方指南里的<a href="https://code.visualstudio.com/docs/editor/userdefinedsnippets#_snippet-syntax">Snippets语法</a>。</p><h2 id="同步管理"><a class="markdownIt-Anchor" href="#同步管理"></a> 同步管理</h2><p>【2021-07-03更新】日前VS Code已推出官方同步方案，可以同步设置、User Snippets和所安装插件。可在设置中开启“Settings Sync”。以下同步方案可以忽略。</p><p>有两种方案，第一种：由于VS Code的User Snippets功能只需依赖Snippets文件就可以，Snippets文件位于&quot;C:\Users\user_name\AppData\Roaming\Code\User\snippets&quot;，所以可以简单地使用OneDrive来同步，以管理员身份打开CMD，执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mklink /d &quot;C:\Users\your_user_name\OneDrive\snippets&quot; &quot;C:\Users\your_user_name\AppData\Roaming\Code\User\snippets&quot;</span><br></pre></td></tr></table></figure><p>第二种，可以使用Settings Sync插件，Settings Sync插件支持同步用户配置、Snippets、扩展及其配置等，很实用。<br />首先安装Settings Sync插件，重新加载后会进入Settings Sync的配置的界面，点击LOGIN WITH GITHUB，授权GitHub Token和Github Gist Id，并选择新建Gist来存储配置文件。<br /><img src="https://img-blog.csdnimg.cn/20200518115641661.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /><br />以后只要使用<strong>Shift + Alt + U</strong>就可以上传配置；使用<strong>Shift + Alt + D</strong>就可以下载配置。<br />在<a href="https://gist.github.com/">Gist</a>中，有名为cloudSettings Secret的Gist，里面就有所有的配置文件以及Revision信息。<br />值得注意的是，虽然该插件插件的是Secret Gist，但是只要有Gist ID，所有人还是都可以访问这个Gist的。建议大家千万不要把登录信息放在Snippets中！平时也要注意，代码中不要直接使用明文密码，最起码也用文件读取的方式，安全一些，否则可能不小心就同步到GitHub上去了！</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;创建snippets文件&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#创建snippets文件&quot;&gt;&lt;/a&gt; 创建Snippets文件&lt;/h2&gt;
&lt;p&gt;在VS Code可以为每种语言创建Snippets文件：打开File–&amp;gt;Preferences–&amp;gt;User Snippets，Existing Snippets区域显示了已经创建的Snippets文件，点击New Snippets区域的语言可以创建新的Snippets文件。&lt;/p&gt;</summary>
    
    
    
    <category term="Tools" scheme="https://forskamse.github.io/categories/Tools/"/>
    
    
    <category term="VS Code" scheme="https://forskamse.github.io/tags/VS-Code/"/>
    
    <category term="User Snippets" scheme="https://forskamse.github.io/tags/User-Snippets/"/>
    
    <category term="Settings Sync" scheme="https://forskamse.github.io/tags/Settings-Sync/"/>
    
  </entry>
  
  <entry>
    <title>内网穿透方法总结</title>
    <link href="https://forskamse.github.io/2020/04/23/2020-04-23-Methods_to_Conduct_Intranet_Penetration/"/>
    <id>https://forskamse.github.io/2020/04/23/2020-04-23-Methods_to_Conduct_Intranet_Penetration/</id>
    <published>2020-04-23T13:02:45.000Z</published>
    <updated>2021-08-06T06:30:59.872Z</updated>
    
    <content type="html"><![CDATA[<p>自建服务器或者监控时，需要解决外网设备访问内网端口的任务。这个任务称为内网穿透，解决方法通常是端口映射与端口转发。</p><span id="more"></span> <p>网上关于端口映射与端口转发之间区别的讨论很多，观点也不尽相同，在此我也无意争辩二者的区别，因为实际情况是，端口映射与端口转发这两个词在很多时候都混用了。</p><p>在阅读本文时，请各位暂且认同：端口映射发生于节点与路由/网关之间，其原理是NAT（Network Address Translation，网络地址翻译）；而端口转发则是利用反向隧道、反向代理，发生于两个网络节点的端口之间。</p><hr /><p><a href="#%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84">端口映射</a></p><p><a href="#%EF%BC%88%E4%B8%80%EF%BC%89%C2%A0%E8%B7%AF%E7%94%B1%E5%99%A8%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%88%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%EF%BC%89%E5%8A%9F%E8%83%BD">（一） 路由器的虚拟服务器（端口映射）功能</a></p><p><a href="#%EF%BC%88%E4%BA%8C%EF%BC%89%20Windows%E4%B8%8A%E4%B8%93%E7%94%A8%E7%9A%84%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E5%B7%A5%E5%85%B7PortTunnel">（二） Windows上专用的端口映射工具PortTunnel</a></p><p><a href="#%EF%BC%88%E4%B8%89%EF%BC%89%C2%A0Linux%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E5%B7%A5%E5%85%B7%EF%BC%9ARINETD">（三） Linux端口映射工具：RINETD</a></p><p><a href="#%EF%BC%88%E5%9B%9B%EF%BC%89%C2%A0nat123%E7%9A%84%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84">（四） nat123的端口映射</a></p><p><a href="#%EF%BC%88%E4%BA%94%EF%BC%89%20%E8%8A%B1%E7%94%9F%E5%A3%B3%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8FNAT-DDNS">（五） 花生壳内网穿透NAT-DDNS</a></p><p><a href="#%E5%9F%BA%E4%BA%8E%E5%8F%8D%E5%90%91%E9%9A%A7%E9%81%93%E7%9A%84%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91">基于反向隧道的端口转发</a></p><p><a href="#%EF%BC%88%E4%B8%80%EF%BC%89%20ssh%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91">（一） ssh端口转发</a></p><p><a href="#%EF%BC%88%E4%BA%8C%EF%BC%89%C2%A0Holer">（二） Holer</a></p><p><a href="#%EF%BC%88%E4%BA%8C%EF%BC%89%E3%80%81%20%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86">基于反向代理的端口转发</a></p><p><a href="#%EF%BC%88%E4%B8%80%EF%BC%89%20frp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F">（一） frp内网穿透</a></p><p><a href="#%EF%BC%88%E4%BA%8C%EF%BC%89%C2%A0ngrok%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F">（二） ngrok内网穿透</a></p><p><a href="#%EF%BC%88%E4%B8%89%EF%BC%89%20n2n%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F">（三） n2n内网穿透</a></p><hr /><h2 id="端口映射"><a class="markdownIt-Anchor" href="#端口映射"></a> 端口映射</h2><p><strong>要实现端口映射，如果是家庭宽带是公网IP，可以直接使用带端口映射功能的路由器，或者将网线插入一台电脑做网关（需要解决的是各服务器之间网络连接的问题，如何使其他服务器连上这台电脑，是通过网线桥接还是无线连接需要自行衡量）；家庭宽带不是公网IP的，可以使用NAT服务、DDNS服务。</strong></p><p>######（一） 路由器的虚拟服务器（端口映射）功能</p><p>这种方法需要一个带有端口映射功能的路由器。我以中兴的天翼网关和树莓派motion网络服务为例。配置时，其中外部端口是外网访问的端口，例如可选9000，建议不要太小，因为服务提供商可能屏蔽较小的一些端口；内网端口是motion的端口，为8081或8080；协议选TCP；内部IP是树莓派的局域网ip。<a href="http://xn--ip59-wh5fv4duiv6ki0x0n2eeiua.60.84.xxx">例如你的公网ip为59.60.84.xxx</a>，<a href="http://xn--59-py2cxq3la595br7f7h48sl9bi7wm5b5y2i612cxv8at7g4ssugb.60.84.xxx:9000">这些设置完以后就可以在浏览器中输入59.60.84.xxx:9000</a>，即可看到实时画面。</p><p><img src="https://img-blog.csdn.net/20170216131050832?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemJnamh5ODg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="" /></p><p>######（二） Windows上专用的端口映射工具PortTunnel</p><p>PortTunnel是一个实现端口映射的专用工具。它是一个直接运行的软件。如果操作系统为Windows NT/Windows 2000/Windows XP，第一次运行时选择Start，PortTunnel会自动以服务方式运行。点击[Add]按钮添加条目，点击[Edit]按钮编辑现有条目，点击[Delete]按钮删除条目。</p><p>在这个“新建/编辑端口映射”对话框中，我们要给该条目命名，然后设定输入端口（Port In）、绑定地址（Bind address）、输出端口（Port Out）和输出地址（Address Out）。其中，“绑定地址”是指监听该主机的哪一个IP（内部IP还是外部IP）。设为“Any(0.0.0.0)”则监听该主机的全部IP。</p><p>PortTunnel专门针对HTTP、FTP、SMTP服务的端口映射，提供了较多的参数设置，在相应的标签菜单下调整。此外，PortTunnel还提供了安全性设置和日志、统计等功能。</p><p>附一篇教程：<a href="http://tech.huweishen.com/gongju/1363.html">《PortTunnel [端口映射软件] 使用配置说明》</a></p><p>######（三） Linux端口映射工具：RINETD</p><p>RINETD可以算得上Linux上最为简单好用的端口映射工具了，安装配置均很简单。在此我也就不展开说了，附一篇教程：<a href="https://blog.csdn.net/majinfei/article/details/52184378">《rinetd 一个linux下的端口转发工具》</a>，若有需要，学着这个教程做一下就行。</p><p>######（四） nat123的端口映射</p><p>nat123对Linux、Windows、Android都适用，在其官网上都有相应的教程：</p><p><a href="http://www.nat123.com/pages_8_206.jsp">Linux版教程</a> / <a href="http://www.nat123.com/Pages_17_291.jsp">Windows版教程</a> / <a href="http://www.nat123.com/pages_17_613.jsp">Android版教程</a></p><p>nat123提供了比较丰富的端口映射功能，有http映射（80端口）、https映射（443端口）、非80端口、非网站（其他端口）、全端口映射、全映射等。提醒大家注意，除全端口映射外，其他服务是不需要在访问侧（外网）加装p2p访问者软件的，可以方便使用【全映射是全端口映射的面p2p访问者软件版本】。nat123有免费线路，也有收费服务，具体的收费情况大家自己再行了解。</p><p>我简单说一下全端口映射，以树莓派的vnc服务为例，首先你需要在nat123官网注册一个账号，然后树莓派上安装好nat123软件，并在本地APP上登录账号。nat123的端口映射管理功能在官网上【而不是在本地进行，或者说它只是没有告诉我们如何在本地进行管理】，所以你需要在nat123官网上添加端口映射时选择全端口映射（仅p2p），然后在安卓手机或Windows上安装p2p访问者（nat123官网下载），运行端口映射服务与vnc服务，对vnc来说，端口号=5900+桌面号，例如桌面号为1，那么端口号就是5901，打开p2p访问者，添加访问端口5901，注意p2p访问者要在后台运行，不要关掉，然后打开vnc viewer，输入域名和端口号5901，即可访问树莓派了。</p><p>nat123配置较为简单，容易上手；有开放免费线路且使用体验较好；Linux/Windows/Android皆可使用，可能适合较多的人。</p><p>######（五） 花生壳内网穿透NAT-DDNS</p><p>说到内网穿透，网上很多人都会提到花生壳的内网穿透。花生壳的解决方案是基于NAT和DDNS的。很多年前我使用花生壳的时候，这个服务确实还是可以的，免费，而且连接速度OK，现在用的人太多，速度自然降下来了，也开始提供付费服务了。具体内容我不多说了。</p><p>花生壳官网：<a href="http://www.oray.com">http://www.oray.com</a></p><p>下面介绍端口转发，端口转发都需要一个公网IP服务器，如果自己没有的话，就只能寻求第三方提供的端口转发服务（如Holer）了。</p><h2 id="基于反向隧道的端口转发"><a class="markdownIt-Anchor" href="#基于反向隧道的端口转发"></a> 基于反向隧道的端口转发</h2><p><strong>反向隧道端口转发的典型是SSH端口转发，下面我先介绍如何在自己有公网IP服务器的情况下用SSH反向隧道做端口转发，然后介绍一款开源的SSH端口转发工具（第三方服务）。</strong></p><p>######（一） ssh端口转发</p><p>ssh端口转发命令的基本格式为：</p><p>ssh [其他Option] -L/-R sourceIP:sourcePort:targetIP:targetPort user@server_addr</p><p>首先明确，建立ssh隧道连接存在两个对象，在这里，我们称发起ssh连接的一侧为Client，而接受ssh连接的一侧为Server，server_addr即为Server的IP地址。</p><p>其中-L/-R含义如下：</p><p>-L：本地端口转发，把发送到Client的端口的请求转发至Server的端口；此时Client是source，Server是target；</p><p>-R：远程端口转发，把发送到Server的端口的请求转发至Client的端口；此时Server是source，Client是target；显然，内网穿透属于这种情况；</p><p>此外，ssh tunnel的典型应用一般是三种，除了上面的本地端口转发和远程端口转发，还有一种-D：动态端口转发，是把发送到Client端口（支持SOCKS协议）的请求转发至Server上，而不需指定转发到哪个Server端口，适用于端口映射关系较多的情况。这种情况相对复杂，与本文所讨论的内网穿透没有太大联系，暂且按下。关于动态端口转发，感兴趣的可以看一下：<a href="https://www.youtube.com/watch?v=MG2N8vDqv1g">《SSH Dynamic Port Forwarding》</a>与<a href="https://debian-administration.org/article/449/SSH_dynamic_port_forwarding_with_SOCKS">《SSH dynamic port forwarding with SOCKS》</a>。</p><p>其他Options：</p><p><code>-N：</code>组织启动阻塞式远程 shell会话。当我们只用 <code>ssh</code> 来建立隧道时很有用。</p><p><code>-f：</code>使该forwarding进程以守护进程形式启动（仅在使用-N选项时有效）。</p><p>-p：登录Server时的SSH的端口，不使用时为22。</p><p><strong>下面以树莓派SSH服务端口为例来做一个ssh端口转发的简单测试。</strong></p><p>Step1：按目前OpenSSH的默认配置，只有localhost才能使用本机的端口转发 , 其他设备发起的连接只会得到“ connection refused”。因此，在开启端口转发之前，首先应该修改sshd的配置，使其他设备发起的连接也可以得到转发。</p><p>编辑/etc/ssh/sshd_config文件，添加：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GatewayPorts yes</span><br></pre></td></tr></table></figure><p>Step2：在树莓派上，通过远程端口映射，将服务器的2222端口映射到树莓派的22端口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -fNR 2222:localhost:22 root@公网IP</span><br></pre></td></tr></table></figure><p>这里其实有所省略，完整的写法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -fNR *:2222:localhost:22 root@公网IP</span><br></pre></td></tr></table></figure><p>*代表接受来自所有IP的连接请求，如果替换为localhost，那么即便做了Step1中的设置，其他设备也无法连接。</p><p>Step3：通过服务器的公网IP地址以及2222端口上访问树莓派：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -p 2222 pi@server_addr</span><br></pre></td></tr></table></figure><p>当然，规避OpenSSH的默认限制亦可以选择在其他设备上单独做一个与服务器之间的隧道连接，只是这样较为麻烦：</p><p>在第三方设备上，通过本地端口映射，将第三方设备的2222端口映射到服务器的2222端口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -fNL 2222:localhost:2222 root@公网IP</span><br></pre></td></tr></table></figure><p>在第三方设备上访问树莓派：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -p 2222 pi@localhost</span><br></pre></td></tr></table></figure><p>######（二） Holer</p><p>Holer的GitHub地址：<a href="https://github.com/Wisdom-Projects/holer">https://github.com/Wisdom-Projects/holer</a></p><p>Holer是基于SSH的内网穿透服务。在Holer仓库的readme文档下有使用指南，没什么技术难度，我就简单说说：例如你想远程SSH登陆你的树莓派，将conf/holer.conf文件中原有的Holer Access Key修改为针对SSH服务的Holer Access Key，再启动Holer即可，服务端就配置完成了。<a href="http://xn--HolerSSHholer-tp5u456ah5e005bml3asgjwiar4no11ifa062y.org:65534">Holer提供的SSH服务的映射端口是holer.org:65534</a>，则在客户端的连接方式是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh pi@holer.org -p 65534</span><br></pre></td></tr></table></figure><p>可以看到，Holer的配置确实简单，但是其问题也十分明显，只有一个Holer Access Key作为唯一标识，大家都是用这个Key，连接数多了以后就出问题了。</p><p>Holer也提供了独立的Access Key，这是需要付费开通的。</p><h2 id="基于反向代理的端口转发"><a class="markdownIt-Anchor" href="#基于反向代理的端口转发"></a> 基于反向代理的端口转发</h2><p><strong>有公网IP服务器的人可以使用frp、ngrok、n2n等反向代理工具来实现内网穿透。</strong></p><p>######（一） frp内网穿透</p><p>GitHub仓库：<a href="https://github.com/fatedier/frp">https://github.com/fatedier/frp</a></p><p>GitHubReleases：<a href="https://github.com/fatedier/frp/releases/">https://github.com/fatedier/frp/releases/</a></p><p>根据服务器/客户端所属架构与系统，在releases中<strong>分别</strong>下载合适的版本，并解压出来。</p><p>frps.ini是服务器端的配置文件，配置如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">\[common\]</span><br><span class="line">bind_port = 6666</span><br></pre></td></tr></table></figure><p>记住bind_port是frp服务的监听端口。</p><p>启动服务端frps：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./frps -c ./frps.ini</span><br></pre></td></tr></table></figure><p>而在客户端，我们要修改的配置文件是frpc.ini（以ssh服务为例）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">\[common\]</span><br><span class="line">server_addr = x.x.x.x</span><br><span class="line">server_port = 6666</span><br><span class="line"> </span><br><span class="line">\[ssh\]</span><br><span class="line">type = tcp</span><br><span class="line">local_ip = 127.0.0.1</span><br><span class="line">local_port = 22</span><br><span class="line">remote_port = 2222</span><br></pre></td></tr></table></figure><p>server_addr是服务器的公网ip，server_port是服务器上设置的frp服务的监听端口。</p><p>[ssh]部分的local_port是ssh服务的本地端口，默认是22，而remote端口并不是6666，而是由自己另外指定的服务器上ssh转发的目标端口，这里我选择2222。</p><p>启动客户端frpc：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./frpc -c ./frpc.ini</span><br></pre></td></tr></table></figure><p>正确连接后，访问本地服务器则可以使用以下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh pi@公网ip -p 2222</span><br></pre></td></tr></table></figure><p>为提高frp服务的可靠性，可以添加crontab来保证frp在意外中断后能够及时恢复服务。</p><p>服务端添加crontab定时任务：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">* * * * * /bin/bash /path/to/frp/frps_control.sh</span><br></pre></td></tr></table></figure><p>其中frps_control.sh为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">ps -ef | grep &#x27;frps.ini&#x27; | grep -v &#x27;grep&#x27;</span><br><span class="line"> </span><br><span class="line">if \[ $? -ne 0 \]</span><br><span class="line"> </span><br><span class="line">then</span><br><span class="line"> </span><br><span class="line">cd /path/to/frp/</span><br><span class="line"> </span><br><span class="line">nohup ./frps -c frps.ini &gt;&gt; log &amp;</span><br><span class="line"> </span><br><span class="line">echo &#x27;frps is now restarting!&#x27;</span><br><span class="line"> </span><br><span class="line">exit</span><br><span class="line"> </span><br><span class="line">else</span><br><span class="line"> </span><br><span class="line">echo &#x27;frps is running!&#x27;</span><br><span class="line"> </span><br><span class="line">exit</span><br><span class="line"> </span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>客户端添加crontab定时任务：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">* * * * * /bin/bash /path/to/frp/frpc_control.sh</span><br></pre></td></tr></table></figure><p>其中frpc_control为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">client_state=\`ps -ef | grep &#x27;frpc.ini&#x27; | grep -v &#x27;grep&#x27;\`</span><br><span class="line"> </span><br><span class="line">if \[ ! -n &quot;$client_state&quot; \]</span><br><span class="line"> </span><br><span class="line">then</span><br><span class="line"> </span><br><span class="line">cd /path/to/frp/</span><br><span class="line"> </span><br><span class="line">nohup ./frpc -c frpc.ini &gt;&gt; log &amp;</span><br><span class="line"> </span><br><span class="line">echo &#x27;frpc is now restarting!&#x27;</span><br><span class="line"> </span><br><span class="line">exit</span><br><span class="line"> </span><br><span class="line">else</span><br><span class="line"> </span><br><span class="line">echo &#x27;frpc is running!&#x27;</span><br><span class="line"> </span><br><span class="line">exit</span><br><span class="line"> </span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>######（二） ngrok内网穿透</p><p>关于ngrok内网穿透，这里有一篇较完整的教程，供大家参考<a href="http://www.jianshu.com/p/91f01e30a9b0">《自搭Ngrok实现树莓派内网穿透》</a>。</p><p>######（三） n2n内网穿透</p><p>请看<a href="http://www.w2bc.com/article/83185">《n2n内网穿透神器(一条命令实现穿透)(linux,安卓,win,openwrt全介绍)》</a>。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>内网穿透服务提供商提供的免费服务的质量逐渐下降是商业的必然趋势。而在选择他们提供的付费服务和自行搭建内网穿透服务之间，我个人还是更倾向于自己搭建，更加灵活而且长期成本会更低。以上内网穿透方法中，目前我一直在用的是<strong>路由器端口映射</strong>、<strong>frp</strong>和<strong>ngrok内网穿透</strong>，这三个方法也是我最终的推荐，足以满足绝大多数场景的内网穿透配置需求**。**</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;自建服务器或者监控时，需要解决外网设备访问内网端口的任务。这个任务称为内网穿透，解决方法通常是端口映射与端口转发。&lt;/p&gt;</summary>
    
    
    
    <category term="Computer" scheme="https://forskamse.github.io/categories/Computer/"/>
    
    <category term="Basics of Computers" scheme="https://forskamse.github.io/categories/Computer/Basics-of-Computers/"/>
    
    
    <category term="Proxy" scheme="https://forskamse.github.io/tags/Proxy/"/>
    
    <category term="Penetration" scheme="https://forskamse.github.io/tags/Penetration/"/>
    
    <category term="Port Forwarding" scheme="https://forskamse.github.io/tags/Port-Forwarding/"/>
    
    <category term="NAT" scheme="https://forskamse.github.io/tags/NAT/"/>
    
    <category term="Tunnel" scheme="https://forskamse.github.io/tags/Tunnel/"/>
    
  </entry>
  
  <entry>
    <title>基于树莓派的蓝牙出勤追踪系统</title>
    <link href="https://forskamse.github.io/2020/02/15/2020-02-15-Bluetooth_Attendance_Tracking_System_Based_on_RPi/"/>
    <id>https://forskamse.github.io/2020/02/15/2020-02-15-Bluetooth_Attendance_Tracking_System_Based_on_RPi/</id>
    <published>2020-02-15T07:17:52.000Z</published>
    <updated>2021-08-09T06:16:28.801Z</updated>
    
    <content type="html"><![CDATA[<p>本文介绍一个基于树莓派的蓝牙出勤追踪系统，用于记录和监督自己的工作时长情况。<br />代码与安装指引已更新在GitHub上：<a href="https://github.com/forskamse/Bluetooth-Attendance-Tracking-System-Based-on-RaspberryPi">树莓派蓝牙出勤追踪系统</a>。</p><p>该系统使用树莓派扫描附近的蓝牙或蓝牙低功耗设备，以无感方式收集出勤信息。信息将被存储在InfluxDB中，并通过Grafana的Dashboard使数据可视化。</p><span id="more"></span><p>我使用APScheduler设置定时事件，往数据库中插入一个异常值，来触发Grafana的报警，向邮箱发送每日报告。</p><p>系统目前支持多个蓝牙设备（蓝牙或BLE）的同时扫描与记录，便于多人使用。多人使用时，需要在代码中增加对应的scheduler。</p><p>此系统还可为树莓派在其他物联网场景的应用提供支持。</p><p>欢迎star与fork。</p><h1 id="附安装指引"><a class="markdownIt-Anchor" href="#附安装指引"></a> 【附安装指引】</h1><h1 id="rpi-bluetooth-attendance-information-collection-system"><a class="markdownIt-Anchor" href="#rpi-bluetooth-attendance-information-collection-system"></a> RPi Bluetooth Attendance Information Collection System</h1><p>This system helps collect attendance information in a non-inductive way by scanning the nearby Bluetooth or BLE device using Raspberry Pi.</p><p>The system stores information in InfluxDB and makes the information observable via Grafana.</p><p>The Daily report is also supported.</p><h2 id="installation"><a class="markdownIt-Anchor" href="#installation"></a> Installation</h2><h4 id="1-clone-the-repository"><a class="markdownIt-Anchor" href="#1-clone-the-repository"></a> 1. Clone the repository</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line">git clone https://github.com/forskamse/RPi-Bluetooth-Attendance-Information-Collection-System.git</span><br></pre></td></tr></table></figure><h4 id="2-system-dependencies"><a class="markdownIt-Anchor" href="#2-system-dependencies"></a> 2. System dependencies</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[Hardware: Raspberry Pi 4 - 4G RAM Version]</span><br><span class="line">[OS: Raspbian GNU/Linux 10 (buster)]</span><br><span class="line">[HCI Tool: V5.50]</span><br><span class="line">[Influx DB: V1.6.4]</span><br><span class="line">wget -qO- https://repos.influxdata.com/influxdb.key | sudo apt-key add -</span><br><span class="line">echo &quot;deb https://repos.influxdata.com/debian buster stable&quot; | sudo tee /etc/apt/sources.list.d/influxdb.list</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install influxdb influxdb-client</span><br><span class="line">[Grafana V6.6.0]</span><br><span class="line">wget https://dl.grafana.com/oss/release/grafana_6.6.0_armhf.deb</span><br><span class="line">sudo dpkg -i grafana_6.6.0_armhf.deb</span><br><span class="line">[Grafana Rendering Plugin]</span><br><span class="line">wget https://nodejs.org/dist/v12.16.0/node-v12.16.0-linux-armv7l.tar.xz</span><br><span class="line">sudo ln -s /home/pi/Projects/node-v12.16.0-linux-armv7l/bin/node /usr/bin/node</span><br><span class="line">sudo ln -s /home/pi/Projects/node-v12.16.0-linux-armv7l/bin/npm /usr/bin/npm</span><br><span class="line">npm -g install yarn</span><br><span class="line">npm -g install typescript</span><br><span class="line">sudo ln -s /home/pi/Projects/node-v12.16.0-linux-armv7l/bin/tsc /usr/bin/tsc</span><br><span class="line">sudo ln -s /home/pi/Projects/node-v12.16.0-linux-armv7l/bin/yarn /usr/bin/yarn</span><br><span class="line"># You should change to root and run the following commands.</span><br><span class="line">su root</span><br><span class="line">cd /var/lib/grafana/plugins/</span><br><span class="line">git clone https://github.com/grafana/grafana-image-renderer.git</span><br><span class="line">cd grafana-image-renderer</span><br><span class="line">make deps</span><br><span class="line">make build</span><br><span class="line">sudo apt install chromium-browser chromium-chromedriver</span><br><span class="line">cd /var/lib/grafana/plugins/grafana-image-renderer/node_modules/puppeteer/.local-chromium/linux-706915/chrome-linux/    # here pls check whether your chrome version number is 706915 or not</span><br><span class="line">mv chrome chrome.bak</span><br><span class="line">cp /usr/bin/chromium-browser /var/lib/grafana/plugins/grafana-image-renderer/node_modules/puppeteer/.local-chromium/linux-706915/chrome-linux/chrome</span><br><span class="line">cd ~</span><br></pre></td></tr></table></figure><h4 id="3-python-dependencies"><a class="markdownIt-Anchor" href="#3-python-dependencies"></a> 3. Python dependencies</h4><p>Since BLE scanning requires system permission, using system python3 environment is highly recommended. Otherwise you might suffer from some issues on module searching when running the code with sudo permission.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 install influxdb apscheduler -i https://pypi.tuna.tsinghua.edu.cn/simple/</span><br></pre></td></tr></table></figure><h2 id="configuration"><a class="markdownIt-Anchor" href="#configuration"></a> Configuration</h2><h4 id="1-code-modification"><a class="markdownIt-Anchor" href="#1-code-modification"></a> 1. Code modification</h4><ul><li><p><a href="http://RPi-Bluetooth-Attendance-Information-Collection-System.py">RPi-Bluetooth-Attendance-Information-Collection-System.py</a></p><p>On considering the security, just write [your_db_pwd] into a txt file.</p><p>Change [your_db_user].</p><p>Change target device names(targetDevName, data type: list) and target device addresses(targetDevAddrs, data type: list). You can put both ‘Bluetooth’ and ‘BLE’ device addresses in targetDevAddrs.</p><p>Set triggers individually for each target device name if necessary. As a reminder, you should check whether your machine time and local time are consistant.</p></li><li><p><a href="http://start-when-power-on.sh">start-when-power-on.sh</a></p><p>Change /path/to/your/Project.</p></li></ul><h4 id="2-influxdb-configuration"><a class="markdownIt-Anchor" href="#2-influxdb-configuration"></a> 2. InfluxDB configuration</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl unmask influxdb.service</span><br><span class="line">sudo systemctl enable influxdb</span><br><span class="line">sudo systemctl start influxdb</span><br></pre></td></tr></table></figure><p>Enter influxdb cli mode(by runing ‘influx’ on shell):</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE USER [your_db_user] WITH PASSWORD [your_db_pwd] WITH ALL PRIVILEGES</span><br><span class="line">CREATE DATABASE attendanceInformation</span><br></pre></td></tr></table></figure><h4 id="3-grafana-configuration"><a class="markdownIt-Anchor" href="#3-grafana-configuration"></a> 3. Grafana configuration</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">## Start grafana-image-renderer server in the background</span><br><span class="line">cd /var/lib/grafana/plugins/grafana-image-renderer/</span><br><span class="line">nohup node build/app.js server --port=8081 &amp;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">## Edit grafana config file</span><br><span class="line">sudo nano /etc/grafana/grafana.ini</span><br><span class="line">#######################################</span><br><span class="line">[smtp]</span><br><span class="line">enabled = true</span><br><span class="line">host = [your_email_smtp_host]</span><br><span class="line">user = [your_email_address]</span><br><span class="line">password = [your_email_passwd]</span><br><span class="line">from_address = [your_email_address]</span><br><span class="line">from_name = Grafana</span><br><span class="line">;For example: </span><br><span class="line">;[your_email_smtp_host]: smtp.qq.com:465</span><br><span class="line">;[your_email_address]: xxx@qq.com</span><br><span class="line">[rendering]</span><br><span class="line">server_url = http://localhost:8081/render</span><br><span class="line">callback_url = http://localhost:3000/</span><br><span class="line">#######################################</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## Enable and start grafana server</span><br><span class="line">sudo /bin/systemctl daemon-reload</span><br><span class="line">sudo /bin/systemctl enable grafana-server</span><br><span class="line">sudo systemctl start grafana-server</span><br></pre></td></tr></table></figure><p>Run ‘hostname -I’ for [your_host_address].</p><p>Visit http://[your_host_address]:3000/.<br />Change admin password when first login with username as ‘admin’ and password as ‘admin’.</p><p>Create a dashbord and add data source InfluxDB with [your_db_user] and [your_db_pwd].</p><p>Set up query rules:</p><p><img src="https://img-blog.csdnimg.cn/20200215152419934.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /></p><p>Some additional query settins help with data observability and default image rendering time range:</p><p><img src="https://img-blog.csdnimg.cn/20200215152529209.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /></p><p>Set up alert rules:</p><p><img src="https://img-blog.csdnimg.cn/20200215152611665.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /></p><p>‘Evaluate every’ determines the intervals when the rule is evaluated. ‘For’ determines the pending duration after the alert rule was triggered.</p><p>Set up notification channels:</p><p><img src="https://img-blog.csdnimg.cn/20200215152641669.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /></p><p>Here ‘Include image’ determines whether to send a rendered image or not. ‘Disable Resolve Message’ prevents from sending another [OK] alerting email once the former alerting situation was resolved.</p><h4 id="4-boot-from-power-on"><a class="markdownIt-Anchor" href="#4-boot-from-power-on"></a> 4. Boot from power on</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## Add configuration before &quot;exit 0&quot;</span><br><span class="line">sudo nano /etc/rc.local</span><br><span class="line">########################################################</span><br><span class="line">/bin/bash /path/to/your/Project/start-when-power-on.sh</span><br><span class="line">########################################################</span><br></pre></td></tr></table></figure><h2 id="running"><a class="markdownIt-Anchor" href="#running"></a> Running</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /path/to/your/Project/</span><br><span class="line">nohup sudo python3 RPi-Bluetooth-Attendance-Information-Collection-System.py &gt;&gt; RpiAttendance.log &amp;</span><br></pre></td></tr></table></figure><h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2><p><a href="https://pimylifeup.com/raspberry-pi-grafana/">https://pimylifeup.com/raspberry-pi-grafana/</a></p><p><a href="https://github.com/grafana/grafana-image-renderer/blob/master/docs/building_from_source.md">https://github.com/grafana/grafana-image-renderer/blob/master/docs/building_from_source.md</a></p><p><a href="https://github.com/grafana/grafana-image-renderer/issues/7">https://github.com/grafana/grafana-image-renderer/issues/7</a></p><p><a href="https://grafana.com/docs/grafana/latest/administration/image_rendering/">https://grafana.com/docs/grafana/latest/administration/image_rendering/</a></p><p><a href="https://community.openhab.org/t/tutorial-grafana-rendering-on-raspberry-pi/71777">https://community.openhab.org/t/tutorial-grafana-rendering-on-raspberry-pi/71777</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文介绍一个基于树莓派的蓝牙出勤追踪系统，用于记录和监督自己的工作时长情况。&lt;br /&gt;
代码与安装指引已更新在GitHub上：&lt;a href=&quot;https://github.com/forskamse/Bluetooth-Attendance-Tracking-System-Based-on-RaspberryPi&quot;&gt;树莓派蓝牙出勤追踪系统&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;该系统使用树莓派扫描附近的蓝牙或蓝牙低功耗设备，以无感方式收集出勤信息。信息将被存储在InfluxDB中，并通过Grafana的Dashboard使数据可视化。&lt;/p&gt;</summary>
    
    
    
    <category term="Raspberry Pi" scheme="https://forskamse.github.io/categories/Raspberry-Pi/"/>
    
    <category term="IoT" scheme="https://forskamse.github.io/categories/IoT/"/>
    
    <category term="Wireless Sensor Networks" scheme="https://forskamse.github.io/categories/IoT/Wireless-Sensor-Networks/"/>
    
    <category term="Demo" scheme="https://forskamse.github.io/categories/Demo/"/>
    
    
    <category term="Raspberry Pi" scheme="https://forskamse.github.io/tags/Raspberry-Pi/"/>
    
    <category term="IoT" scheme="https://forskamse.github.io/tags/IoT/"/>
    
    <category term="Wireless Sensor Networks" scheme="https://forskamse.github.io/tags/Wireless-Sensor-Networks/"/>
    
    <category term="InfluxDB" scheme="https://forskamse.github.io/tags/InfluxDB/"/>
    
    <category term="Grafana" scheme="https://forskamse.github.io/tags/Grafana/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络详解(一)——基础知识</title>
    <link href="https://forskamse.github.io/2019/01/22/2019-01-22-CNN_in_Detail_Part_I/"/>
    <id>https://forskamse.github.io/2019/01/22/2019-01-22-CNN_in_Detail_Part_I/</id>
    <published>2019-01-22T06:00:00.000Z</published>
    <updated>2021-08-06T06:30:59.870Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-卷积神经网络的组成"><a class="markdownIt-Anchor" href="#1-卷积神经网络的组成"></a> 1. 卷积神经网络的组成</h2><p>1981年诺贝尔医学奖得主，神经生物学家David Hubel 和Torsten Wiesel对人脑视觉系统的研究表明：人脑视觉系统首先通过眼睛来成像，图像通过瞳孔、晶状体最终在视网膜上成像。视网膜上布满了大量的光感受细胞，可以把光刺激转换为神经冲动，神经冲动通过视觉通路传递到大脑的初级视觉皮层（Primary Visual Cortex，V1），V1初步处理得到边缘、方向等特征信息，而后经由V2的进一步抽象得到轮廓、形状等特征信息，如此迭代地经由多层（V1层至V5层）的抽象后得到高层特征。高层特征是低层特征的组合<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，从低层特征到高层特征的抽象过程中，语义的表现越来越清晰，存在的歧义越来越少，对目标的识别也就越来越精确。这就是人脑视觉系统的分层处理机制。</p><span id="more"></span><p>视觉皮层上的细胞有简单细胞（Simple Cell）与复杂细胞（Complex Cell）之分，这两种细胞的共同点是他们都只对特定方向的条形图样刺激有反应，而他们的主要区别是简单细胞对应的视网膜上的光感受细胞所在的区域比复杂细胞所对应的区域来得小，这个区域被称为感受野（Receptive Field）。这就是人脑视觉系统的感受野机制。</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190121231252850_1844689380.png"></div><p>1980年，日本学者Kunihiko Fukushima提出感知机模型（Neocognitron），提出使用卷积层来模拟视觉细胞对特定图案的反应、使用池化层模拟感受野的方法。卷积神经网络的设计深受这个方法的影响，其基本结构为：</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190107202305429_94794149.png"></div><p>具体说来，卷积层用于提取不同的图像特征，有减少参数数量、保留空间信息的作用；池化层用于模拟感受野，有选取特征、减少参数数量的作用，同时引入微小平移不变性<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>；而激活层的设置则是为了引入非线性因子，提升模型的表达能力，这是神经网络中普遍采用的。</p><h2 id="2-卷积层"><a class="markdownIt-Anchor" href="#2-卷积层"></a> 2. 卷积层</h2><h3 id="21-图像的局部相关性"><a class="markdownIt-Anchor" href="#21-图像的局部相关性"></a> 2.1 图像的局部相关性</h3><p>图像是具有局部相关性的一类数据<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>，其局部相关性是指组成图像的每个像素点与其周围的像素点是有关联的，而图像上距离较远的像素相关性较弱，因此处理图像时实际上没必要每个神经元都对全局图像进行感知。</p><h3 id="22-全连接网络用于图像处理"><a class="markdownIt-Anchor" href="#22-全连接网络用于图像处理"></a> 2.2 全连接网络用于图像处理</h3><p>以MNIST手写数字识别为例，该数据集中的图像为（28，28，1）的灰度图像，这个图像由28 * 28个像素点（Pixel）构成，每个像素点有一个通道（Channel）。如果使用全连接网络（即网络中的神经元与相邻层上的每个神经元均连接），那么输入层有28 * 28 =784个神经元，假设hidden层采用了15个神经元<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>，输出层是10个神经元，那么参数个数(w和b)就有：784 * 15 * 10+15+10=117625个。即使在这种情况下，参数量都十分庞大了，如果输入图像的像素点更多、全连接网络的隐藏层层数更多、隐藏层神经元数量更多，参数量就会更加庞大。<br />大量的参数很容易导致网络过拟合，而且每进行一次反向传播计算量都是巨大的，无论从调参还是计算资源的角度都不建议用全连接网络做图像处理。此外，全连接网络认为“每个输入值都是平等的”，它将输入视为一维向量，并不关心这个像素是第几行、第几列的像素，忽视了空间信息，用于图像这种具有空间局部相关性的数据也是不合适的。</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/1546681571_28983.png"></div><h3 id="23-减少参数数量"><a class="markdownIt-Anchor" href="#23-减少参数数量"></a> 2.3 减少参数数量</h3><p>在图像局部相关性的支撑下，卷积连接应用而生。<br />为简化说明，来看一个简单的例子：<br />在下面的这张图中，输入为3 * 3 = 9个像素，如果将其与16个隐藏层神经元全连接，就会有9 * 16 = 144个连接，也就有144个权值。</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190112180923731_700883300.png"></div><p>为减少连接数，并且基于图像局部相关性的假设，可以仅取四个位置相近（注意图像的Width和Height两个维度）的像素作为输入，四个像素与同一个神经元进行连接，连接的权值记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">w_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">w_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>， 如下图所示。</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190112181611409_233506424.png"></div><p>这种连接方式又可看作是数学上的卷积操作<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>，其中这一组权值就被称为卷积核， 如下图右图所示，因此得名卷积连接。</p><p>我们将这个卷积操作在输入图像上滑动起来，自然地，连接的神经元也向下滑动，连接的权值仍记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">w_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">w_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，如下图所示。此时注意，这个卷积操作要覆盖图像上的所有9个像素，需要滑动四次，因此对应着四个神经元。图像的四部分局部像素与这四个神经元连接时共享同一套权值（简洁地说，这四个神经元共享一套权值），这就是所谓的“权值共享”的概念。这组权值又叫做卷积核。</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190112183300720_471577742.png"></div><p>卷积连接方式使得每个神经元所感知的图像的范围由整张图缩减到了4个像素点，从而减少了权值的数量，又采取了“权值共享”的方法，进一步减少了参数的数量。</p><p>允许我们对图像进行卷积操作的理论依据就是图像的局部相关性：卷积神经网络的设计认为每个神经元没必要对全局图像进行感知，只需对局部像素按空间位置进行局部连接即可。</p><h3 id="24-提取图像特征"><a class="markdownIt-Anchor" href="#24-提取图像特征"></a> 2.4 提取图像特征</h3><p>卷积层每次用一个卷积核在图像上滑动，来提取图像的某一显著特征。<br />卷积核可以找到图中和卷积核自身最相似的部分，而且相似度越高，得到的响应值越大。</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190122174325180_288459116.png"></div><p>图7中上面一排的照片是5架战斗机，把其中一架战斗机的图像截出来作为卷积核，与原图像进行卷积，得到结果如下排图像所示。可以看到，每架战斗机所在的位置都得到了一个极大的响应。<br />因此，通过设置合理的损失函数，在卷积神经网络中使用反向传播算法，最终可以学习到相应于目标结果的卷积核，在Inference的时候就可以提取出有效特征。</p><h3 id="25-保留空间信息"><a class="markdownIt-Anchor" href="#25-保留空间信息"></a> 2.5 保留空间信息</h3><p>与全连接网络相比，卷积网络没有将图像展开为一维向量，而是使用卷积核在原图像上滑动来提取特征，因此保留了原图像的局部空间信息。<br />图7中上面一排右边的照片是由左边照片对5架战斗机平移得到的。经过同样的卷积操作后，得到的特征响应图相当于左边的特征响应图做相应的平移。这是卷积神经网络的局部连接和权值共享带来的“同变性（Equivariance）”<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>，亦是卷积神经网络可以保留图像空间信息的体现。</p><h3 id="26-卷积操作的补充"><a class="markdownIt-Anchor" href="#26-卷积操作的补充"></a> 2.6 卷积操作的补充</h3><ol><li>卷积核（Filter）</li></ol><p>在数学定义上，矩阵的卷积（Convolution）操作为：首先将卷积核进行翻转，构成一个卷积核的镜像，然后使用该镜像和前面矩阵相应位置进行点乘。如下面所示：</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/1546851390_24790.png"></div><ol start="2"><li>步长（Step）</li></ol><p>卷积操作每次移动的单位数称为步长。</p><ol start="3"><li>填充（Padding）<br />为了控制输出的尺寸，可以采用填充的方法。例如在步长为2的情况下，输出尺寸原为5 * 5，如果想使输出尺寸为3 * 3，  可以在输入外围添加一圈0，在这种情况下，输出的尺寸就是3 * 3。</li></ol><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190107180531456_2081156539.png"></div><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190112180202610_1822722602.png"></div><h2 id="3-激活层"><a class="markdownIt-Anchor" href="#3-激活层"></a> 3. 激活层</h2><p>激活层算不上卷积神经网络的特色，这里就不详细介绍了，简而言之，激活层的作用就是引入非线性因子，提升模型的表达能力。</p><h2 id="4-池化层"><a class="markdownIt-Anchor" href="#4-池化层"></a> 4. 池化层</h2><p>卷积神经网络在卷积层和激活层之后又增加了池化层，用来模拟感受野，以达到选取特征、减少参数数量的作用，同时引入微小平移不变性。</p><h3 id="41-特征选取"><a class="markdownIt-Anchor" href="#41-特征选取"></a> 4.1 特征选取</h3><p>池化的一个功能是对特征的选取，卷积神经网络中常用的有Average Pooling和Maximum Pooling。Average Pooling，即对池化区域内特征点求平均，Maximum Pooling则对池化区域内特征点取最大。Average Pooling更能保留图片的背景信息，如果背景中也含有有效信息，Average Pooling就更合适；Maximum Pooling会忽略背景信息，在有噪声的情况下则更有效。<br />通过池化，CNN进一步减少了参数数量（降维）。</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/1540565865_21442.png"></div><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/1540565888_8954.png"></div><h3 id="42-微小平移不变性"><a class="markdownIt-Anchor" href="#42-微小平移不变性"></a> 4.2 微小平移不变性</h3><p>在局部连接和权值共享的作用下，平移后图像的特征映射图与特征映射图直接做对应的平移得到的结果差别不大，即前面所述的同变性。</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190107204820550_1059782468.png"></div>此时再进行池化，以Maximum Pooling为例，如下图所示，在左图中得到的池化结果是11，在右图中得到的池化结果也是11，体现了平移不变性。  <div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108100749906_1800606002.png"></div>需要指出的是，池化的平移不变性是有限的，即所说的微小平移不变性。如果平移超出了感受野的位置，平移不变性就难以体现。  <h2 id="5-分层表达"><a class="markdownIt-Anchor" href="#5-分层表达"></a> 5. 分层表达</h2><p>前已述及，人脑视觉系统存在分层处理的机制，卷积神经网络用多层的网络来模拟人脑视觉系统的分层处理。<br />通过多层的卷积神经网络，计算机逐步“理解”一幅图像大致遵循这样的过程：像素–&gt;边缘–&gt;基本形状–&gt;复杂图案–&gt;更复杂图案。<br />例如，在学习一张车的图片时，浅层的卷积层能从最基本的像素中学习到边缘特征，较深层点的可以学习到圆形等基本形状，再经过几层可以学习到轮胎、车身等图案特征，最后可以学习到车的整体特征。</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108113541696_1346990095.png"></div><h2 id="6-卷积的可视化与解释性"><a class="markdownIt-Anchor" href="#6-卷积的可视化与解释性"></a> 6. 卷积的可视化与解释性</h2><p>深度学习的解释性学界仍在研究当中。目前对于卷积神经网络，仅能通过可视化提供简单的解释。</p><h3 id="61-边缘检测"><a class="markdownIt-Anchor" href="#61-边缘检测"></a> 6.1 边缘检测</h3><p>先解释卷积层如何做边缘检测。<br />图片最常做的边缘检测有两类：垂直边缘（Vertical Edges）检测和水平边缘（Horizontal Edges）检测。</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108120127391_1249309616.png"></div> <p>以垂直边缘检测为例，原始灰度图像尺寸为 6x6，卷积核尺寸为 3x3，不做Padding，Stride = 1，卷积后得到的特征映射图尺寸为 4x4，得到结果如下：</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108142020333_337721441.png"></div> 在灰度图像中，０代表灰，正值表示白，值越大越白，负值代表黑，值越小越黑。本例的原始图像和卷积后的特征映射图，有图例所示的黑白灰分布，提取出了垂直边缘。  <h3 id="62-响应相似图形"><a class="markdownIt-Anchor" href="#62-响应相似图形"></a> 6.2 响应相似图形</h3><p>这部分可以参考2.4节。</p><h3 id="63-特征响应图可视化"><a class="markdownIt-Anchor" href="#63-特征响应图可视化"></a> 6.3 特征响应图可视化</h3><p>相关研究<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>中，曾实现了对特征映射图的可视化。直接看一下结果：</p><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108144217752_522028051.png"></div><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108144230894_1788507434.png"></div><div align="center"><img  src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108144335133_1669012016.png"></div>目前的研究虽然还是不能完全解释CNN，但是通过可视化，我们发现CNN学习到的特征确实如我们所预期的呈现分层特性，底层是一些边缘角点以及颜色的抽象特征，越到高层则越呈现出具体的特征，与人类视觉系统类似。  <h2 id="7-卷积神经网络为什么有效"><a class="markdownIt-Anchor" href="#7-卷积神经网络为什么有效"></a> 7. 卷积神经网络为什么有效</h2><ol><li>从神经科学角度：卷积神经网络模仿了人脑视觉系统的分层处理机制以及感受野机制；</li><li>从统计角度：卷积神经网络抓住了图像的局部相关性（Spatially-local Correlation）；</li><li>从正则化的角度：由于局部连接、权值共享和池化，降低了模型参数数量，控制了模型复杂度，可有效避免模型过拟合。</li></ol><p><strong>关键词 ： 局部感受野、权值共享、时间/空间亚采样</strong></p><h2 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h2><p><a href="https://book.douban.com/subject/27125397/">深度学习与计算机视觉——算法原理、框架应用与代码实现</a><br /><a href="https://www.linkedin.com/pulse/derivation-convolutional-neural-network-from-fully-connected-gad">Derivation of Convolutional Neural Network from Fully Connected Network Step-By-Step</a><br /><a href="https://www.cnblogs.com/charlotte77/p/7759802.html">卷积神经网络CNN原理详解(一)——基本原理</a><br /><a href="https://lguduy.github.io//2017/07/02/CNN%E4%B8%BA%E4%BB%80%E4%B9%88work/#annotations:EasaThA1EemS5wtu41br7w">CNN为什么有效</a><br /><a href="https://zhangting2020.github.io/2018/05/30/Transform-Invariance/">卷积神经网络为什么具有平移不变性？</a><br /><a href="https://zhuanlan.zhihu.com/p/30800318">吴恩达 DeepLearning.ai 课程提炼笔记（4-1）卷积神经网络 — 卷积神经网络基础</a><br /><a href="https://blog.csdn.net/zhang2012liang/article/details/52687498">CNN十大问</a><br /><a href="https://www.cnblogs.com/hejunlin1992/p/7583444.html">CNN中减少网络的参数的三个思想</a></p><hr class="footnotes-sep" /><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>需要注意的是这些层之间的连接并不一定是简单的逐层连接，例如V2层就与其它层均有连接，对这些层之间连接的进一步研究有可能进一步提升卷积神经网络的效果。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>亦有人称池化同时引入了尺度变换和旋转的不变性，由于其可解释性与效果都不佳，因此认可度不高，在此省略不讲。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>语音和自然语言也是具有局部特征性的数据，CNN也可以用于语音处理与自然语言处理。 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>可看作选择15个特征。 <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>实际上应该是数学上的互相关（Cross-correlation）。在深度学习中，我们使用的卷积运算实则没有卷积核翻转为镜像的这一步操作，因为在权重学习的角度，翻转是没有必要的，互相关与卷积相差的就是核没有翻转，所以深度学习中的卷积操作在数学上准确度来说称为互相关。 <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p><a href="https://blog.csdn.net/voxel_grid/article/details/79275637#annotations:l5eZ9BJ8EemTjb9M9uq6Mw">关于 CNN对图像特征的 位移、尺度、形变不变性的理解</a> <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p><a href="https://zhuanlan.zhihu.com/p/24833574">Deep Visualization:可视化并理解CNN</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;1-卷积神经网络的组成&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-卷积神经网络的组成&quot;&gt;&lt;/a&gt; 1. 卷积神经网络的组成&lt;/h2&gt;
&lt;p&gt;1981年诺贝尔医学奖得主，神经生物学家David Hubel 和Torsten Wiesel对人脑视觉系统的研究表明：人脑视觉系统首先通过眼睛来成像，图像通过瞳孔、晶状体最终在视网膜上成像。视网膜上布满了大量的光感受细胞，可以把光刺激转换为神经冲动，神经冲动通过视觉通路传递到大脑的初级视觉皮层（Primary Visual Cortex，V1），V1初步处理得到边缘、方向等特征信息，而后经由V2的进一步抽象得到轮廓、形状等特征信息，如此迭代地经由多层（V1层至V5层）的抽象后得到高层特征。高层特征是低层特征的组合&lt;sup class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn1&quot; id=&quot;fnref1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;，从低层特征到高层特征的抽象过程中，语义的表现越来越清晰，存在的歧义越来越少，对目标的识别也就越来越精确。这就是人脑视觉系统的分层处理机制。&lt;/p&gt;</summary>
    
    
    
    <category term="Deep Learning" scheme="https://forskamse.github.io/categories/Deep-Learning/"/>
    
    <category term="Neural Networks" scheme="https://forskamse.github.io/categories/Deep-Learning/Neural-Networks/"/>
    
    <category term="CNN Special Column" scheme="https://forskamse.github.io/categories/Deep-Learning/Neural-Networks/CNN-Special-Column/"/>
    
    
    <category term="CNN" scheme="https://forskamse.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>Linux域名解析服务</title>
    <link href="https://forskamse.github.io/2018/12/13/2018-12-13-Linux_Domain_Name_Resolution/"/>
    <id>https://forskamse.github.io/2018/12/13/2018-12-13-Linux_Domain_Name_Resolution/</id>
    <published>2018-12-13T15:09:55.000Z</published>
    <updated>2021-08-06T06:51:27.931Z</updated>
    
    <content type="html"><![CDATA[<p>Linux域名解析服务的配置由三个基本的配置文件决定：  /etc/hosts, /etc/resolv.conf与/etc/nsswitch.conf。本文结合这三个文件各自的作用与联系介绍Linux的域名解析服务。</p><span id="more"></span><h2 id="etchosts"><a class="markdownIt-Anchor" href="#etchosts"></a> /etc/hosts</h2><p>/etc/hosts文件包含了IP地址和主机名之间的映射，可能还包括主机名的别名，合法条目格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IP_address canonical_hostname [aliases...]</span><br></pre></td></tr></table></figure><p>系统上的所有网络程序首先通过查询该文件来解析对应于某个主机名的IP地址，如果没有解析成功再使用DNS服务程序解析。<br />通常可以将常用的域名和IP地址映射加入到hosts文件中，实现快速方便的访问。通常情况下这个文件首先记录了本机的ip和主机名。</p><h2 id="etcresolvconf"><a class="markdownIt-Anchor" href="#etcresolvconf"></a> /etc/resolv.conf</h2><p>/etc/resolv.conf配置了DNS客户，它包含了主机的域名搜索顺序和DNS服务器的地址，合法条目格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nameserver Name server IP address</span><br><span class="line">domain Local domain name</span><br><span class="line">search Search list for host-name lookup</span><br><span class="line">sortlist</span><br></pre></td></tr></table></figure><p>其中：<br />nameserver  声明DNS服务器的IP地址。可以有很多行的nameserver，每一个带一个IP地址。在查询时就按nameserver在本文件中的顺序进行，且只有当第一个nameserver没有反应时才查询下面的nameserver。<br />domain  声明本地域名。在本地域名下的请求可以直接使用短名（Short Name），例如设置了domain <a href="http://example.com">example.com</a>，要访问email.example.com主机<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，可以直接用email这个短名来访问，就可以访问到email.example.com主机。<br />search  声明域名搜索列表。其默认值为domain设置的值，当search设置值以后，domain值就失效了。当要查询没有域名的主机（如email），解析器将轮流使用search声明的域名（如search <a href="http://google.com">google.com</a> <a href="http://baidu.com">baidu.com</a>）进行组合来查找主机（<a href="http://xn--email-6o6hp10dsgmvzl.google.com">将查找到email.google.com</a>，然后就停止解析了，不会再对baidu.com域进行检索）。<br />sortlist  允许将得到域名结果进行特定的排序。它的参数为网络/掩码对，允许任意的排列顺序。</p><h2 id="etcnsswitchconf"><a class="markdownIt-Anchor" href="#etcnsswitchconf"></a> /etc/nsswitch.conf</h2><p>自glibc 2.x版本之后，Linux的域名解析服务就由<a href="https://en.wikipedia.org/wiki/Name_Service_Switch">Name Service Switch (NSS)</a> 接管了，其配置文件为/etc/nsswitch.conf。<br />NSS并不是只管域名解析的，管域名解析的是它配置文件的hosts字段：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hosts: files dns</span><br></pre></td></tr></table></figure><p>其中，files指定了搜索/etc/hosts文件，且其优先级最高；dns字段则指定了前面用/etc/resolv.conf建立的主机数据库（hosts database）。</p><h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> [Reference]</h2><ol><li><a href="https://wiki.archlinux.org/index.php/Domain_name_resolution">Domain name resolution</a></li><li><a href="https://jlk.fjfi.cvut.cz/arch/manpages/man/hosts.5">Arch manual pages - HOSTS(5)</a></li><li><a href="https://jlk.fjfi.cvut.cz/arch/manpages/man/resolv.conf.5">Arch manual pages - RESOLV.CONF(5)</a></li><li><a href="https://jlk.fjfi.cvut.cz/arch/manpages/man/nsswitch.conf.5">Arch manual pages - NSSWITCH.CONF(5)</a></li></ol><hr class="footnotes-sep" /><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>域名和主机名都是IP的别名，为了避免记忆数字IP而设计出来的人类易读的形式。透过解析器（Resolver），可以将域名和主机名解析为对应的IP。域名的范围要比主机名大，一个域名下可以有多个主机名，例如，域名abc.com下，有主机server1和server2，其主机全名就是 <a href="http://server1.abc.com">server1.abc.com</a> 和 <a href="http://server2.abc.com">server2.abc.com</a> 。<a href="http://server1.abc.com">server1.abc.com</a> 和 <a href="http://server2.abc.com">server2.abc.com</a> 同时也是abc.com的子域名。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">&lt;p&gt;Linux域名解析服务的配置由三个基本的配置文件决定：  /etc/hosts, /etc/resolv.conf与/etc/nsswitch.conf。本文结合这三个文件各自的作用与联系介绍Linux的域名解析服务。&lt;/p&gt;</summary>
    
    
    
    <category term="Computer" scheme="https://forskamse.github.io/categories/Computer/"/>
    
    <category term="Linux" scheme="https://forskamse.github.io/categories/Computer/Linux/"/>
    
    <category term="Basics of Computers" scheme="https://forskamse.github.io/categories/Computer/Basics-of-Computers/"/>
    
    
    <category term="DNS" scheme="https://forskamse.github.io/tags/DNS/"/>
    
  </entry>
  
  <entry>
    <title>正向代理与反向代理</title>
    <link href="https://forskamse.github.io/2018/12/13/2018-12-13-Forward_and_Reverse_Proxy/"/>
    <id>https://forskamse.github.io/2018/12/13/2018-12-13-Forward_and_Reverse_Proxy/</id>
    <published>2018-12-13T08:09:13.000Z</published>
    <updated>2021-08-06T06:30:59.869Z</updated>
    
    <content type="html"><![CDATA[<p>客户端在访问目标服务器时，可能会遇到：1) 目标服务器允许客户端访问，但受到其他限制（如客户端防火墙等）导致客户端无法访问目标服务器的情况；2）目标服务器拒绝客户端访问资源（如服务器端防火墙、IP限制等）的情况。</p><p>正向代理与反向代理则是分别用于应对这两种情况的。</p><span id="more"></span><p>第一种情况下，为了能够访问到目标服务器，我们就在客户端与目标服务器中间设立一个代理服务器（当然要确保代理服务器可以访问目标服务器），客户端向代理服务器发送一个请求，告知代理要访问的目标服务器，代理接收到请求后向目标服务器转交访问请求并且将获得的内容返回给客户端。</p><p>第二种情况下，为了能够访问到目标服务器，我们也要在客户端与目标服务器中间设立一个代理服务器（当然也要确保代理服务器可以访问目标服务器），客户端向目标服务器发送请求（实际是发到了反向代理服务器上），反向代理访问目标服务器并且将获得的内容返回给客户端；这个行为是将目标服务器上的资源反代到了代理服务器上，使得客户端可以访问。</p><h2 id="区别"><a class="markdownIt-Anchor" href="#区别"></a> 区别</h2><p>个人认为正向代理与反向代理最本质的区别在于<strong>代理服务器代理的是客户端还是目标服务器端</strong>：如果代理服务器与客户端常态连接<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，那么我们认为其代理的是客户端，称其为正向代理；如果代理服务器与目标服务器端常态连接，那么我们认为其代理的是目标服务器端，称其为反向代理。</p><p>看一下其他文章的看法<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>：<br />有一些文章强调反向代理对客户端是透明的（即反向代理隐藏了真实的服务器端），没有隐藏客户端，客户端不需要进行任何配置；正向代理对服务器端是透明的（即正向代理隐藏了真实的客户端），隐藏了客户端，客户端需要进行配置。</p><p>对于前者，我认为这是局限于反向代理服务器为目标服务器服务的场景（如负载均衡、静态缓冲等），并不恰当；在解除目标服务器对IP的限制等反向代理为客户端服务的场景下，反向代理变为对服务器端透明了，而且可能隐藏了客户端，此时客户端是需要配置指向反代服务器；而如果是内网穿透场景，客户端和目标服务器端都需要配置，反代服务器对任何一方都不是透明的。</p><p>对于后者，科学访问、加速访问等场景下，客户端是需要进行配置的，如果正向代理用来做授权访问的话，通常客户端就不需要配置，至于是将客户端的IP暴露给服务器端（正向代理对服务器端透明，客户端未被隐藏），还是将正向代理的IP暴露给服务器端（正向代理隐藏了客户端，对服务器端并不透明）也不确定。</p><p>也就是说，代理服务器的透明与否、是否隐藏客户端完全取决于代理服务器自身的配置，由此又有透明代理、匿名代理、混淆代理、高匿代理的区别<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>；是否需要配置客户端则完全由应用场景决定。</p><h2 id="正向代理应用场景"><a class="markdownIt-Anchor" href="#正向代理应用场景"></a> 正向代理应用场景</h2><ul><li>科学访问</li></ul><p><img src="https://img-blog.csdnimg.cn/20181213160528424.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /></p><p>如图1所示，假设最初用户A要访问服务器B需要经过R1和R2路由器这样一个路由节点，如果路由器R1或者路由器R2发生故障，那么就无法访问服务器B了。但是如果用户A让代理服务器Z去代替自己访问服务器B，由于代理服务器Z没有在路由器R1或R2节点中，而是通过其它的路由节点访问服务器B，那么用户A就可以得到服务器B的数据了。</p><ul><li>加速访问</li></ul><p>仍如图一所示，假设路由器R1、R2已经恢复连接，但是用户A通过路由器R1、R2访问到服务器B的速度较慢，而通过代理服务器为访问服务器B的速度更快，人们就会使用代理服务器来加速访问。</p><ul><li>缓存（Cache）</li></ul><p>仍如图一所示，如果在用户A访问服务器B某数据J之前，已经有人通过代理服务器Z访问过服务器B上得数据J，那么代理服务器Z会把数据J保存一段时间，如果有人正好取该数据J，那么代理服务器Z不再访问服务器B，而把缓存的数据J直接发给用户A。这一技术被称为缓存命中。如果有更多的像用户A的用户来访问代理服务器Z，那么这些用户都可以直接从代理服务器Z中取得数据J，而不必再去服务器B下载数据了。</p><ul><li>客户端授权访问</li></ul><p>)  <img src="https://img-blog.csdnimg.cn/20181213160708263.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /></p><p>如图2所示，在内网中，用户A和用户B都设置了代理服务器，如果A有访问互联网的权限，用户A被允许访问互联网，则可以通过代理服务器Z访问到服务器B；用户B不被允许访问互联网，其访问服务器B的数据包就会被丢弃。授权在代理服务器Z上做出。</p><h2 id="反向代理应用场景"><a class="markdownIt-Anchor" href="#反向代理应用场景"></a> 反向代理应用场景</h2><ul><li>用于负载均衡</li></ul><p>1）需要有一个负载均衡设备来分发用户请求，将用户请求分发到空闲的服务器上<br />2）服务器返回自己的服务到负载均衡设备<br />3）负载均衡将服务器的服务返回用户</p><p><img src="https://img-blog.csdnimg.cn/2018121316082763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="" /></p><ul><li>缓存（Cache）</li></ul><p>反向代理也可以用于缓存，客户端访问时可以从代理服务器直接读回数据。常有人将反向代理的缓存功能用于镜像网站的制作。</p><ul><li>用于内网穿透</li></ul><p>反向代理用于内网穿透的应用十分广泛。外网通常无法直接访问内网，但如果为内网设备配置了反向代理，客户端就可以透过反向代理服务器访问到内网设备。<br />更多细节可以移步我的博客 <a href="https://blog.csdn.net/zbgjhy88/article/details/55289785#%EF%BC%88%E4%BA%8C%EF%BC%89%E3%80%81%20%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86">外网访问内网（内网穿透）方法总结</a> 反向代理部分。</p><ul><li>解除目标服务器对IP的限制</li></ul><p>请看下面的反向代理实例。</p><h2 id="正向代理实例"><a class="markdownIt-Anchor" href="#正向代理实例"></a> 正向代理实例</h2><p><a href="https://blog.csdn.net/ydyang1126/article/details/56675544">Nginx搭建HTTP正向代理服务器</a></p><p>该实例使用nginx搭建了一个HTTP正向代理服务器，使得公司内网中访问外网受限的电脑可以通过正向代理访问外网。</p><h2 id="反向代理实例"><a class="markdownIt-Anchor" href="#反向代理实例"></a> 反向代理实例</h2><p><a href="https://jixun.moe/post/ymusic-hosts-fix/">自建反代服务器解决云音乐海外限制</a></p><p>该实例搭建了一个反向代理服务器，对网易云音乐网页文件及其 API 接口进行反带，使得网易云音乐客户端可以访问资源；实验的反代服务器位于国外，本身也是受限的，无法访问网易云音乐，但是这里使用了一个小Trick，反代服务器暴露给网易云音乐的是一个查得的国内IP，从而避免了网易云音乐的IP限制。当然，如果服务器本身位于国内，就不必使用这个Trick了。</p><h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> [Reference]</h2><p><a href="https://www.zhihu.com/question/24723688">反向代理为何叫反向代理？</a><br /><a href="https://www.jianshu.com/p/cc0683c4f306">nginx 反向代理</a><br /><a href="http://blog.51cto.com/z00w00/1031287">图解正向代理、反向代理、透明代理</a><br /><a href="https://blog.csdn.net/ydyang1126/article/details/56675544">Nginx搭建HTTP正向代理服务器</a><br /><a href="https://jixun.moe/post/ymusic-hosts-fix/">自建反代服务器解决云音乐海外限制</a></p><hr class="footnotes-sep" /><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>常态连接并不意味着双方有着绝对的持续连接状态，只要有着必要的映射关系即可。例如反向代理的负载均衡场景，代理服务器会将请求分发到哪些服务器上这是固定了的；再如正向代理的HTTP代理，代理服务器与客户端之间存在HTTP服务（端口）的映射关系，代理服务器具体访问哪个目标服务器则是由客户端指定的，不存在常态连接。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p><a href="http://www.ibloger.net/article/2347.html">正向代理和反向代理、透明代理的区别？</a>, <a href="https://www.cnblogs.com/Anker/p/6056540.html">正向代理与反向代理【总结】</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p><a href="https://blog.csdn.net/a19860903/article/details/47146715">透明代理、匿名代理、混淆代理、高匿代理有什么区别？</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">&lt;p&gt;客户端在访问目标服务器时，可能会遇到：1) 目标服务器允许客户端访问，但受到其他限制（如客户端防火墙等）导致客户端无法访问目标服务器的情况；2）目标服务器拒绝客户端访问资源（如服务器端防火墙、IP限制等）的情况。&lt;/p&gt;
&lt;p&gt;正向代理与反向代理则是分别用于应对这两种情况的。&lt;/p&gt;</summary>
    
    
    
    <category term="Computer" scheme="https://forskamse.github.io/categories/Computer/"/>
    
    <category term="Basics of Computers" scheme="https://forskamse.github.io/categories/Computer/Basics-of-Computers/"/>
    
    
    <category term="Forward Proxy" scheme="https://forskamse.github.io/tags/Forward-Proxy/"/>
    
    <category term="Reverse Proxy" scheme="https://forskamse.github.io/tags/Reverse-Proxy/"/>
    
    <category term="Proxy" scheme="https://forskamse.github.io/tags/Proxy/"/>
    
  </entry>
  
  <entry>
    <title>使用pip安装TensorFlow Object Detection API</title>
    <link href="https://forskamse.github.io/2018/07/24/2018-07-24-Install_TensorFlow_Object_Detection_API_With_pip/"/>
    <id>https://forskamse.github.io/2018/07/24/2018-07-24-Install_TensorFlow_Object_Detection_API_With_pip/</id>
    <published>2018-07-24T08:27:57.000Z</published>
    <updated>2021-08-06T06:30:59.867Z</updated>
    
    <content type="html"><![CDATA[<p>TensorFlow Object Detection API的安装相当麻烦，其 <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md">官方安装指导</a>要求使用者先克隆下整个tensorflow/models仓库，然后安装Protobuf，编译出object_detection模块，再使用pip进行安装。虽然从开发者的角度看，此安装方法足以满足在各个系统平台下安装TensorFlow Object Detection API的需求，但对于使用者来说，安装这一个API可能就需要耗费大量的时间。</p><span id="more"></span><h2 id="解决方法"><a class="markdownIt-Anchor" href="#解决方法"></a> 解决方法</h2><p>【2021-07-05更新】TensorFlow在TensorFlow 2.2.0时推出了TensorFlow Models高级API的官方PyPI项目，然和遗憾的是，截止当前，TensorFlow官方仍然只在其中纳入Official分支，Community分支和Research分支（Object Detection就在其中）还是没有得到妥善安排。也就是说，我们仍然无法使用pip轻松地安装TensorFlow Object Detection API.</p><p>为跟上TensorFlow Object Detection API的官方更新，也为TensorFlow 2.x用户提供便捷安装途径，作出一些更新：</p><ul><li>更新项目至PyPI</li><li>更新至支持TensorFlow 2.2.0以上版本</li><li>更新至支持TensorFlow 1.15.0</li><li>移除Python 2.x版本支持</li><li>移除此前提供的egg包</li></ul><p>最新项目地址：</p><ul><li>GitHub: <a href="https://github.com/forskamse/TensorFlow-Object-Detection-API">https://github.com/forskamse/TensorFlow-Object-Detection-API</a></li><li>PyPI: <a href="https://pypi.org/project/tf1-tensorflow-object-detection-api/">tf1-tensorflow-object-detection-api</a>，<a href="https://pypi.org/project/tf2-tensorflow-object-detection-api/">tf2-tensorflow-object-detection-api</a></li></ul><hr /><p>鉴于上述问题，我将object detection api打包成whl包和egg包，直接使用pip或者easy_install安装即可。</p><p>我将打包好的whl包与egg包分享出来，打包环境为Raspbian 9 Stretch（Python环境是3.5.3和Python2.7.13）、Win10 64位（Python环境是3.6.6和Python2.7.15）、Manjaro Linux 64位（Python环境是3.6.6和Python2.7.15）。下载地址：<a href="https://github.com/forskamse/Python_Packages_of_TensorFlow_Object_Detection_API">Python_Packages_of_TensorFlow_Object_Detection_API</a></p><h4 id="1-安装依赖"><a class="markdownIt-Anchor" href="#1-安装依赖"></a> 1. 安装依赖</h4><p>Tensorflow Object Detection API 需要如下依赖：</p><p>[使用包管理工具安装（Linux）/系统级安装（Windows）]</p><ul><li>protobuf</li><li>python-tk (tk in Manjaro)</li></ul><p>[使用pip安装]</p><ul><li>tensorflow</li><li>pillow</li><li>lxml</li><li>jupyter</li><li>matplotlib</li><li>cython</li><li>contextlib2</li></ul><h4 id="2-安装下载的whl包或者egg包"><a class="markdownIt-Anchor" href="#2-安装下载的whl包或者egg包"></a> 2. 安装下载的whl包或者egg包</h4><p>安装whl只需执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install xxx.whl</span><br></pre></td></tr></table></figure><p>安装egg只需执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">easy_install xxx.egg</span><br></pre></td></tr></table></figure><h4 id="3-使用"><a class="markdownIt-Anchor" href="#3-使用"></a> 3. 使用</h4><p>使用方法如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from object_detection.xxx import xxx</span><br><span class="line"># e.g.:</span><br><span class="line">from object_detection.utils import label_map_util, visualization_utils</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;TensorFlow Object Detection API的安装相当麻烦，其 &lt;a href=&quot;https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md&quot;&gt;官方安装指导&lt;/a&gt;要求使用者先克隆下整个tensorflow/models仓库，然后安装Protobuf，编译出object_detection模块，再使用pip进行安装。虽然从开发者的角度看，此安装方法足以满足在各个系统平台下安装TensorFlow Object Detection API的需求，但对于使用者来说，安装这一个API可能就需要耗费大量的时间。&lt;/p&gt;</summary>
    
    
    
    <category term="Deep Learning" scheme="https://forskamse.github.io/categories/Deep-Learning/"/>
    
    <category term="Deployment" scheme="https://forskamse.github.io/categories/Deep-Learning/Deployment/"/>
    
    
    <category term="Deep Learning" scheme="https://forskamse.github.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Linux远程桌面服务VNC/XRDP/Xdmcp/SSH+X11转发及其在树莓派上的使用</title>
    <link href="https://forskamse.github.io/2018/07/21/2018-07-12-Linux_Remote_Desktop_Services_and_Their_Applications_on_RPi/"/>
    <id>https://forskamse.github.io/2018/07/21/2018-07-12-Linux_Remote_Desktop_Services_and_Their_Applications_on_RPi/</id>
    <published>2018-07-21T08:37:57.000Z</published>
    <updated>2021-06-24T14:23:09.658Z</updated>
    
    <content type="html"><![CDATA[<p>Linux下有三大知名的远程桌面服务，即VNC/XRDP/Xdmcp，此外还有一个认知度不那么高的SSH+X11转发服务也是很好用的。下面的介绍中我引入在树莓派上的应用（使用Raspbian Stretch），给大家一个直观的认识。</p><span id="more"></span><h2 id="vnc"><a class="markdownIt-Anchor" href="#vnc"></a> VNC</h2><p>使用VNC服务时，先在树莓派上安装vncserver，然后在PC或其他设备上安装vncviewer。</p><p>树莓派上的vncserver有：realvnc、tightvnc、x11vnc等。其实知名的vnc服务提供方还有tigervnc和ultravnc等，只是没有推出arm或树莓派版本。</p><p>realvnc在此下载安装：<a href="https://www.realvnc.com/en/connect/download/vnc/raspberrypi/">https://www.realvnc.com/en/connect/download/vnc/raspberrypi/</a><br />tightvnc和x11vnc使用apt-get安装即可：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install tightvnc</span><br><span class="line">或</span><br><span class="line">sudo apt-get install x11vnc</span><br></pre></td></tr></table></figure><p>realvnc和tightvnc在安装完成后执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vncserver</span><br></pre></td></tr></table></figure><p>首次执行，会要求输入密码以及view-only模式密码，输入后生成一个桌面，提示如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">New desktop is raspberrypi:1 (192.168.253.6:1)</span><br></pre></td></tr></table></figure><p>x11vnc在安装完成后执行:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#设置密码</span><br><span class="line">x11vnc -storepasswd</span><br><span class="line">#启动服务</span><br><span class="line">x11vnc -auth guess -once -loop -noxdamage -repeat -rfbauth /home/pi/.vnc/passwd -rfbport 5900 -shared</span><br></pre></td></tr></table></figure><p>vncviewer可以使用realvnc、tightvnc、ultravnc、tigervnc等提供的vncviewer。</p><p>realvnc viewer：<a href="https://www.realvnc.com/en/connect/download/viewer/">https://www.realvnc.com/en/connect/download/viewer/</a></p><p>realvnc提供的vncviewer支持很多设备，同时复制粘贴等功能也相对完善，一般选用realvnc viewer就可以了。<br /><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/Remote_Desktop_Service/2018071200151253.jpeg" alt="" /></p><p>tightvnc viewer：<a href="https://www.tightvnc.com/download.php">https://www.tightvnc.com/download.php</a></p><p>ultravnc viewer：<a href="http://www.uvnc.com/downloads.html">http://www.uvnc.com/downloads.html</a></p><p>tigervnc viewer：<a href="https://bintray.com/tigervnc/beta/tigervnc">https://bintray.com/tigervnc/beta/tigervnc</a></p><h2 id="xrdp"><a class="markdownIt-Anchor" href="#xrdp"></a> XRDP</h2><p>Windows上有一个远程桌面服务（Remote Desktop Protocol，RDP），Linux上类似的RDP服务称为XRDP。</p><p>安装方法如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install xrdp</span><br></pre></td></tr></table></figure><p>XRDP安装完是默认启动的，开机也会自动启动。</p><p>Windows上自带的远程桌面连接可以直接使用：</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/Remote_Desktop_Service/2018071200491873.png" alt="" /></p><p>不过复制粘贴这些功能做的不如vncviewer好。</p><h2 id="xdmcp"><a class="markdownIt-Anchor" href="#xdmcp"></a> Xdmcp</h2><p>Xdmcp（X Display Manager Control Protocol），即X显示管理器控制协议，由DP（Display Manager），即显示管理器。</p><p>树莓派上默认使用的是lightdm这个显示管理器，修改其配置以启用Xdmcp：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo nano /etc/lightdm/lightdm.conf</span><br><span class="line">#找到XDMCP Server configuration，修改启用项配置，其他端口等配置不必改。</span><br><span class="line">enabled=true</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/Remote_Desktop_Service/20180712011957109.jpeg" alt="" /></p><p>Xdmcp的客户端方面，我推荐xmanager，下载地址：<a href="http://www.xshellcn.com/xiazai.html">http://www.xshellcn.com/xiazai.html</a></p><p>建立会话：</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/Remote_Desktop_Service/20180712013335521.jpeg" alt="" /></p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/Remote_Desktop_Service/20180712013344447.jpeg" alt="" /></p><p>此外，也可以使用Mobaxterm：</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/Remote_Desktop_Service/20180712023253542.jpeg" alt="" /></p><h2 id="sshx11转发"><a class="markdownIt-Anchor" href="#sshx11转发"></a> SSH+X11转发</h2><p>这种远程桌面服务方式在服务端方面不需要进行更多的设置，只要SSH能正常访问即可。</p><p>客户端方面推荐使用Mobaxterm，只需要在对话中将Remote environment由Interactive shell修改为LXDE desktop，如下：</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/Remote_Desktop_Service/20180712020827542.jpeg" alt="" /></p><p>打开后的效果如下：</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/Remote_Desktop_Service/20180712020545402.jpeg" alt="" /></p><p>使用Putty也是可以的，在会话设置的Connection–SSH–X11下启用X11 forwarding：</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/Remote_Desktop_Service/20180712022851820.png" alt="" /></p><p>打开终端后，执行以下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">startlxde</span><br></pre></td></tr></table></figure><p>就可以打开桌面了。</p><p>说一句题外话，Mobaxterm是个十分全面的终端软件，无论是明码文字接口Telnet、Rsh，密码文字接口SSH，图形接口Xdmcp（XServer）、RDP（XRDP）、VNC，X11 Forwarding，文件传输FTP、SFTP，甚至是串口Serial都支持。本人强烈推荐。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Linux下有三大知名的远程桌面服务，即VNC/XRDP/Xdmcp，此外还有一个认知度不那么高的SSH+X11转发服务也是很好用的。下面的介绍中我引入在树莓派上的应用（使用Raspbian Stretch），给大家一个直观的认识。&lt;/p&gt;</summary>
    
    
    
    <category term="Computer" scheme="https://forskamse.github.io/categories/Computer/"/>
    
    <category term="Linux" scheme="https://forskamse.github.io/categories/Computer/Linux/"/>
    
    <category term="Raspberry Pi" scheme="https://forskamse.github.io/categories/Raspberry-Pi/"/>
    
    
    <category term="Computer" scheme="https://forskamse.github.io/tags/Computer/"/>
    
    <category term="Operation&amp;Maintenance" scheme="https://forskamse.github.io/tags/Operation-Maintenance/"/>
    
    <category term="Raspberry Pi" scheme="https://forskamse.github.io/tags/Raspberry-Pi/"/>
    
  </entry>
  
  <entry>
    <title>硬盘基础知识</title>
    <link href="https://forskamse.github.io/2018/07/21/2018-07-21-Basics_of_Disks/"/>
    <id>https://forskamse.github.io/2018/07/21/2018-07-21-Basics_of_Disks/</id>
    <published>2018-07-21T08:37:57.000Z</published>
    <updated>2021-08-09T13:16:51.055Z</updated>
    
    <content type="html"><![CDATA[<h2 id="硬盘接口"><a class="markdownIt-Anchor" href="#硬盘接口"></a> 硬盘接口</h2><p>IDE（Integrated Drive Electronics），即电子集成驱动器，是曾经主流的硬盘接口（同时也作为光驱的接口）。IDE又称ATA（Advanced Technology Attachment），即“高级技术附件”。稍晚时间后，又出现了EIDE（Enhanced IDE）及其他改进版本，从当下的视角再看，我们通常已经不再区分IDE与EIDE了。在SATA（Serial ATA）出现后，ATA改名为PATA（Parallel ATA）以作区分。PATA活跃于1986年至2013年。</p><p>SCSI（Small Computer System Interface），即小型计算机系统接口，可以连接硬盘、软驱、光驱、打印机等设备。SCSI出现的原因主要是因为IDE接口的硬盘转速太慢，传输速率太低。从原理层面看，SCSI与IDE一样使用的是并行技术，因此在SAS（Serial Attached SCSI）出现后SCSI就通常被称为并行SCSI了。</p><p>此后又出现了SATA（Serial Advanced Technology Attachment，串行高级技术附件）、SAS（Serial Attached SCSI，串行连接SCSI） 等接口，使用了串行技术，提高了数据传输速率。</p><p>我们可以将，SCSI和SAS划归为另一个系列，SCSI和SAS价格较高，在各自的年代都是用在高级的服务器上的，私人电脑上较少使用。而将IDE和SATA划归为一个系列，它们用于一般电脑或PC上，SATA在当下非常普遍。</p><span id="more"></span><h2 id="命名"><a class="markdownIt-Anchor" href="#命名"></a> 命名</h2><p>在Linux上，IDE硬盘会被标识为hd，例如，在一个IDE接口上接着的两块硬盘会被分别标识为hda与hdb；出现SCSI硬盘后，Linux将其标识为sd，如sda、sdb。此后所有除IDE接口外的硬盘全部沿用SCSI硬盘的标识标准，即sd，没有再做改动。</p><h2 id="机械硬盘与固态硬盘"><a class="markdownIt-Anchor" href="#机械硬盘与固态硬盘"></a> 机械硬盘与固态硬盘</h2><p>HDD（Hard Disk Drive），硬盘驱动器，常指机械硬盘（Mechanical Hard Disk），区别于固态硬盘（Solid State Disk/Drive）。</p><h4 id="机械硬盘组成与容量"><a class="markdownIt-Anchor" href="#机械硬盘组成与容量"></a> 机械硬盘组成与容量</h4><p>机械硬盘由盘片、磁头及其它辅助机构组成。盘片（Disk）是硬盘中承载数据存储的介质，其上附着着磁粉，磁粉的S/N极将分别代表着二进制中的0和1，从而表示二进制数据。利用磁头（Head）的磁力控制指定的一些磁粉的方向，就存储了特定的信息。</p><p>下图是一个盘片的示意图：<br /><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/About_Disks/20180721165231268.gif" alt="" /></p><p>如上图所示，盘片被分为很多条磁道（Track），即表面上的一些同心圆，磁道是从盘片外圈往内圈编号0磁道，1磁道…。每一个磁道又按512个字节为单位划分为等分，叫做扇区（Sector）。</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/About_Disks/20180721165302175.gif" alt="" /></p><p>磁盘是由多个盘片叠加在一起，互相之间由垫圈隔开。盘片上下两面各有一个磁头，每张盘片同一位置的磁道，组成了柱面（Cylinder ）。显然，磁道数=柱面数。</p><p>知道CHS（Cylinders、Heads、Sectors）的数量后，就可以确定磁盘的容量：</p><p><em>磁盘容量 = 柱面数（磁道数）× 磁头数 × 扇区数 × 扇区大小（512 Bytes）</em></p><h4 id="固态硬盘"><a class="markdownIt-Anchor" href="#固态硬盘"></a> 固态硬盘</h4><p>固态硬盘没有采用磁性介质作为存储介质，而是使用半导体材料来存储数据。</p><p>固态硬盘的内部构造十分简单，固态硬盘内主体其实就是一块PCB板，而这块PCB板上最基本的配件就是控制芯片，缓存芯片（部分低端硬盘无缓存芯片）和用于存储数据的闪存芯片。如下图所示：</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/About_Disks/20181030172815673.png" alt="" /></p><p>固态硬盘也有扇区（Sector）的概念，与机械硬盘一致。</p><h2 id="运行模式"><a class="markdownIt-Anchor" href="#运行模式"></a> 运行模式</h2><p>常见的硬盘运行模式有AHCI（Advanced Host Controller Interface，高级主控接口）模式与IDE模式，其中AHCI在Win7以后得到全面支持，IDE则兼容更多系统。IDE不支持一些新技术，也就难以发挥硬盘的速度性能，这一问题在机械硬盘时代显得没有那么严峻，然而伴随着SSD的兴起，这一问题已经变得极为严峻，也就是说SSD在AHCI模式下与在IDE模式下有很大的性能差异。因此，近年来，AHCI正在逐步淘汰IDE。两者的具体对比可查阅下表：</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/About_Disks/20210809210331.png" alt="" /></p><h2 id="分区表初始分区"><a class="markdownIt-Anchor" href="#分区表初始分区"></a> 分区表（初始分区）</h2><p>一块全新的硬盘，必须进行初始分区。初始分区可以分为MBR分区和GPT分区两种形式，对应MBR分区表和GPT分区表。</p><h4 id="mbr分区形式"><a class="markdownIt-Anchor" href="#mbr分区形式"></a> MBR分区形式</h4><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/About_Disks/20180721165337842.jpeg" alt="" /></p><p>如上图所示，MBR分区形式下，硬盘的第一个扇区是主引导扇区，由三个部分组成：主引导记录（Master Boot Record，MBR）、硬盘分区表（Disk Partition Table，DPT）和硬盘有效标志。</p><p>MBR占446个字节，负责从活动分区（活动分区是即启动分区，安装有系统）中装载并运行系统引导程序。</p><p>DPT占64个字节，记录着硬盘中分区的数量以及每一分区的大小，每个分区的信息用16个字节表示，因此限制了分区的数量：不能超过4个主分区或者3主分区+1扩展分区，而扩展分区可以划分为任意数量的逻辑分区（扩展分区不可直接使用，需要转化为逻辑分区方可使用）【注1：逻辑分区数量受系统层级的限制，在Linux中，IDE硬盘最多有59个逻辑分区（5-63），SATA硬盘则有11个逻辑分区（5-15）】。 这16字节的具体内容是：启动标志、起止磁头号、起止扇区号、起止柱面号、隐含扇区数目(4个字节)、分区总扇区数目(4个字节)。这里又暴露了MBR分区的一个缺陷：用4个字节表示分区总扇区数， 最大能表示2的32次方的扇区个数，按每扇区512字节计算，每个分区最大不能超过2.2TB。</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/About_Disks/20180721165409994.jpeg" alt="" /></p><p>硬盘有效标志占2个字节，又被称为幻数（Magic Number），固定为55AA。如果该标志错误系统就不能启动。</p><h4 id="gpt分区形式"><a class="markdownIt-Anchor" href="#gpt分区形式"></a> GPT分区形式</h4><p>GPT是GUID（Globally Unique Identifier Partition Table） Partition Table的缩写，意即全局唯一标识符分区表。</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/About_Disks/20180721165427999.png" alt="" /></p><p>GPT分区的LBA0是保护性MBR【注2：LBA意为逻辑块地址（Logical Bolck Address），每个逻辑块的大小是512字节，这是与扇区不同的定位方式 】，为了实现有限的兼容性，GPT仍然为MBR保留了这一扇区，用来阻止基于MBR的磁盘工具识别错误，从而覆盖GPT磁盘。</p><p>LBA1是GPT头（Primary GPT Header），LBA-1是备份GPT头（Secondary GPT Header），这两部分内容是一样的。GPT头的具体内容在此不做详细说明了。</p><p>LBA2-LBA33是分区表项，LBA-33 - LBA-2是备份分区表项，两部分内容也是一样的。GPT就是为了避免MBR的两大缺点：在GPT中，分区表项的数量有MBR的4项增多到128项，因此允许划分128个主分区；同时每项由MBR的16字节扩大到128字节，描述每个分区的开始扇区和结束扇区都用8个字节，因而最多支持2的64次方的扇区数，即支持最大约9.4ZB大小的分区。分区表项的具体内容如下：</p><p><img src="https://img-blog.csdn.net/20180721165455982?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" /></p><h4 id="mbr-vs-gpt"><a class="markdownIt-Anchor" href="#mbr-vs-gpt"></a> MBR VS. GPT</h4><p>MBR的缺点之一是不支持大于2.2T的分区，而GPT可以支持18EB的硬盘；</p><p>MBR还有一个缺点是限制磁盘不能超过4个主分区或者3主分区+1扩展分区（包含随意数目的逻辑分区），而GPT则没有此限制。</p><p>GPT也有缺点，GPT分区硬盘在修复磁盘坏轨、做资料恢复、系统还原等任务时都会遇到麻烦，MBR则较为方便。</p><p>GPT 定义是 Intel提出的用以替代BIOS以实现对更多硬件的支持的规范：EFI( Extensible Firmware Interface ) 的一部分。例如，使用EFI/UEFI就可以引导GPT分区下的系统，可以将系统安装到2T容量以上的硬盘中。</p><p>考虑到兼容性，在EFI/UEFI中可以设置Legacy（传统）模式，从而引导MBR分区下的系统了。</p><p>而BIOS只可以引导MBR分区下的系统，不可以引导GPT分区下的系统（但支持GPT分区的硬盘做数据盘）。</p><h4 id="查看分区类型"><a class="markdownIt-Anchor" href="#查看分区类型"></a> 查看分区类型</h4><p><em>Windows系统下</em></p><p>在“此电脑–管理–磁盘管理”中右键查看“磁盘0”或“磁盘1”属性，在“卷”选项卡下的“磁盘分区形式”即是该磁盘分区类型。</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/About_Disks/20181030165722528.png" alt="" /></p><p><em>Linux系统下</em></p><p>使用命令查询：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo parted -l</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/About_Disks/20181030165744755.png" alt="" /></p><p>Partition Table显示gpt则说明是GPT分区表，显示msdos则说明是MBR分区表。</p><h4 id="mbr与gpt的选择"><a class="markdownIt-Anchor" href="#mbr与gpt的选择"></a> MBR与GPT的选择</h4><h6 id="1-作为系统盘"><a class="markdownIt-Anchor" href="#1-作为系统盘"></a> 1. 作为系统盘</h6><p>在Intel的大力推动下，现在很多PC、服务器出厂就是使用EFI/UEFI来启动系统的，磁盘的分区表也是GPT。</p><p>如果换上一块全新的磁盘，并希望使用MBR分区表，则需要在EFI/UEFI中切换Legacy模式，否则安装系统时会出错，例如：“Windows 无法安装到此磁盘。选定磁盘不是 GPT 分区类型的磁盘”。</p><h6 id="2-作为数据盘"><a class="markdownIt-Anchor" href="#2-作为数据盘"></a> 2. 作为数据盘</h6><p>GPT或是MBR都可以被在EFI/UEFI引导的系统下使用，没有差别。如果需要大于2.2T的分区或是更高的主分区数要求，则选择GPT。</p><p><strong>总的来说</strong>，作为系统盘，如果需要在2.2T容量以上的分区安装系统，或者对主分区数有更高要求，就必须使用GPT+EFI/UEFI，否则选择GPT+EFI/UEFI、MBR+BIOS或者MBR+EFI/UEFI（Legacy）都是可以的；而作为数据盘，选择的随意性更大，不需要考虑EFI/UEFI的影响。</p><p>我的建议是分区方式最好不要转换，可能会造成文件的丢失，如果确有必要，可以通过傲梅分区助手、DiskGenius来辅助，切不可使用Windows系统磁盘管理中的转换或是Linux安装系统的转换功能。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;硬盘接口&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#硬盘接口&quot;&gt;&lt;/a&gt; 硬盘接口&lt;/h2&gt;
&lt;p&gt;IDE（Integrated Drive Electronics），即电子集成驱动器，是曾经主流的硬盘接口（同时也作为光驱的接口）。IDE又称ATA（Advanced Technology Attachment），即“高级技术附件”。稍晚时间后，又出现了EIDE（Enhanced IDE）及其他改进版本，从当下的视角再看，我们通常已经不再区分IDE与EIDE了。在SATA（Serial ATA）出现后，ATA改名为PATA（Parallel ATA）以作区分。PATA活跃于1986年至2013年。&lt;/p&gt;
&lt;p&gt;SCSI（Small Computer System Interface），即小型计算机系统接口，可以连接硬盘、软驱、光驱、打印机等设备。SCSI出现的原因主要是因为IDE接口的硬盘转速太慢，传输速率太低。从原理层面看，SCSI与IDE一样使用的是并行技术，因此在SAS（Serial Attached SCSI）出现后SCSI就通常被称为并行SCSI了。&lt;/p&gt;
&lt;p&gt;此后又出现了SATA（Serial Advanced Technology Attachment，串行高级技术附件）、SAS（Serial Attached SCSI，串行连接SCSI） 等接口，使用了串行技术，提高了数据传输速率。&lt;/p&gt;
&lt;p&gt;我们可以将，SCSI和SAS划归为另一个系列，SCSI和SAS价格较高，在各自的年代都是用在高级的服务器上的，私人电脑上较少使用。而将IDE和SATA划归为一个系列，它们用于一般电脑或PC上，SATA在当下非常普遍。&lt;/p&gt;</summary>
    
    
    
    <category term="Computer" scheme="https://forskamse.github.io/categories/Computer/"/>
    
    <category term="Basics of Computers" scheme="https://forskamse.github.io/categories/Computer/Basics-of-Computers/"/>
    
    
    <category term="Computer" scheme="https://forskamse.github.io/tags/Computer/"/>
    
    <category term="Operation&amp;Maintenance" scheme="https://forskamse.github.io/tags/Operation-Maintenance/"/>
    
  </entry>
  
  <entry>
    <title>Linux文件系统</title>
    <link href="https://forskamse.github.io/2018/07/17/2018-07-17-Linux_File_System/"/>
    <id>https://forskamse.github.io/2018/07/17/2018-07-17-Linux_File_System/</id>
    <published>2018-07-17T08:37:57.000Z</published>
    <updated>2021-08-06T06:51:27.931Z</updated>
    
    <content type="html"><![CDATA[<h4 id="文件系统"><a class="markdownIt-Anchor" href="#文件系统"></a> 文件系统</h4><p>计算机的文件系统是一种存储和组织计算机数据的方法，借助于文件系统，用户或程序对文件的访问和查找变得容易。 Linux支持的文件系统格式有：Ext2, Ext3, Ext4, ReiserFS, Xfs, Btrfs, FAT, FAT32, NTFS等。本文中，我并不打算展开对这些文件系统的详细解释，只是简单说出以下这些结论：</p><p>Ext2, Ext3, Ext4是Linux系统上最常用的文件系统，发展到Ext4时已经十分稳定，没有特别要求时，一般都可以使用；</p><p>ReiserFS是用B+树作为数据结构的文件系统，在处理小文件时有较好的性能，在实践中，ReiserFS在处理文件小于1k小文件时，甚至效率可以比ext3快约10倍;</p><p>XFS使用64位管理空间，在多文件、大文件系统、空间利用率等方面相比Ext4更有优势。从CentOS 7开始，默认的文件系统就由此前的Ext4改为XFS了，由于文件规模的不断增大，日后Ext4可能会被XFS所取代。</p><p>Btrfs官方宣称其为“下一代文件系统”，虽然从理念上看Btrfs确实可能存在不错的效果，但截至目前，它的性能表现还是太差了，不建议使用。</p><p>【Ext4、XFS、Btrfs的详细对比，感兴趣的读者可以看看这篇Benchmark：<a href="http://www.ilsistemista.net/index.php/linux-a-unix/6-linux-filesystems-benchmarked-ext3-vs-ext4-vs-xfs-vs-btrfs.html?start=1">EXT3 vs EXT4 vs XFS vs BTRFS linux filesystems benchmark</a>】</p><span id="more"></span><p>Linux虽然支持FAT、FAT32、NTFS，但仅仅是为了兼容性，这三个文件系统很容易产生磁盘碎片（尽管NTFS上已有不小改善），Linux系统下一般是不会轻易使用的。</p><h4 id="挂载点"><a class="markdownIt-Anchor" href="#挂载点"></a> 挂载点</h4><p>挂载点是linux中的磁盘文件系统的入口目录。</p><p><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jul_2018/Linux_File_System/20180721165625481.jpeg" alt="" /></p><p>挂载点与其功能描述如下：</p><table><thead><tr><th>/</th><th>根目录，存放系统命令和用户数据等（如果下面挂载点没有单独的分区，它们都将在根目录的分区中）</th></tr></thead><tbody><tr><td>/boot</td><td>boot   loader 的静态链接文件，存放与Linux启动相关的程序</td></tr><tr><td>/home</td><td>用户目录，存放普通用户的数据</td></tr><tr><td>/tmp</td><td>临时文件</td></tr><tr><td>/usr</td><td>是Red Hat Linux系统存放软件的地方,如有可能应将最大空间分给它：      /usr/local 自已安装程序安装在此   /usr/X1186           X-Windows目录，存放一些X-Windows的配置文件   /usr/include        系统头文件，存储一些C语言的头文件   /usr/src             Linux内核源代码，Linux系统所安装的内核源代码都保存在此   /usr/bin            对/bin目录的一些补充   /usr/sbin          对/sbin目录的一些补充   /usr/share/doc   用户文档</td></tr><tr><td>/var</td><td>不断变化的数据，服务器的一些服务、日志放在下面：   /var/www：一般WEB存放网页的目录   /var/mail：postfix邮件的存放邮件的目录   /var/log：系统日志记录   /var/spool：存放一些邮件、新闻、打印队列等。</td></tr><tr><td>/opt</td><td>（Option可选的）附加的应用程序软件包</td></tr><tr><td>/bin</td><td>基本命令执行文件</td></tr><tr><td>/dev</td><td>设备文件</td></tr><tr><td>/etc</td><td>主机特定的系统配置</td></tr><tr><td>/lib</td><td>基本共享库以及内核模块</td></tr><tr><td>/media</td><td>用于移动介质的挂载点</td></tr><tr><td>/mnt</td><td>用于临时挂载文件系统或者别的硬件设备（如光驱、软驱）</td></tr><tr><td>/proc</td><td>系统信息的虚拟目录(2.4 和 2.6 内核)，这些信息是在内存中，由系统自己产生的。</td></tr><tr><td>/root</td><td>root   用户的目录</td></tr><tr><td>/sbin</td><td>基本系统命令执行文件</td></tr><tr><td>/sys</td><td>系统信息的虚拟目录(2.6 内核)</td></tr><tr><td>/srv</td><td>系统提供的用于 service 的数据</td></tr><tr><td>/lost+found</td><td>这个目录在大多数情况下都是空的。但是如果你正在工作突然停电，或是没有用正常方式关机，在你重新启动机器的时候，有些文件就会找不到应该存放的地方，对于这些文件，系统将他们放在这个目录下。</td></tr></tbody></table><p>当然上面这么多挂载点，实际上是没有比较每个目录都单独进行挂载，我们只需要根据自己的实际使用需要对个别目录进行挂载，这样系统结构看起来也会精简很多。最少的时候，我们只需要挂载/就可以了（当然这样并不好）。</p><h4 id="分区"><a class="markdownIt-Anchor" href="#分区"></a> 分区</h4><p>根据挂载点的不同，对磁盘进行分区，选择最合适的文件系统，可以使计算机的性能、管理达到最优。</p><p>分区有很多的优点，例如：</p><p>1）保护数据；假如误操作，有分区的情况下就可能保护一部分数据免受误操作的影响；重装操作系统时，如果原先的系统中/home与/两个挂载点是对应着两个不同分区时，/home目录就不会受到影响；</p><p>2）针对不同挂载点的特性选择文件系统，开启不同的挂载选项（如是否需要即时同步，是否开启日志，是否启用压缩）以更好地发挥性能，比如对/var使用Reiserfs（这里面的文件通常小而繁杂），对/home使用XFS（超大容量支持可能是用户文件比较需求的），对/使用Ext4（更加稳定）。</p><p>3）分区可以缩小硬盘搜索范围，提高效率。</p><p>我举一例比较典型的分区方案：</p><table><thead><tr><th>挂载点</th><th>分区</th><th>文件系统</th><th>分配详情</th></tr></thead><tbody><tr><td>/boot</td><td>启动分区</td><td>Ext4</td><td>只需要几百m即可，可以容纳下两三个内核足矣。</td></tr><tr><td>/swap</td><td>交换分区</td><td>Swap</td><td>物理内存的1.5-2倍，物理内存够大也可不分配</td></tr><tr><td>/</td><td>根分区</td><td>Ext4</td><td>桌面系统给个100G~200G足矣。</td></tr><tr><td>/home</td><td>家分区</td><td>XFS</td><td>剩下的可以全部分配给家分区</td></tr></tbody></table><h4 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h4><p><a href="https://linux.cn/article-7083-1.html">https://linux.cn/article-7083-1.html</a></p><p><a href="http://my.oschina.net/leejun2005/blog/290073">http://my.oschina.net/leejun2005/blog/290073</a></p><p><a href="http://wuchong.me/blog/2014/07/19/linux-file-system/">http://wuchong.me/blog/2014/07/19/linux-file-system/</a></p>]]></content>
    
    
    <summary type="html">&lt;h4 id=&quot;文件系统&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#文件系统&quot;&gt;&lt;/a&gt; 文件系统&lt;/h4&gt;
&lt;p&gt;计算机的文件系统是一种存储和组织计算机数据的方法，借助于文件系统，用户或程序对文件的访问和查找变得容易。 Linux支持的文件系统格式有：Ext2, Ext3, Ext4, ReiserFS, Xfs, Btrfs, FAT, FAT32, NTFS等。本文中，我并不打算展开对这些文件系统的详细解释，只是简单说出以下这些结论：&lt;/p&gt;
&lt;p&gt;Ext2, Ext3, Ext4是Linux系统上最常用的文件系统，发展到Ext4时已经十分稳定，没有特别要求时，一般都可以使用；&lt;/p&gt;
&lt;p&gt;ReiserFS是用B+树作为数据结构的文件系统，在处理小文件时有较好的性能，在实践中，ReiserFS在处理文件小于1k小文件时，甚至效率可以比ext3快约10倍;&lt;/p&gt;
&lt;p&gt;XFS使用64位管理空间，在多文件、大文件系统、空间利用率等方面相比Ext4更有优势。从CentOS 7开始，默认的文件系统就由此前的Ext4改为XFS了，由于文件规模的不断增大，日后Ext4可能会被XFS所取代。&lt;/p&gt;
&lt;p&gt;Btrfs官方宣称其为“下一代文件系统”，虽然从理念上看Btrfs确实可能存在不错的效果，但截至目前，它的性能表现还是太差了，不建议使用。&lt;/p&gt;
&lt;p&gt;【Ext4、XFS、Btrfs的详细对比，感兴趣的读者可以看看这篇Benchmark：&lt;a href=&quot;http://www.ilsistemista.net/index.php/linux-a-unix/6-linux-filesystems-benchmarked-ext3-vs-ext4-vs-xfs-vs-btrfs.html?start=1&quot;&gt;EXT3 vs EXT4 vs XFS vs BTRFS linux filesystems benchmark&lt;/a&gt;】&lt;/p&gt;</summary>
    
    
    
    <category term="Computer" scheme="https://forskamse.github.io/categories/Computer/"/>
    
    <category term="Linux" scheme="https://forskamse.github.io/categories/Computer/Linux/"/>
    
    <category term="Basics of Computers" scheme="https://forskamse.github.io/categories/Computer/Basics-of-Computers/"/>
    
    
    <category term="Computer" scheme="https://forskamse.github.io/tags/Computer/"/>
    
    <category term="Operation&amp;Maintenance" scheme="https://forskamse.github.io/tags/Operation-Maintenance/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络重要论文资源合辑</title>
    <link href="https://forskamse.github.io/2018/06/20/2018-06-20-CNN_Papers_All_in_One/"/>
    <id>https://forskamse.github.io/2018/06/20/2018-06-20-CNN_Papers_All_in_One/</id>
    <published>2018-06-20T06:00:00.000Z</published>
    <updated>2021-06-24T14:13:17.815Z</updated>
    
    <content type="html"><![CDATA[<h2 id="卷积神经网络的前身与早期发展"><a class="markdownIt-Anchor" href="#卷积神经网络的前身与早期发展"></a> <strong>卷积神经网络的前身与早期发展：</strong></h2><ul><li><strong>1980年日本学者福岛邦彦（Kunihiko Fukushima）提出的神经认知机模型（Neocognitron）</strong><br />Fukushima K, Miyake S. Neocognitron: A self-organizing neural network model for a mechanism of visual pattern recognition[M].Competition and cooperation in neural nets. Springer, Berlin, Heidelberg, 1982: 267-285.</li><li><strong>1989年Yann LeCun提出第一个真正意义上的CNN：LeNet 1989</strong><br />LeCun Y, Boser B, Denker J S, et al. Backpropagation applied to handwritten zip code recognition[J]. Neural computation, 1989, 1(4): 541-551.</li><li><strong>1998年Yann LeCun在其博士论文中详细介绍了LeNet（又称LeNet-5），影响力巨大</strong><br />LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324.</li></ul><span id="more"></span><h2 id="2012年以来卷积神经网络迎来迅猛发展阶段"><a class="markdownIt-Anchor" href="#2012年以来卷积神经网络迎来迅猛发展阶段"></a> <strong>2012年以来卷积神经网络迎来迅猛发展阶段：</strong></h2><ul><li><strong>2012年ILSVRC冠军：AlexNet，掀起深度学习计算机视觉狂潮</strong><br />Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C].Advances in neural information processing systems. 2012: 1097-1105.</li><li><strong>2013年ILSVRC冠军：ZFNet</strong><br />Zeiler M D, Fergus R. Visualizing and understanding convolutional networks[C].European conference on computer vision. Springer, Cham, 2014: 818-833.</li><li><strong>2014年ILSVRC冠军：GoogLeNet，提出Inception结构</strong><br />Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]. Cvpr, 2015.</li><li><strong>2014年ILSVRC亚军：VGGNet，亮点是对网络深度的研究</strong><br />Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.</li><li><strong>2015年ILSVRC冠军：ResNet，提出Residual结构</strong><br />He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C].Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.</li></ul><h2 id="卷积神经网络结合改进与瓶颈阶段"><a class="markdownIt-Anchor" href="#卷积神经网络结合改进与瓶颈阶段"></a> <strong>卷积神经网络结合改进与瓶颈阶段：</strong></h2><p><em><strong>合理结合Inception结构与Residual结构的卷积神经网络已经能够达到令人满意的特征提取效果，但是在解释性上却没有更深一步进展。</strong></em></p><ul><li><strong>2016年Google团队结合了Inception结构与Residual 结构，提出Inception-Residual Net</strong><br />Szegedy C, Ioffe S, Vanhoucke V, et al. Inception-v4, inception-resnet and the impact of residual connections on learning[C].AAAI. 2017, 4: 12.</li><li><strong>2016年何凯明提出新的ResNet的想法：Identity Mapping</strong><br />He K, Zhang X, Ren S, et al. Identity mappings in deep residual networks[C].European Conference on Computer Vision. Springer, Cham, 2016: 630-645.</li><li><strong>2017年DenseNet</strong><br />Huang G, Liu Z, Weinberger K Q, et al. Densely connected convolutional networks[C].Proceedings of the IEEE conference on computer vision and pattern recognition. 2017, 1(2): 3.</li></ul><h2 id="轻量级卷积神经网络发展阶段"><a class="markdownIt-Anchor" href="#轻量级卷积神经网络发展阶段"></a> <strong>轻量级卷积神经网络发展阶段：</strong></h2><p><em><strong>2016年以来，卷积神经网络开始往轻量化发展，为视觉深度学习模型在移动设备上的应用提供条件。</strong></em></p><ul><li><strong>2016年MobileNet</strong><br />Howard A G, Zhu M, Chen B, et al. Mobilenets: Efficient convolutional neural networks for mobile vision applications[J]. arXiv preprint arXiv:1704.04861, 2017.</li><li><strong>2016年ShuffleNet</strong><br />Zhang X, Zhou X, Lin M, et al. Shufflenet: An extremely efficient convolutional neural network for mobile devices[J]. arXiv preprint arXiv:1707.01083, 2017.</li><li><strong>2016年Xception</strong>【注：Xception目标并不是使卷积神经网络轻量化，而是在不增加网络复杂度的情况下提升性能，但其中使用的depthwise convolution思想是MobileNet等轻量级卷积神经网络的关键，故也列在这里】<br />Chollet F. Xception: Deep learning with depthwise separable convolutions[J]. arXiv preprint, 2017: 1610.02357.</li><li><strong>2016年ResNeXt</strong>【注：ResNeXt也是为了在不增加网络复杂度的情况下提升性能，列在此处的原因与Xception相同】<br />Xie S, Girshick R, Dollár P, et al. Aggregated residual transformations for deep neural networks[C].Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. IEEE, 2017: 5987-5995.</li></ul><p><strong>论文合集GitHub地址：<a href="https://github.com/forskamse/CNN">CNN-Papers</a></strong></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;卷积神经网络的前身与早期发展&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#卷积神经网络的前身与早期发展&quot;&gt;&lt;/a&gt; &lt;strong&gt;卷积神经网络的前身与早期发展：&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1980年日本学者福岛邦彦（Kunihiko Fukushima）提出的神经认知机模型（Neocognitron）&lt;/strong&gt;&lt;br /&gt;
Fukushima K, Miyake S. Neocognitron: A self-organizing neural network model for a mechanism of visual pattern recognition[M].Competition and cooperation in neural nets. Springer, Berlin, Heidelberg, 1982: 267-285.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1989年Yann LeCun提出第一个真正意义上的CNN：LeNet 1989&lt;/strong&gt;&lt;br /&gt;
LeCun Y, Boser B, Denker J S, et al. Backpropagation applied to handwritten zip code recognition[J]. Neural computation, 1989, 1(4): 541-551.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1998年Yann LeCun在其博士论文中详细介绍了LeNet（又称LeNet-5），影响力巨大&lt;/strong&gt;&lt;br /&gt;
LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324.&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Deep Learning" scheme="https://forskamse.github.io/categories/Deep-Learning/"/>
    
    <category term="Neural Networks" scheme="https://forskamse.github.io/categories/Deep-Learning/Neural-Networks/"/>
    
    <category term="CNN Special Column" scheme="https://forskamse.github.io/categories/Deep-Learning/Neural-Networks/CNN-Special-Column/"/>
    
    
    <category term="CNN" scheme="https://forskamse.github.io/tags/CNN/"/>
    
  </entry>
  
</feed>
