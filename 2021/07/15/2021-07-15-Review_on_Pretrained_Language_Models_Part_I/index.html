<!doctype html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta><title>预训练语言模型综述（一）—— 预训练语言模型及其历史 - Forskamse&#039;s Homepage</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Forskamse&#039;s Homepage"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Forskamse&#039;s Homepage"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="本系列文章是笔者以邱锡鹏老师《Pre-trained Models for Natural Language Processing: A Survey》为主要参考材料所做的关于“预训练语言模型综述”的记录，所涉及之素材也包括其他相关综述与未被纳入此综述的工作，分享出来与大家交流讨论。此篇记录预训练语言模型及其历史。"><meta property="og:type" content="blog"><meta property="og:title" content="预训练语言模型综述（一）—— 预训练语言模型及其历史"><meta property="og:url" content="https://forskamse.github.io/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/"><meta property="og:site_name" content="Forskamse&#039;s Homepage"><meta property="og:description" content="本系列文章是笔者以邱锡鹏老师《Pre-trained Models for Natural Language Processing: A Survey》为主要参考材料所做的关于“预训练语言模型综述”的记录，所涉及之素材也包括其他相关综述与未被纳入此综述的工作，分享出来与大家交流讨论。此篇记录预训练语言模型及其历史。"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Covers/12.jpg"><meta property="article:published_time" content="2021-07-14T17:52:31.000Z"><meta property="article:modified_time" content="2021-08-06T06:51:27.932Z"><meta property="article:author" content="Forskamse"><meta property="article:tag" content="Pre-trained Language Model"><meta property="article:tag" content="Language Modeling"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Covers/12.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://forskamse.github.io/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/"},"headline":"预训练语言模型综述（一）—— 预训练语言模型及其历史","image":["https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Covers/12.jpg"],"datePublished":"2021-07-14T17:52:31.000Z","dateModified":"2021-08-06T06:51:27.932Z","author":{"@type":"Person","name":"Forskamse"},"publisher":{"@type":"Organization","name":"Forskamse's Homepage","logo":{"@type":"ImageObject","url":"https://forskamse.github.io/img/logo.png"}},"description":"本系列文章是笔者以邱锡鹏老师《Pre-trained Models for Natural Language Processing: A Survey》为主要参考材料所做的关于“预训练语言模型综述”的记录，所涉及之素材也包括其他相关综述与未被纳入此综述的工作，分享出来与大家交流讨论。此篇记录预训练语言模型及其历史。"}</script><link rel="canonical" href="https://forskamse.github.io/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/"><link rel="alternate" href="/atom.xml" title="Forskamse&#039;s Homepage" type="application/atom+xml"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Forskamse&#039;s Homepage" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Covers/12.jpg" alt="预训练语言模型综述（一）—— 预训练语言模型及其历史"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt">&nbsp;</i> <time datetime="2021-07-14T17:52:31.000Z">2021-07-15</time></span><i class="far fa-folder"></i><span> </span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/NLP/">NLP</a><span> / </span><a class="link-muted" href="/categories/NLP/PTM-Special-Column/">PTM Special Column</a></span></div></div><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><i class="far fa-clock"></i><span> </span><span class="level-item">16 minutes read (About 2430 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye">&nbsp;</i> <span id="busuanzi_value_page_pv">0</span></span></div></div><h1 class="title is-3 is-size-4-mobile">预训练语言模型综述（一）—— 预训练语言模型及其历史</h1><div class="content"><p>本系列文章是笔者以邱锡鹏老师《Pre-trained Models for Natural Language Processing: A Survey》为主要参考材料所做的关于“预训练语言模型综述”的记录，所涉及之素材也包括其他相关综述与未被纳入此综述的工作，分享出来与大家交流讨论。此篇记录预训练语言模型及其历史。</p><span id="more"></span><h2 id="补充知识"><a class="markdownIt-Anchor" href="#补充知识"></a> 补充知识</h2><ol><li><p>一个好的语言模型应该可以从语料中：</p><p>（1）捕获语言的特征（linguistic features），包括但不限于<br>语义特征（semantic features）：词与句子的语义<br>句法<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>特征（syntactic features）：即句子的结构组织以及句子中词语次之间的依赖关系。<br>（2）反映语言现象：<br>一词多义（polysemy）, 指代（anaphora）, 语用学（pragmatics，现多指言外之意）等。</p></li></ol><ol start="2"><li>词的表示方法(Word Representations/Word Embeddings)<br>把文本向量化通常是自然语言处理的第一步。词的向量表示有最简单的One-hot Representation，以及用低维度稠密向量表示的Distributed Representation<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>。</li></ol><h2 id="nlp方法模型发展简史"><a class="markdownIt-Anchor" href="#nlp方法模型发展简史"></a> NLP方法/模型发展简史</h2><h6 id="1-非神经网络方法"><a class="markdownIt-Anchor" href="#1-非神经网络方法"></a> 1. 非神经网络方法</h6><p>非神经网络方法通常依赖于离散的人工特征，应用起来也比较困难。</p><h6 id="2-早期神经网络模型"><a class="markdownIt-Anchor" href="#2-早期神经网络模型"></a> 2. 早期神经网络模型</h6><p>早期神经网络模型多使用RNN、CNN等神经网络，同时网络也较浅。主要原因是缺少针对各种NLP任务的大规模数据集，模型如果过深极易引起过拟合，在实际使用中难以确保泛化能力。</p><h6 id="3-第一代预训练语言模型"><a class="markdownIt-Anchor" href="#3-第一代预训练语言模型"></a> 3. 第一代预训练语言模型</h6><p>第一代预训练语言模型学习Non-contextual(static) word embeddings，即与上下文无关的、静态的词向量。第一代预训练语言模型的做法是把词汇表中的每一个词汇映射到一个lookup table中，训练过程就是得到这个lookup table的过程。得到这个lookup table后，把每个词的One-hot乘以lookup table就得到这个词的词向量了。</p><p>第一代预训练语言模型有两个明显的缺陷，一是无法处理一词多义等语言现象，因为它没有把词与词的上下文联系起来；二是OOV(Out of Vocabulary)问题，如果有些词没有在训练数据中出现过，那么通过lookup table中也无法得到它的词向量，为了解决OOV问题，我们可以把词进一步分割，变成字符等形式<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>，这样就可以一定程度上解决OOV问题了。</p><p>第一代预训练语言模型相对于第二代预训练语言模型还是比较浅的。两个经典结构是Continuous Bag-of-Words(CBOW)和Skip-Gram(SG)，最典型的实现就是word2vec。还有一个经典结构是GloVe，也被广泛用于获取词向量。<br>推广开来，同时期还有不少工作研究句向量、段向量乃至篇章向量（如Skip-thought vectors，Paragraph vector，Context2Vec等）。将这些工作也归类为第一代预训练语言模型的原因是他们也是把输入映射为固定维度的向量表示。</p><h6 id="4-第二代预训练语言模型"><a class="markdownIt-Anchor" href="#4-第二代预训练语言模型"></a> 4. 第二代预训练语言模型</h6><p>第二代预训练语言模型学习contextual(dynamical) word embeddings，即与上下文相关的、动态的词向量。</p><p>第二代预训练语言模型的重要代表是ElMo(Embeddings from Language Models)、OpenAI GPT (Generative Pre-training) 和BERT(Bidirectional Encoder Representation from Transformer) 。</p><p>得益于<strong>更强的算力、深度模型的发展、NLP预训练任务的设计、大规模训练语料的利用、各种训练技巧</strong>的出现，第二代预训练语言模型蓬勃发展、越来越强大。</p><p><img src="https://img-blog.csdnimg.cn/20200517112313993.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="第一代与第二代预训练语言模型"></p><h6 id="5-扩展的预训练语言模型"><a class="markdownIt-Anchor" href="#5-扩展的预训练语言模型"></a> 5. 扩展的预训练语言模型</h6><p>随着预训练语言模型的发展，研究人员已经不再满足于使用简单范式和简单语料训练预训练语言模型，由此催生了一系列扩展的预训练语言模型。其中包括：知识增强（Knowledge-Enriched）的预训练模型、多语言/跨语言（Multilingual）的预训练模型、针对特定语言（Language-Specific）的预训练模型、多模态（Multi-Modal，包括视频-文本、图像-文本、声音-文本等）的预训练模型、针对特定领域（Domain-Specific）的预训练模型、针对特定任务（Task-Specific）的预训练模型等。此外，还有一些预训练模型是在大型预训练模型上做出一些修改/压缩等操作所得的，包括修剪、量化、参数共享、蒸馏、模块替换等，这其中也涉及到如何应用预训练语言模型的问题，在讲到预训练模型的应用是还会进一步介绍。下图是邱老师综述中关于扩展的预训练模型及相关工作的归纳：</p><p><img src="https://img-blog.csdnimg.cn/20210715235045868.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt="扩展的预训练语言模型"></p><h2 id="nlp深度神经网络的发展"><a class="markdownIt-Anchor" href="#nlp深度神经网络的发展"></a> NLP深度神经网络的发展</h2><p><img src="https://img-blog.csdnimg.cn/20200517113139104.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt=""><br>当前，NLP任务通用的神经网络架构如图1所示（其实就是第二代预训练语言模型的架构）。<br>邱老师的文章把Neural Contextual Encoders分为了两类。<br>一类是Sequence Models，此类模型是按序列顺序来获取词的上下文（包括CNN模型和RNN模型（LSTM和GRU）），无法很好地处理长期依赖（Long-term dependency）。<br>另一类是Graph-based Models，此类模型按预定义的树形或图结构（如句法结构、语义联系）建立词与上下文的联系，但是如何建立好的此类结构是比较困难的。因此，全连接与自注意力在强大算力的加持下就提供了一个更为直接的方法：可以建立全连接图然后让模型学习两个词之间的联系。</p><style type="text/css">.tg{border-collapse:collapse;border-spacing:0}.tg td{border-color:#000;border-style:solid;border-width:1px;font-family:Arial,sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal}.tg th{border-color:#000;border-style:solid;border-width:1px;font-family:Arial,sans-serif;font-size:14px;font-weight:400;overflow:hidden;padding:10px 5px;word-break:normal}.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}</style><table class="tg"><thead><tr><th class="tg-0pky">Contextual Encoders</th><th class="tg-0pky">NN Types</th><th class="tg-0pky">References</th></tr></thead><tbody><tr><td class="tg-c3ow" rowspan="3">Sequence Models</td><td class="tg-0pky">CNN</td><td class="tg-0pky">[1]Y. Kim, “Convolutional Neural Networks for Sentence Classification,” in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Doha, Qatar, Oct. 2014, pp. 1746–1751, doi: 10.3115/v1/D14-1181.</td></tr><tr><td class="tg-0pky">LSTM</td><td class="tg-0pky">[1]A. M. Dai and Q. V. Le, “Semi-supervised Sequence Learning,” arXiv:1511.01432 [cs], Nov. 2015, Accessed: May 17, 2020. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1511.01432"><span style="color:#905">http://arxiv.org/abs/1511.01432</span></a>.<br>[2]P. Liu, X. Qiu, and X. Huang, “Recurrent Neural Network for Text Classification with Multi-Task Learning,” p. 7.</td></tr><tr><td class="tg-0pky">GRU</td><td class="tg-0pky">[1]R. Kadlec, M. Schmid, O. Bajgar, and J. Kleindienst, “Text Understanding with the Attention Sum Reader Network,” arXiv:1603.01547 [cs], Jun. 2016, Accessed: May 17, 2020. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1603.01547"><span style="color:#905">http://arxiv.org/abs/1603.01547</span></a>.<br>[2]L. Li, M. Huang, Y. Liu, S. Qian, and X. He, “Contextual label sensitive gated network for biomedical event trigger extraction,” Journal of Biomedical Informatics, vol. 95, p. 103221, Jul. 2019, doi: 10.1016/j.jbi.2019.103221.</td></tr><tr><td class="tg-c3ow" rowspan="3">Graph-based Models</td><td class="tg-0pky">Recursive NN</td><td class="tg-0pky">[1]R. Socher et al., “Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank,” in Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Seattle, Washington, USA, Oct. 2013, pp. 1631–1642, Accessed: May 17, 2020. [Online]. Available: <a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D13-1170"><span style="color:#905">https://www.aclweb.org/anthology/D13-1170</span></a>.</td></tr><tr><td class="tg-0pky">TreeLSTM</td><td class="tg-0pky">[1]K. S. Tai, R. Socher, and C. D. Manning, “Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks,” in Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Beijing, China, Jul. 2015, pp. 1556–1566, doi: 10.3115/v1/P15-1150.<br>[2]X. Zhu, P. Sobhani, and H. Guo, “Long short-term memory over recursive structures,” in Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, Lille, France, Jul. 2015, pp. 1604–1612, Accessed: May 16, 2020. [Online].</td></tr><tr><td class="tg-0pky">GCN</td><td class="tg-0pky">[1]T. N. Kipf and M. Welling, “Semi-Supervised Classification with Graph Convolutional Networks,” arXiv:1609.02907 [cs, stat], Feb. 2017, Accessed: May 17, 2020. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1609.02907"><span style="color:#905">http://arxiv.org/abs/1609.02907</span></a>.</td></tr></tbody></table><p><img src="https://img-blog.csdnimg.cn/20200515153802900.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3piZ2poeTg4,size_16,color_FFFFFF,t_70" alt=""></p><p>[1] <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/31370551?sort=created">https://www.zhihu.com/question/31370551?sort=created</a><br>[2] Z. S. Harris, “Distributional Structure,” WORD, vol. 10, no. 2–3, pp. 146–162, Aug. 1954, doi: 10.1080/00437956.1954.11659520.</p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>容易混淆的概念有语法与词法，词法是分析词与词的变形，即形态学(morphology)；而语法是一个更完整的概念，包括音韵学（phonology）、形态学(morphology)与造句法（syntax）[1]。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Distributed Representation与Distributional Representation容易混淆。通常认为，Distributed Representation是与Local Representation（One-hot Representation就属于Local Representation）相对的，用到低维稠密向量来表示词的语义，单独的维度是不表达什么含义的，只有整个向量表达出含义；而One-hot Representation则是高维稀疏向量来表示词的语义，只有一个维度表示含义。而Distributional Representation的理论基础则是Harris在1954年提出的分布假说（Distributional Hypothesis）[2]，即上下文相似的词，其语义也相近。所以说凡是用到上下文的Representation都可以称为Distributional Representation，如传统的基于计数的词向量、Word2Vec以及contextualized word vector都属于Distributional Representation。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>代表工作有CharCNN、FastText和Byte-Pair Encoding (BPE)等。 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li></ol></section></div><div class="article-licensing box"><div class="licensing-title"><p>预训练语言模型综述（一）—— 预训练语言模型及其历史</p><p><a href="https://forskamse.github.io/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/">https://forskamse.github.io/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Forskamse</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2021-07-15</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2021-08-06</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Pre-trained-Language-Model/">Pre-trained Language Model</a><a class="link-muted mr-2" rel="tag" href="/tags/Language-Modeling/">Language Modeling</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=60c3b9500800bf0011ba681a&amp;product=sticky-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/Alipay.png" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/WeChat.jpg" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/08/28/2021-08-28-Review_on_Pretrained_Language_Models_Part_II/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">预训练语言模型综述（二）—— 预训练任务及训练策略</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/03/08/2021-03-08-Implementations_of_Some_CNN_Modules_Based_on_TensorFlow2/"><span class="level-item">基于TensorFlow 2.x的一些CNN模块/网络的实现</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config=function(){this.page.url="https://forskamse.github.io/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/",this.page.identifier="2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/"};!function(){var e=document,t=e.createElement("script");t.src="//forskamse.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)}()</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Forskamse"></figure><p class="title is-size-4 is-block" style="line-height:inherit">Forskamse</p><p class="is-size-6 is-block">Ph.D. Student in ECE</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Macao, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">17</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">17</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">32</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/forskamse" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/forskamse"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="CSDN" href="https://forskamse.blog.csdn.net"><i class="fab fa-cuttlefish"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:forskamse@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="profile" display="flex" align-items="center" justify-content="center"><iframe width="100%" height="100%" src="//music.163.com/outchain/player?type=2&amp;id=1329750306&amp;auto=0"></iframe></div><div class="card widget" data-type="profile" display="flex" align-items="center" justify-content="center"><a target="_blank" rel="noopener" href="https://clustrmaps.com/site/1bimd" title="Visit tracker"><img width="100%" height="100%" src="//www.clustrmaps.com/map_v2.png?d=6fqRfd5WfWFGOTXaDemdbnpxHNvQm58AoOCDuZ8Jhu0&amp;cl=ffffff"></a></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://skliotsc.um.edu.mo/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">SKL-IOTSC(UM)</span></span><span class="level-right"><span class="level-item tag">skliotsc.um.edu.mo</span></span></a></li><li><a class="level is-mobile" href="https://um.edu.mo/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">University of Macau</span></span><span class="level-right"><span class="level-item tag">um.edu.mo</span></span></a></li><li><a class="level is-mobile" href="https://sisse.jnu.edu.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">SISSE(JNU)</span></span><span class="level-right"><span class="level-item tag">sisse.jnu.edu.cn</span></span></a></li><li><a class="level is-mobile" href="https://jnu.edu.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Jinan University</span></span><span class="level-right"><span class="level-item tag">jnu.edu.cn</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=forskamsesblog&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="forskamsesblog" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Mathematics/"><span class="level-start"><span class="level-item">Mathematics</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Computer/"><span class="level-start"><span class="level-item">Computer</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Computer/Basics-of-Computers/"><span class="level-start"><span class="level-item">Basics of Computers</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Computer/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Deployment/"><span class="level-start"><span class="level-item">Deployment</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Neural-Networks/"><span class="level-start"><span class="level-item">Neural Networks</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Neural-Networks/CNN-Special-Column/"><span class="level-start"><span class="level-item">CNN Special Column</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Neural-Networks/Implementations/"><span class="level-start"><span class="level-item">Implementations</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/Demo/"><span class="level-start"><span class="level-item">Demo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/IoT/"><span class="level-start"><span class="level-item">IoT</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/IoT/Wireless-Sensor-Networks/"><span class="level-start"><span class="level-item">Wireless Sensor Networks</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/NLP/PTM-Special-Column/"><span class="level-start"><span class="level-item">PTM Special Column</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Raspberry-Pi/"><span class="level-start"><span class="level-item">Raspberry Pi</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Tools/"><span class="level-start"><span class="level-item">Tools</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/2021/09/26/2021-09-27-Review_on_Pretrained_Language_Models_Part_III/"><img src="https://img-blog.csdnimg.cn/d9465a02fbef4dfebef2639b6ddaa201.png" alt="预训练语言模型综述（三）—— 预训练语言模型的实际使用"></a></figure><div class="media-content"><p class="date"><time datetime="2021-09-26T14:25:50.000Z">2021-09-26</time></p><p class="title"><a href="/2021/09/26/2021-09-27-Review_on_Pretrained_Language_Models_Part_III/">预训练语言模型综述（三）—— 预训练语言模型的实际使用</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a> / <a href="/categories/NLP/">NLP</a> / <a href="/categories/NLP/PTM-Special-Column/">PTM Special Column</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/08/28/2021-08-28-Review_on_Pretrained_Language_Models_Part_II/"><img src="https://img-blog.csdnimg.cn/20200517142611672.png" alt="预训练语言模型综述（二）—— 预训练任务及训练策略"></a></figure><div class="media-content"><p class="date"><time datetime="2021-08-28T11:13:47.000Z">2021-08-28</time></p><p class="title"><a href="/2021/08/28/2021-08-28-Review_on_Pretrained_Language_Models_Part_II/">预训练语言模型综述（二）—— 预训练任务及训练策略</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a> / <a href="/categories/NLP/">NLP</a> / <a href="/categories/NLP/PTM-Special-Column/">PTM Special Column</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/"><img src="https://img-blog.csdnimg.cn/20200517112313993.png" alt="预训练语言模型综述（一）—— 预训练语言模型及其历史"></a></figure><div class="media-content"><p class="date"><time datetime="2021-07-14T17:52:31.000Z">2021-07-15</time></p><p class="title"><a href="/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/">预训练语言模型综述（一）—— 预训练语言模型及其历史</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a> / <a href="/categories/NLP/">NLP</a> / <a href="/categories/NLP/PTM-Special-Column/">PTM Special Column</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/03/08/2021-03-08-Implementations_of_Some_CNN_Modules_Based_on_TensorFlow2/"><img src="https://img-blog.csdnimg.cn/20210705005936584.png" alt="基于TensorFlow 2.x的一些CNN模块/网络的实现"></a></figure><div class="media-content"><p class="date"><time datetime="2021-03-08T07:22:01.000Z">2021-03-08</time></p><p class="title"><a href="/2021/03/08/2021-03-08-Implementations_of_Some_CNN_Modules_Based_on_TensorFlow2/">基于TensorFlow 2.x的一些CNN模块/网络的实现</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a> / <a href="/categories/Deep-Learning/Neural-Networks/">Neural Networks</a> / <a href="/categories/Deep-Learning/Neural-Networks/Implementations/">Implementations</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/01/07/2021-01-07-Deployment_of_JupyterLab3_on_Remote_Server/"><img src="https://img-blog.csdnimg.cn/20210714003645449.png" alt="在远程服务器上部署JupyterLab 3.0"></a></figure><div class="media-content"><p class="date"><time datetime="2021-01-07T08:52:43.000Z">2021-01-07</time></p><p class="title"><a href="/2021/01/07/2021-01-07-Deployment_of_JupyterLab3_on_Remote_Server/">在远程服务器上部署JupyterLab 3.0</a></p><p class="categories"><a href="/categories/Tools/">Tools</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">September 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">August 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/07/"><span class="level-start"><span class="level-item">July 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/03/"><span class="level-start"><span class="level-item">March 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">January 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/07/"><span class="level-start"><span class="level-item">July 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">February 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">January 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/12/"><span class="level-start"><span class="level-item">December 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">June 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Complexity/"><span class="tag">Complexity</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer/"><span class="tag">Computer</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DNS/"><span class="tag">DNS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debug/"><span class="tag">Debug</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Forward-Proxy/"><span class="tag">Forward Proxy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Grafana/"><span class="tag">Grafana</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Implementations/"><span class="tag">Implementations</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/InfluxDB/"><span class="tag">InfluxDB</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IoT/"><span class="tag">IoT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Jupyter/"><span class="tag">Jupyter</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JupyterLab/"><span class="tag">JupyterLab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Language-Modeling/"><span class="tag">Language Modeling</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NAT/"><span class="tag">NAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NP-Hard/"><span class="tag">NP-Hard</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NPC/"><span class="tag">NPC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Neural-Networks/"><span class="tag">Neural Networks</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Operation-Maintenance/"><span class="tag">Operation&amp;Maintenance</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/P-NP/"><span class="tag">P=NP?</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Penetration/"><span class="tag">Penetration</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Port-Forwarding/"><span class="tag">Port Forwarding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pre-trained-Language-Model/"><span class="tag">Pre-trained Language Model</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Proxy/"><span class="tag">Proxy</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Raspberry-Pi/"><span class="tag">Raspberry Pi</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reverse-Proxy/"><span class="tag">Reverse Proxy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Settings-Sync/"><span class="tag">Settings Sync</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TensorFlow2/"><span class="tag">TensorFlow2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tunnel/"><span class="tag">Tunnel</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/User-Snippets/"><span class="tag">User Snippets</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VS-Code/"><span class="tag">VS Code</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wireless-Sensor-Networks/"><span class="tag">Wireless Sensor Networks</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Forskamse&#039;s Homepage" height="28"></a><p class="is-size-7"><span>&copy; 2021 Forskamse</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en")</script><script>var IcarusThemeSettings={article:{highlight:{clipboard:!0,fold:"unfolded"}}}</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load",function(){document.querySelectorAll('[role="article"] > .content').forEach(function(e){renderMathInElement(e)})})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><script src="/js/main.js" defer></script><script src="/js/busuanzi.pure.mini.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener("DOMContentLoaded",function(){loadInsight({contentUrl:"/content.json"},{hint:"Type something...",untitled:"(Untitled)",posts:"Posts",pages:"Pages",categories:"Categories",tags:"Tags"})})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"superSample":2,"width":150,"height":300,"position":"left","hOffset":0,"vOffset":-50},"mobile":{"show":true,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"tagMode":false});</script></body></html>