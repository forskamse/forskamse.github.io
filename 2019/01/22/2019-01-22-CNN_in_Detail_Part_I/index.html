<!doctype html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta><title>卷积神经网络详解(一)——基础知识 - Forskamse&#039;s Homepage</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Forskamse&#039;s Homepage"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Forskamse&#039;s Homepage"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="1. 卷积神经网络的组成 1981年诺贝尔医学奖得主，神经生物学家David Hubel 和Torsten Wiesel对人脑视觉系统的研究表明：人脑视觉系统首先通过眼睛来成像，图像通过瞳孔、晶状体最终在视网膜上成像。视网膜上布满了大量的光感受细胞，可以把光刺激转换为神经冲动，神经冲动通过视觉通路传递到大脑的初级视觉皮层（Primary Visual Cortex，V1），V1初步处理得到边缘、"><meta property="og:type" content="blog"><meta property="og:title" content="卷积神经网络详解(一)——基础知识"><meta property="og:url" content="https://forskamse.github.io/2019/01/22/2019-01-22-CNN_in_Detail_Part_I/"><meta property="og:site_name" content="Forskamse&#039;s Homepage"><meta property="og:description" content="1. 卷积神经网络的组成 1981年诺贝尔医学奖得主，神经生物学家David Hubel 和Torsten Wiesel对人脑视觉系统的研究表明：人脑视觉系统首先通过眼睛来成像，图像通过瞳孔、晶状体最终在视网膜上成像。视网膜上布满了大量的光感受细胞，可以把光刺激转换为神经冲动，神经冲动通过视觉通路传递到大脑的初级视觉皮层（Primary Visual Cortex，V1），V1初步处理得到边缘、"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Covers/06.jpg"><meta property="article:published_time" content="2019-01-22T06:00:00.000Z"><meta property="article:modified_time" content="2021-08-06T06:30:59.870Z"><meta property="article:author" content="Forskamse"><meta property="article:tag" content="CNN"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Covers/06.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://forskamse.github.io/2019/01/22/2019-01-22-CNN_in_Detail_Part_I/"},"headline":"卷积神经网络详解(一)——基础知识","image":["https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Covers/06.jpg"],"datePublished":"2019-01-22T06:00:00.000Z","dateModified":"2021-08-06T06:30:59.870Z","author":{"@type":"Person","name":"Forskamse"},"publisher":{"@type":"Organization","name":"Forskamse's Homepage","logo":{"@type":"ImageObject","url":"https://forskamse.github.io/img/logo.png"}},"description":"1. 卷积神经网络的组成 1981年诺贝尔医学奖得主，神经生物学家David Hubel 和Torsten Wiesel对人脑视觉系统的研究表明：人脑视觉系统首先通过眼睛来成像，图像通过瞳孔、晶状体最终在视网膜上成像。视网膜上布满了大量的光感受细胞，可以把光刺激转换为神经冲动，神经冲动通过视觉通路传递到大脑的初级视觉皮层（Primary Visual Cortex，V1），V1初步处理得到边缘、"}</script><link rel="canonical" href="https://forskamse.github.io/2019/01/22/2019-01-22-CNN_in_Detail_Part_I/"><link rel="alternate" href="/atom.xml" title="Forskamse&#039;s Homepage" type="application/atom+xml"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Forskamse&#039;s Homepage" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Covers/06.jpg" alt="卷积神经网络详解(一)——基础知识"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt">&nbsp;</i> <time datetime="2019-01-22T06:00:00.000Z">2019-01-22</time></span><i class="far fa-folder"></i><span> </span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/Neural-Networks/">Neural Networks</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/Neural-Networks/CNN-Special-Column/">CNN Special Column</a></span></div></div><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><i class="far fa-clock"></i><span> </span><span class="level-item">27 minutes read (About 3979 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye">&nbsp;</i> <span id="busuanzi_value_page_pv">0</span></span></div></div><h1 class="title is-3 is-size-4-mobile">卷积神经网络详解(一)——基础知识</h1><div class="content"><h2 id="1-卷积神经网络的组成"><a class="markdownIt-Anchor" href="#1-卷积神经网络的组成"></a> 1. 卷积神经网络的组成</h2><p>1981年诺贝尔医学奖得主，神经生物学家David Hubel 和Torsten Wiesel对人脑视觉系统的研究表明：人脑视觉系统首先通过眼睛来成像，图像通过瞳孔、晶状体最终在视网膜上成像。视网膜上布满了大量的光感受细胞，可以把光刺激转换为神经冲动，神经冲动通过视觉通路传递到大脑的初级视觉皮层（Primary Visual Cortex，V1），V1初步处理得到边缘、方向等特征信息，而后经由V2的进一步抽象得到轮廓、形状等特征信息，如此迭代地经由多层（V1层至V5层）的抽象后得到高层特征。高层特征是低层特征的组合<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，从低层特征到高层特征的抽象过程中，语义的表现越来越清晰，存在的歧义越来越少，对目标的识别也就越来越精确。这就是人脑视觉系统的分层处理机制。</p><span id="more"></span><p>视觉皮层上的细胞有简单细胞（Simple Cell）与复杂细胞（Complex Cell）之分，这两种细胞的共同点是他们都只对特定方向的条形图样刺激有反应，而他们的主要区别是简单细胞对应的视网膜上的光感受细胞所在的区域比复杂细胞所对应的区域来得小，这个区域被称为感受野（Receptive Field）。这就是人脑视觉系统的感受野机制。</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190121231252850_1844689380.png"></div><p>1980年，日本学者Kunihiko Fukushima提出感知机模型（Neocognitron），提出使用卷积层来模拟视觉细胞对特定图案的反应、使用池化层模拟感受野的方法。卷积神经网络的设计深受这个方法的影响，其基本结构为：</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190107202305429_94794149.png"></div><p>具体说来，卷积层用于提取不同的图像特征，有减少参数数量、保留空间信息的作用；池化层用于模拟感受野，有选取特征、减少参数数量的作用，同时引入微小平移不变性<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>；而激活层的设置则是为了引入非线性因子，提升模型的表达能力，这是神经网络中普遍采用的。</p><h2 id="2-卷积层"><a class="markdownIt-Anchor" href="#2-卷积层"></a> 2. 卷积层</h2><h3 id="21-图像的局部相关性"><a class="markdownIt-Anchor" href="#21-图像的局部相关性"></a> 2.1 图像的局部相关性</h3><p>图像是具有局部相关性的一类数据<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>，其局部相关性是指组成图像的每个像素点与其周围的像素点是有关联的，而图像上距离较远的像素相关性较弱，因此处理图像时实际上没必要每个神经元都对全局图像进行感知。</p><h3 id="22-全连接网络用于图像处理"><a class="markdownIt-Anchor" href="#22-全连接网络用于图像处理"></a> 2.2 全连接网络用于图像处理</h3><p>以MNIST手写数字识别为例，该数据集中的图像为（28，28，1）的灰度图像，这个图像由28 * 28个像素点（Pixel）构成，每个像素点有一个通道（Channel）。如果使用全连接网络（即网络中的神经元与相邻层上的每个神经元均连接），那么输入层有28 * 28 =784个神经元，假设hidden层采用了15个神经元<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>，输出层是10个神经元，那么参数个数(w和b)就有：784 * 15 * 10+15+10=117625个。即使在这种情况下，参数量都十分庞大了，如果输入图像的像素点更多、全连接网络的隐藏层层数更多、隐藏层神经元数量更多，参数量就会更加庞大。<br>大量的参数很容易导致网络过拟合，而且每进行一次反向传播计算量都是巨大的，无论从调参还是计算资源的角度都不建议用全连接网络做图像处理。此外，全连接网络认为“每个输入值都是平等的”，它将输入视为一维向量，并不关心这个像素是第几行、第几列的像素，忽视了空间信息，用于图像这种具有空间局部相关性的数据也是不合适的。</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/1546681571_28983.png"></div><h3 id="23-减少参数数量"><a class="markdownIt-Anchor" href="#23-减少参数数量"></a> 2.3 减少参数数量</h3><p>在图像局部相关性的支撑下，卷积连接应用而生。<br>为简化说明，来看一个简单的例子：<br>在下面的这张图中，输入为3 * 3 = 9个像素，如果将其与16个隐藏层神经元全连接，就会有9 * 16 = 144个连接，也就有144个权值。</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190112180923731_700883300.png"></div><p>为减少连接数，并且基于图像局部相关性的假设，可以仅取四个位置相近（注意图像的Width和Height两个维度）的像素作为输入，四个像素与同一个神经元进行连接，连接的权值记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">w_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">w_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>， 如下图所示。</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190112181611409_233506424.png"></div><p>这种连接方式又可看作是数学上的卷积操作<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>，其中这一组权值就被称为卷积核， 如下图右图所示，因此得名卷积连接。</p><p>我们将这个卷积操作在输入图像上滑动起来，自然地，连接的神经元也向下滑动，连接的权值仍记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">w_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">w_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，如下图所示。此时注意，这个卷积操作要覆盖图像上的所有9个像素，需要滑动四次，因此对应着四个神经元。图像的四部分局部像素与这四个神经元连接时共享同一套权值（简洁地说，这四个神经元共享一套权值），这就是所谓的“权值共享”的概念。这组权值又叫做卷积核。</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190112183300720_471577742.png"></div><p>卷积连接方式使得每个神经元所感知的图像的范围由整张图缩减到了4个像素点，从而减少了权值的数量，又采取了“权值共享”的方法，进一步减少了参数的数量。</p><p>允许我们对图像进行卷积操作的理论依据就是图像的局部相关性：卷积神经网络的设计认为每个神经元没必要对全局图像进行感知，只需对局部像素按空间位置进行局部连接即可。</p><h3 id="24-提取图像特征"><a class="markdownIt-Anchor" href="#24-提取图像特征"></a> 2.4 提取图像特征</h3><p>卷积层每次用一个卷积核在图像上滑动，来提取图像的某一显著特征。<br>卷积核可以找到图中和卷积核自身最相似的部分，而且相似度越高，得到的响应值越大。</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190122174325180_288459116.png"></div><p>图7中上面一排的照片是5架战斗机，把其中一架战斗机的图像截出来作为卷积核，与原图像进行卷积，得到结果如下排图像所示。可以看到，每架战斗机所在的位置都得到了一个极大的响应。<br>因此，通过设置合理的损失函数，在卷积神经网络中使用反向传播算法，最终可以学习到相应于目标结果的卷积核，在Inference的时候就可以提取出有效特征。</p><h3 id="25-保留空间信息"><a class="markdownIt-Anchor" href="#25-保留空间信息"></a> 2.5 保留空间信息</h3><p>与全连接网络相比，卷积网络没有将图像展开为一维向量，而是使用卷积核在原图像上滑动来提取特征，因此保留了原图像的局部空间信息。<br>图7中上面一排右边的照片是由左边照片对5架战斗机平移得到的。经过同样的卷积操作后，得到的特征响应图相当于左边的特征响应图做相应的平移。这是卷积神经网络的局部连接和权值共享带来的“同变性（Equivariance）”<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>，亦是卷积神经网络可以保留图像空间信息的体现。</p><h3 id="26-卷积操作的补充"><a class="markdownIt-Anchor" href="#26-卷积操作的补充"></a> 2.6 卷积操作的补充</h3><ol><li>卷积核（Filter）</li></ol><p>在数学定义上，矩阵的卷积（Convolution）操作为：首先将卷积核进行翻转，构成一个卷积核的镜像，然后使用该镜像和前面矩阵相应位置进行点乘。如下面所示：</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/1546851390_24790.png"></div><ol start="2"><li>步长（Step）</li></ol><p>卷积操作每次移动的单位数称为步长。</p><ol start="3"><li>填充（Padding）<br>为了控制输出的尺寸，可以采用填充的方法。例如在步长为2的情况下，输出尺寸原为5 * 5，如果想使输出尺寸为3 * 3， 可以在输入外围添加一圈0，在这种情况下，输出的尺寸就是3 * 3。</li></ol><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190107180531456_2081156539.png"></div><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190112180202610_1822722602.png"></div><h2 id="3-激活层"><a class="markdownIt-Anchor" href="#3-激活层"></a> 3. 激活层</h2><p>激活层算不上卷积神经网络的特色，这里就不详细介绍了，简而言之，激活层的作用就是引入非线性因子，提升模型的表达能力。</p><h2 id="4-池化层"><a class="markdownIt-Anchor" href="#4-池化层"></a> 4. 池化层</h2><p>卷积神经网络在卷积层和激活层之后又增加了池化层，用来模拟感受野，以达到选取特征、减少参数数量的作用，同时引入微小平移不变性。</p><h3 id="41-特征选取"><a class="markdownIt-Anchor" href="#41-特征选取"></a> 4.1 特征选取</h3><p>池化的一个功能是对特征的选取，卷积神经网络中常用的有Average Pooling和Maximum Pooling。Average Pooling，即对池化区域内特征点求平均，Maximum Pooling则对池化区域内特征点取最大。Average Pooling更能保留图片的背景信息，如果背景中也含有有效信息，Average Pooling就更合适；Maximum Pooling会忽略背景信息，在有噪声的情况下则更有效。<br>通过池化，CNN进一步减少了参数数量（降维）。</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/1540565865_21442.png"></div><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/1540565888_8954.png"></div><h3 id="42-微小平移不变性"><a class="markdownIt-Anchor" href="#42-微小平移不变性"></a> 4.2 微小平移不变性</h3><p>在局部连接和权值共享的作用下，平移后图像的特征映射图与特征映射图直接做对应的平移得到的结果差别不大，即前面所述的同变性。</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190107204820550_1059782468.png"></div>此时再进行池化，以Maximum Pooling为例，如下图所示，在左图中得到的池化结果是11，在右图中得到的池化结果也是11，体现了平移不变性。<div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108100749906_1800606002.png"></div>需要指出的是，池化的平移不变性是有限的，即所说的微小平移不变性。如果平移超出了感受野的位置，平移不变性就难以体现。<h2 id="5-分层表达"><a class="markdownIt-Anchor" href="#5-分层表达"></a> 5. 分层表达</h2><p>前已述及，人脑视觉系统存在分层处理的机制，卷积神经网络用多层的网络来模拟人脑视觉系统的分层处理。<br>通过多层的卷积神经网络，计算机逐步“理解”一幅图像大致遵循这样的过程：像素–&gt;边缘–&gt;基本形状–&gt;复杂图案–&gt;更复杂图案。<br>例如，在学习一张车的图片时，浅层的卷积层能从最基本的像素中学习到边缘特征，较深层点的可以学习到圆形等基本形状，再经过几层可以学习到轮胎、车身等图案特征，最后可以学习到车的整体特征。</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108113541696_1346990095.png"></div><h2 id="6-卷积的可视化与解释性"><a class="markdownIt-Anchor" href="#6-卷积的可视化与解释性"></a> 6. 卷积的可视化与解释性</h2><p>深度学习的解释性学界仍在研究当中。目前对于卷积神经网络，仅能通过可视化提供简单的解释。</p><h3 id="61-边缘检测"><a class="markdownIt-Anchor" href="#61-边缘检测"></a> 6.1 边缘检测</h3><p>先解释卷积层如何做边缘检测。<br>图片最常做的边缘检测有两类：垂直边缘（Vertical Edges）检测和水平边缘（Horizontal Edges）检测。</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108120127391_1249309616.png"></div><p>以垂直边缘检测为例，原始灰度图像尺寸为 6x6，卷积核尺寸为 3x3，不做Padding，Stride = 1，卷积后得到的特征映射图尺寸为 4x4，得到结果如下：</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108142020333_337721441.png"></div>在灰度图像中，０代表灰，正值表示白，值越大越白，负值代表黑，值越小越黑。本例的原始图像和卷积后的特征映射图，有图例所示的黑白灰分布，提取出了垂直边缘。<h3 id="62-响应相似图形"><a class="markdownIt-Anchor" href="#62-响应相似图形"></a> 6.2 响应相似图形</h3><p>这部分可以参考2.4节。</p><h3 id="63-特征响应图可视化"><a class="markdownIt-Anchor" href="#63-特征响应图可视化"></a> 6.3 特征响应图可视化</h3><p>相关研究<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>中，曾实现了对特征映射图的可视化。直接看一下结果：</p><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108144217752_522028051.png"></div><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108144230894_1788507434.png"></div><div align="center"><img src="https://gitee.com/forskamse/forskamse-open-images/raw/main/blog/Jan_2019/CNN_Basics_P1/20190108144335133_1669012016.png"></div>目前的研究虽然还是不能完全解释CNN，但是通过可视化，我们发现CNN学习到的特征确实如我们所预期的呈现分层特性，底层是一些边缘角点以及颜色的抽象特征，越到高层则越呈现出具体的特征，与人类视觉系统类似。<h2 id="7-卷积神经网络为什么有效"><a class="markdownIt-Anchor" href="#7-卷积神经网络为什么有效"></a> 7. 卷积神经网络为什么有效</h2><ol><li>从神经科学角度：卷积神经网络模仿了人脑视觉系统的分层处理机制以及感受野机制；</li><li>从统计角度：卷积神经网络抓住了图像的局部相关性（Spatially-local Correlation）；</li><li>从正则化的角度：由于局部连接、权值共享和池化，降低了模型参数数量，控制了模型复杂度，可有效避免模型过拟合。</li></ol><p><strong>关键词 ： 局部感受野、权值共享、时间/空间亚采样</strong></p><h2 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h2><p><a target="_blank" rel="noopener" href="https://book.douban.com/subject/27125397/">深度学习与计算机视觉——算法原理、框架应用与代码实现</a><br><a target="_blank" rel="noopener" href="https://www.linkedin.com/pulse/derivation-convolutional-neural-network-from-fully-connected-gad">Derivation of Convolutional Neural Network from Fully Connected Network Step-By-Step</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/charlotte77/p/7759802.html">卷积神经网络CNN原理详解(一)——基本原理</a><br><a target="_blank" rel="noopener" href="https://lguduy.github.io//2017/07/02/CNN%E4%B8%BA%E4%BB%80%E4%B9%88work/#annotations:EasaThA1EemS5wtu41br7w">CNN为什么有效</a><br><a target="_blank" rel="noopener" href="https://zhangting2020.github.io/2018/05/30/Transform-Invariance/">卷积神经网络为什么具有平移不变性？</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/30800318">吴恩达 DeepLearning.ai 课程提炼笔记（4-1）卷积神经网络 — 卷积神经网络基础</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhang2012liang/article/details/52687498">CNN十大问</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hejunlin1992/p/7583444.html">CNN中减少网络的参数的三个思想</a></p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>需要注意的是这些层之间的连接并不一定是简单的逐层连接，例如V2层就与其它层均有连接，对这些层之间连接的进一步研究有可能进一步提升卷积神经网络的效果。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>亦有人称池化同时引入了尺度变换和旋转的不变性，由于其可解释性与效果都不佳，因此认可度不高，在此省略不讲。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>语音和自然语言也是具有局部特征性的数据，CNN也可以用于语音处理与自然语言处理。 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>可看作选择15个特征。 <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>实际上应该是数学上的互相关（Cross-correlation）。在深度学习中，我们使用的卷积运算实则没有卷积核翻转为镜像的这一步操作，因为在权重学习的角度，翻转是没有必要的，互相关与卷积相差的就是核没有翻转，所以深度学习中的卷积操作在数学上准确度来说称为互相关。 <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/voxel_grid/article/details/79275637#annotations:l5eZ9BJ8EemTjb9M9uq6Mw">关于 CNN对图像特征的 位移、尺度、形变不变性的理解</a> <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/24833574">Deep Visualization:可视化并理解CNN</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p></li></ol></section></div><div class="article-licensing box"><div class="licensing-title"><p>卷积神经网络详解(一)——基础知识</p><p><a href="https://forskamse.github.io/2019/01/22/2019-01-22-CNN_in_Detail_Part_I/">https://forskamse.github.io/2019/01/22/2019-01-22-CNN_in_Detail_Part_I/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Forskamse</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2019-01-22</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2021-08-06</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/CNN/">CNN</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=60c3b9500800bf0011ba681a&amp;product=sticky-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/Alipay.png" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/WeChat.jpg" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/02/15/2020-02-15-Bluetooth_Attendance_Tracking_System_Based_on_RPi/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">基于树莓派的蓝牙出勤追踪系统</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2018/12/13/2018-12-13-Linux_Domain_Name_Resolution/"><span class="level-item">Linux域名解析服务</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config=function(){this.page.url="https://forskamse.github.io/2019/01/22/2019-01-22-CNN_in_Detail_Part_I/",this.page.identifier="2019/01/22/2019-01-22-CNN_in_Detail_Part_I/"};!function(){var t=document,e=t.createElement("script");e.src="//forskamse.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Forskamse"></figure><p class="title is-size-4 is-block" style="line-height:inherit">Forskamse</p><p class="is-size-6 is-block">Ph.D. Student in ECE</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Macao, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">17</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">17</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">32</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/forskamse" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/forskamse"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="CSDN" href="https://forskamse.blog.csdn.net"><i class="fab fa-cuttlefish"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:forskamse@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="profile" display="flex" align-items="center" justify-content="center"><iframe width="100%" height="100%" src="//music.163.com/outchain/player?type=2&amp;id=1329750306&amp;auto=0"></iframe></div><div class="card widget" data-type="profile" display="flex" align-items="center" justify-content="center"><a target="_blank" rel="noopener" href="https://clustrmaps.com/site/1bimd" title="Visit tracker"><img width="100%" height="100%" src="//www.clustrmaps.com/map_v2.png?d=6fqRfd5WfWFGOTXaDemdbnpxHNvQm58AoOCDuZ8Jhu0&amp;cl=ffffff"></a></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://skliotsc.um.edu.mo/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">SKL-IOTSC(UM)</span></span><span class="level-right"><span class="level-item tag">skliotsc.um.edu.mo</span></span></a></li><li><a class="level is-mobile" href="https://um.edu.mo/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">University of Macau</span></span><span class="level-right"><span class="level-item tag">um.edu.mo</span></span></a></li><li><a class="level is-mobile" href="https://sisse.jnu.edu.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">SISSE(JNU)</span></span><span class="level-right"><span class="level-item tag">sisse.jnu.edu.cn</span></span></a></li><li><a class="level is-mobile" href="https://jnu.edu.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Jinan University</span></span><span class="level-right"><span class="level-item tag">jnu.edu.cn</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=forskamsesblog&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="forskamsesblog" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Algorithm/Mathematics/"><span class="level-start"><span class="level-item">Mathematics</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Computer/"><span class="level-start"><span class="level-item">Computer</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Computer/Basics-of-Computers/"><span class="level-start"><span class="level-item">Basics of Computers</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Computer/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Deployment/"><span class="level-start"><span class="level-item">Deployment</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Neural-Networks/"><span class="level-start"><span class="level-item">Neural Networks</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Neural-Networks/CNN-Special-Column/"><span class="level-start"><span class="level-item">CNN Special Column</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Neural-Networks/Implementations/"><span class="level-start"><span class="level-item">Implementations</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/Demo/"><span class="level-start"><span class="level-item">Demo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/IoT/"><span class="level-start"><span class="level-item">IoT</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/IoT/Wireless-Sensor-Networks/"><span class="level-start"><span class="level-item">Wireless Sensor Networks</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/NLP/PTM-Special-Column/"><span class="level-start"><span class="level-item">PTM Special Column</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Raspberry-Pi/"><span class="level-start"><span class="level-item">Raspberry Pi</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Tools/"><span class="level-start"><span class="level-item">Tools</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/2021/09/26/2021-09-27-Review_on_Pretrained_Language_Models_Part_III/"><img src="https://img-blog.csdnimg.cn/d9465a02fbef4dfebef2639b6ddaa201.png" alt="预训练语言模型综述（三）—— 预训练语言模型的实际使用"></a></figure><div class="media-content"><p class="date"><time datetime="2021-09-26T14:25:50.000Z">2021-09-26</time></p><p class="title"><a href="/2021/09/26/2021-09-27-Review_on_Pretrained_Language_Models_Part_III/">预训练语言模型综述（三）—— 预训练语言模型的实际使用</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a> / <a href="/categories/NLP/">NLP</a> / <a href="/categories/NLP/PTM-Special-Column/">PTM Special Column</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/08/28/2021-08-28-Review_on_Pretrained_Language_Models_Part_II/"><img src="https://img-blog.csdnimg.cn/20200517142611672.png" alt="预训练语言模型综述（二）—— 预训练任务及训练策略"></a></figure><div class="media-content"><p class="date"><time datetime="2021-08-28T11:13:47.000Z">2021-08-28</time></p><p class="title"><a href="/2021/08/28/2021-08-28-Review_on_Pretrained_Language_Models_Part_II/">预训练语言模型综述（二）—— 预训练任务及训练策略</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a> / <a href="/categories/NLP/">NLP</a> / <a href="/categories/NLP/PTM-Special-Column/">PTM Special Column</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/"><img src="https://img-blog.csdnimg.cn/20200517112313993.png" alt="预训练语言模型综述（一）—— 预训练语言模型及其历史"></a></figure><div class="media-content"><p class="date"><time datetime="2021-07-14T17:52:31.000Z">2021-07-15</time></p><p class="title"><a href="/2021/07/15/2021-07-15-Review_on_Pretrained_Language_Models_Part_I/">预训练语言模型综述（一）—— 预训练语言模型及其历史</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a> / <a href="/categories/NLP/">NLP</a> / <a href="/categories/NLP/PTM-Special-Column/">PTM Special Column</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/03/08/2021-03-08-Implementations_of_Some_CNN_Modules_Based_on_TensorFlow2/"><img src="https://img-blog.csdnimg.cn/20210705005936584.png" alt="基于TensorFlow 2.x的一些CNN模块/网络的实现"></a></figure><div class="media-content"><p class="date"><time datetime="2021-03-08T07:22:01.000Z">2021-03-08</time></p><p class="title"><a href="/2021/03/08/2021-03-08-Implementations_of_Some_CNN_Modules_Based_on_TensorFlow2/">基于TensorFlow 2.x的一些CNN模块/网络的实现</a></p><p class="categories"><a href="/categories/Deep-Learning/">Deep Learning</a> / <a href="/categories/Deep-Learning/Neural-Networks/">Neural Networks</a> / <a href="/categories/Deep-Learning/Neural-Networks/Implementations/">Implementations</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/01/07/2021-01-07-Deployment_of_JupyterLab3_on_Remote_Server/"><img src="https://img-blog.csdnimg.cn/20210714003645449.png" alt="在远程服务器上部署JupyterLab 3.0"></a></figure><div class="media-content"><p class="date"><time datetime="2021-01-07T08:52:43.000Z">2021-01-07</time></p><p class="title"><a href="/2021/01/07/2021-01-07-Deployment_of_JupyterLab3_on_Remote_Server/">在远程服务器上部署JupyterLab 3.0</a></p><p class="categories"><a href="/categories/Tools/">Tools</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">September 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">August 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/07/"><span class="level-start"><span class="level-item">July 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/03/"><span class="level-start"><span class="level-item">March 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">January 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/07/"><span class="level-start"><span class="level-item">July 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">February 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">January 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/12/"><span class="level-start"><span class="level-item">December 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/06/"><span class="level-start"><span class="level-item">June 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Complexity/"><span class="tag">Complexity</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer/"><span class="tag">Computer</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DNS/"><span class="tag">DNS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debug/"><span class="tag">Debug</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Forward-Proxy/"><span class="tag">Forward Proxy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Grafana/"><span class="tag">Grafana</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Implementations/"><span class="tag">Implementations</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/InfluxDB/"><span class="tag">InfluxDB</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IoT/"><span class="tag">IoT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Jupyter/"><span class="tag">Jupyter</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JupyterLab/"><span class="tag">JupyterLab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Language-Modeling/"><span class="tag">Language Modeling</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NAT/"><span class="tag">NAT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NP-Hard/"><span class="tag">NP-Hard</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NPC/"><span class="tag">NPC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Neural-Networks/"><span class="tag">Neural Networks</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Operation-Maintenance/"><span class="tag">Operation&amp;Maintenance</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/P-NP/"><span class="tag">P=NP?</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Penetration/"><span class="tag">Penetration</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Port-Forwarding/"><span class="tag">Port Forwarding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pre-trained-Language-Model/"><span class="tag">Pre-trained Language Model</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Proxy/"><span class="tag">Proxy</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Raspberry-Pi/"><span class="tag">Raspberry Pi</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reverse-Proxy/"><span class="tag">Reverse Proxy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Settings-Sync/"><span class="tag">Settings Sync</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TensorFlow2/"><span class="tag">TensorFlow2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tunnel/"><span class="tag">Tunnel</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/User-Snippets/"><span class="tag">User Snippets</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VS-Code/"><span class="tag">VS Code</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wireless-Sensor-Networks/"><span class="tag">Wireless Sensor Networks</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Forskamse&#039;s Homepage" height="28"></a><p class="is-size-7"><span>&copy; 2021 Forskamse</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en")</script><script>var IcarusThemeSettings={article:{highlight:{clipboard:!0,fold:"unfolded"}}}</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load",function(){document.querySelectorAll('[role="article"] > .content').forEach(function(e){renderMathInElement(e)})})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><script src="/js/main.js" defer></script><script src="/js/busuanzi.pure.mini.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener("DOMContentLoaded",function(){loadInsight({contentUrl:"/content.json"},{hint:"Type something...",untitled:"(Untitled)",posts:"Posts",pages:"Pages",categories:"Categories",tags:"Tags"})})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"superSample":2,"width":150,"height":300,"position":"left","hOffset":0,"vOffset":-50},"mobile":{"show":true,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"tagMode":false});</script></body></html>